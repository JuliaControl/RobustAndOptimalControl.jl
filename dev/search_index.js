var documenterSearchIndex = {"docs":
[{"location":"uncertainty/#Uncertainty-modeling","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We provide two general means of modeling uncertainty, the traditional MDelta framework [Skogestad][Doyle91], and using parametric uncertainty. Support for parametric uncertainty is almost universal in Julia, not only in ControlSystems.jl, by means of computing with uncertain number types. In this tutorial, we will use a Monte-Carlo approach using uncertain number types from MonteCarloMeasurements.jl.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Both the MDelta framework and parametric-uncertainty approaches are illustrated below.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Pages = [\"uncertainty.md\"]\nDepth = 3","category":"page"},{"location":"uncertainty/#Uncertainty-API","page":"Uncertainty modeling","title":"Uncertainty API","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"δc Creates an uncertain complex parameter.\nδr Creates an uncertain real parameter.\nδss (Experimental) Creates an uncertain statespace model.\nneglected_delay Create a multiplicative weight that represents uncertainty from an unmodeled delay.\nneglected_lag Create a multiplicative weight that represents uncertainty from an unmodeled lag (pole).\ngain_and_delay_uncertainty Create a multiplicative weight that represents uncertainty from uncertain gains and delay.\nmakeweight Create a custom weighting function.\nfit_complex_perturbations\nSee MonteCarloMeasurements.jl to create uncertain parameters that are represented by samples.\nsys_from_particles Convert from an uncertain representation using Particles to a \"multi-model\" representation using multiple StateSpace models.\nss2particles Convert a vector of state-space models to a single state-space model with coefficient type MonteCarloMeasurements.Particles.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"See example uncertain.jl.","category":"page"},{"location":"uncertainty/#Parametric-uncertainty-using-[MonteCarloMeasurements.jl](https://github.com/baggepinnen/MonteCarloMeasurements.jl)","page":"Uncertainty modeling","title":"Parametric uncertainty using MonteCarloMeasurements.jl","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The most straightforward way to model uncertainty is to use uncertain parameters, using tools such as IntervalArithmetic (strict, worst case guarantees) or MonteCarloMeasurements (less strict worst-case analysis or probabilistic). In the following, we show an example with MIMO systems with both parametric uncertainty and diagonal, complex uncertainty, adapted from 8.11.3 in Skogestad, \"Multivariable Feedback Control: Analysis and Design\". This example is also available as a julia script in uncertain.jl.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We will create uncertain parameters using the δr constructor from this package. One may alternatively create uncertain parameters directly using any of the constructors from MonteCarloMeasurements.jl. Most functions from ControlSystemsBase.jl should work with systems containing parameters from MonteCarloMeasurements.jl.","category":"page"},{"location":"uncertainty/#Basic-example","page":"Uncertainty modeling","title":"Basic example","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This example shows how to use MonteCarloMeasurements directly to build uncertain systems.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"using DisplayAs # hide\nusing ControlSystemsBase, MonteCarloMeasurements, Plots\ngr(fmt=:png) # hide\nω = 1 ± 0.1 # Create an uncertain Gaussian parameter","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"ζ = 0.3..0.4 # Create an uncertain uniform parameter","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"G = tf(ω^2, [1, 2ζ*ω, ω^2]) # systems accept uncertain parameters","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"w = exp10.(-2:0.02:2)\nbodeplot(G, w)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"plot(step(G, 0:0.1:20))\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/#Example:-Spinning-satellite","page":"Uncertainty modeling","title":"Example: Spinning satellite","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This example makes use of real-valued uncertain parameters created using δr, it comes from section 3.7.1 of Skogestad's book.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"using DisplayAs # hide\nusing RobustAndOptimalControl, ControlSystemsBase, MonteCarloMeasurements, Plots, LinearAlgebra\ngr(fmt=:png, size=(640,480)) # hide\nunsafe_comparisons(true)\n\na = 10\nP = ss([0 a; -a 0], I(2), [1 a; -a 1], 0)\nK = ss(1.0I(2))\n\nw = 2π .* exp10.(LinRange(-2, 2, 500))\nS, PS, CS, T = gangoffour(P, K)\nsigmaplot(S, w, lab=\"S\")\nsigmaplot!(T, w, c=2, lab=\"T\", ylims=(0.01, 45))","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Both sensitivity functions are very large, expect a non-robust system!","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Next, we add parametric uncertainty","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"a = 10*(1 + 0.1δr(100)) # Create an uncertain parameter with nominal value 10 and 10% uncertainty, represented by 100 samples\nP = ss([0 a; -a 0], I(2), [1 a; -a 1], 0)\n\nSp, PSp, CSp, Tp = gangoffour(P, K)\nsigmaplot(Sp, w, lab=\"S\")\nsigmaplot!(Tp, w, c=2, lab=\"T\", ylims=(0.01, 100))\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Not only are sensitivity functions large, they vary a lot under the considered uncertainty. We can also plot a step response of one of the sensitivity functions to check how the system behaves","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"plot(step(c2d(Tp, 0.01), 10))\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This kind of plot is quite useful, it immediately tells you that this transfer function appears stable, and that there is uncertainty in the static gain etc.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Next, we add complex diagonal multiplicative input uncertainty. With input uncertainty of magnitude ϵ  dfrac1σ(T) we are guaranteed robust stability (even for “full-block complex perturbations\")","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"a = 10\nP = ss([0 a; -a 0], I(2), [1 a; -a 1], 0)\n\nW0 = makeweight(0.2, (20,1), 2)\nW = I(2) + W0 .* diagm([δc(100), δc(100)]) # Create a diagonal complex uncertainty weighted in frequency by W0, use 100 samples\nPs = P*W\nSs, PSs, CSs, Ts = gangoffour(Ps, K)\nsigmaplot(Ss, w, lab=\"S\")\nsigmaplot!(Ts, w, c=2, lab=\"T\", ylims=(0.01, 100))\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Under this uncertainty, the sensitivity could potentially be sky high., note how some of the 100 realizations peak much higher than the others. This is an indication that the system might be unstable.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"With complex entries in the system model, we can't really plot the step response, but we can plot, e.g., the absolute value","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"res = step(c2d(Ts, 0.01), 10)\nplot(res.t, [abs.(res.y)[1,:,1] abs.(res.y)[2,:,2]]) # plot only the diagonal response\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Looks unstable to me. The analysis using MDelta methodology below will also reach this conclusion.","category":"page"},{"location":"uncertainty/#Example:-Distillation-Process","page":"Uncertainty modeling","title":"Example: Distillation Process","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This example comes from section 3.7.2 of Skogestad's book. In this example, we'll explore also complex uncertainties, created using δc.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"using DisplayAs # hide\nusing RobustAndOptimalControl, ControlSystemsBase, MonteCarloMeasurements, Plots, LinearAlgebra\ngr(fmt=:png, size=(640,480)) # hide\nunsafe_comparisons(true)\n\nM = [87.8 -86.4; 108.2 -109.6]\nG = Ref(ss(tf(1, [75, 1]))) .* M\nRGA = relative_gain_array(G, 0)\nsum(abs, RGA) # A good estimate of the true condition number, which is 141.7","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"large elements in the RGA indicate a process that is difficult to control","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We consider the following inverse-based controller, which may also be looked upon as a steady-state decoupler with a PI controller","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"k1 = 0.7\nKinv = Ref(ss(tf(k1*[75, 1], [1, 0]))) .* inv(M) \n\n# reference filter\nF = tf(1, [5, 1]) .* I(2)\n\nw = 2π .* exp10.(LinRange(-2, 2, 500))\nsigmaplot(input_sensitivity(G, Kinv), w)\nsigmaplot!(output_sensitivity(G, Kinv), w, c=2)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Sensitivity looks nice, how about step response","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"plot(step(feedback(G*Kinv)*F, 20))","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Looks excellent..","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We consider again the input gain uncertainty as in the previous example, and we manually select the perturbations to be ϵ_1 = 02 and ϵ_2 = 02. We then have","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"G′ = G * diagm([1 + 0.2, 1 - 0.2])\nplot!(step(feedback(G′*Kinv)*F, 20), l=:dash)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Looks very poor! The system was not robust to simultaneous input uncertainty!","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We can also do this with a real, diagonal input uncertainty that grows with frequency","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"W0 = makeweight(0.2, 1, 2.0) # uncertainty goes from 20% at low frequencies to 200% at high frequencies\nW = I(2) + W0 .* diagm([δr(100), δr(100)])\nGs = G*W\n\nplot(step(feedback(G*Kinv)*F, 20))\nplot!(step(feedback(G′*Kinv)*F, 20), l=:dash)\nres = step(c2d(feedback(Gs*Kinv)*F, 0.01), 20)\nmcplot!(res.t, abs.(res.y[:, :, 1]'), alpha=0.3)\nmcplot!(res.t, abs.(res.y[:, :, 2]'), alpha=0.3)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The system is very sensitive to real input uncertainty!","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"With a complex, diagonal uncertainty, modeling both gain and phase variations, it looks slightly worse, but not much worse than with real uncertainty.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"W = I(2) + W0 .* diagm([δc(100), δc(100)]) # note δc instead of δr above\nGs = G*W\nres = step(c2d(feedback(Gs*Kinv)*F, 0.01), 20)\nmcplot!(res.t, abs.(res.y[:, :, 1]'), alpha=0.3)\nmcplot!(res.t, abs.(res.y[:, :, 2]'), alpha=0.3)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"How about the sensitivity functions?","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Si = input_sensitivity(Gs, Kinv)\nsigmaplot(Si, w, c=1, lab=\"Si\")\nSo = output_sensitivity(Gs, Kinv)\nsigmaplot!(So, w, c=2, lab=\"So\")\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The sensitivity at the plant output is enormous. A low sensitivity with the nominal system does not guarantee robustness!","category":"page"},{"location":"uncertainty/#Model-order-reduction-for-uncertain-models","page":"Uncertainty modeling","title":"Model-order reduction for uncertain models","text":"","category":"section"},{"location":"uncertainty/#\\nu-gap-approach","page":"Uncertainty modeling","title":"nu-gap approach","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The nu-gap metric is a measure of distance between models when they are used in a feedback loop. This metric has the nice property that a controller designed for a process P that achieves a normalized coprime factor margin (ncfmargin) of m, will stabilize all models that are within a nu-gap distance of m from P. This can be used to reduce the number of uncertain realizations for a model represented with Particles like above in a smart way. Say that we have a plant model P","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"using DisplayAs # hide\nusing RobustAndOptimalControl, ControlSystemsBase, MonteCarloMeasurements, Plots\nω = with_nominal(0.9 .. 1.1, 1)\nζ = with_nominal(0.5 ± 0.01, 0.5)\nP = tf([ω^2], [1, 2*ζ*ω, ω^2]) |> ss","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"represented by 2000 samples (indicated by the displayed type Particles{Float64, 2000}). If we plot P, it looks something like this:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"w = exp10.(LinRange(-1, 0.5, 150))\n# nyquistplot(P, w, lab=\"Original P\", xlims=(-1.1,1.1), ylims=(-1.5,0.7), points=true, format=:png, dpi=80)\nbodeplot(P, w, lab=\"Original P\", plotphase = false, format=:png, dpi=80, ri=false, c=1, legend=true)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We can compute the nu-gap metric between each realization in P and the nominal value (encoded using with_nominal above):","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"gap = nugap(P)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The worst-case gap is:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"pmaximum(gap) # p for \"particle\" maximum","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"That means that if we design a controller for the nominal P without any uncertainty, and make sure that it achieves an ncfmargin of at least this value, it will stabilize all realizations in P.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We can also reduce the number of realizations in P by discarding those that are close in the nu-gap sense to the nominal value:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Pr = nu_reduction(P, 0.1)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"here, all realizations that were within a nu-gap distance of 0.1 from the nominal value were discarded. nu_reduction usually reduces the number of realizations substantially. The plot of P_r looks like","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"# nyquistplot(Pr, lab=\"Reduced P\", xlims=(-1.1,1.1), ylims=(-1.5,0.7), points=true, format=:png, dpi=80)\nbodeplot!(Pr, w, lab=\"Reduced P\", plotphase = false, format=:png, dpi=80, ri=false, c=2, l=2)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"we see that the reduction kept the realizations that were furthest away from the nominal value.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We can reduce the number of realizations even further using nu_reduction_recursive:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Prr = nu_reduction_recursive(P, 0.1)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"# nyquistplot(Prr, lab=\"Recursively reduced P\", xlims=(-1.1,1.1), ylims=(-1.5,0.7), points=true, format=:png, dpi=80)\nbodeplot!(Prr, w, lab=\"Recursively reduced P\", plotphase = false, format=:png, dpi=80, ri=false, c=3, l=3)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We now have only three realizations left, the nominal one and the two extreme cases (in the nu-gap sense).","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The algorithm used in nu_reduction_recursive has a worst-case complexity of O(N^2) where N is the number of realizations (particles) in P, but this complexity is only problematic for small gaps and large number of realizations, say, nu  002 and N  50.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"With the reduced model, we can more easily perform loop-shaping or other control design tasks, as long as we keep track of ncfmargin staying above our nu-gap.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"warn: Stochastic interpretation\nIf P has a stochastic interpretation, i.e., the coefficients come from some distribution, this interpretation will be lost after reduction, mean values and standard deviations will not be preserved. The reduced system should instead be interpreted as preserving worst-case uncertainty.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"For more background on the nu-gap metric, see When are two systems similar? and the book by Skogestad and Postlethwaite or by Åström and Murray.","category":"page"},{"location":"uncertainty/#Balanced-truncation","page":"Uncertainty modeling","title":"Balanced truncation","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Another option to reduce the complexity of an uncertain model is to reinterpret it has a deterministic model with expanded state and output dimensions. For example, an uncertain model with N particles and state and output dimensions n_x n_y can be converted into a deterministic model with state and output dimensions Nn_x and Nn_y respectively (the input dimension remains the same). The order of this model can then be reduced using standard balanced truncation (or any other model-reduction method). The conversion from a model with Particles coefficients to an expanded deterministic model is performed by mo_sys_from_particles, and balanced truncation (and other model-reduction techniques) is documented at Model reduction.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Note, the reduced-order model cannot easily be converted back to a representation with Particles when this approach is taken. The model-order reduction will in this case only reduce the state dimension, but the output dimension will remain the same.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We demonstrate this procedure on the model from the section above:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Pmo = mo_sys_from_particles(P, sparse=false)\nPred, S = baltrunc(Pmo)\nbodeplot(P, w, lab=\"Original P\", plotphase = false, format=:png, dpi=80, ri=false, c=1, legend=true)\nbodeplot!(Pred, w, lab=\"\", plotphase = false, format=:png, dpi=80, c=2, l=1, sp=1, alpha=0.01)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This time, we keep the same output dimension, but the state dimension is reduced significantly:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Pred.nx","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Note, Pred here represents the uncertain model with a single deterministic model of order Pred.nx, while the original uncertain model P was represented by 2000 internal models of state dimension 2.","category":"page"},{"location":"uncertainty/#Using-the-M\\Delta-framework","page":"Uncertainty modeling","title":"Using the MDelta framework","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The examples above never bothered with things like the \"structured singular value\", mu or linear-fractional transforms. We do, however, provide some elementary support for this modeling framework.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"In robust control, we often find ourselves having to consider the feedback interconnections below.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"        ┌─────────┐\n  zΔ◄───┤         │◄────wΔ\n        │         │\n   z◄───┤    P    │◄────w\n        │         │\n   y◄───┤         │◄────u\n        └─────────┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"        ┌─────────┐\n  zΔ◄───┤         │◄────wΔ\n        │         │\n   z◄───┤    P    │◄────w\n        │         │\n   y┌───┤         │◄───┐u\n    │   └─────────┘    │\n    │      ┌───┐       │\n    └─────►│ K ├───────┘\n           └───┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"           ┌───┐\n    ┌─────►│ Δ ├───────┐\n    │      └───┘       │\n    │   ┌─────────┐    │\n  zΔ└───┤         │◄───┘wΔ\n        │         │\n   z◄───┤    P    │◄────w\n        │         │\n   y┌───┤         │◄───┐u\n    │   └─────────┘    │\n    │      ┌───┐       │\n    └─────►│ K ├───────┘\n           └───┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The first block diagram denotes an open-loop system P with an uncertainty mapping w_Delta = Delta  z_Delta, a performance mapping from w to z and a input-output mapping between u and y. Such a system P can be partitioned as","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"P = beginbmatrix\nP_11  P_12  P_13\nP_21  P_22  P_23\nP_31  P_32  P_33\nendbmatrix","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"where each P(s)_ij is a transfer matrix. The type UncertainSS with constructor uss represents the block","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"P = beginbmatrix\nP_11  P_12\nP_21  P_22\nendbmatrix","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"while an ExtendedStateSpace object represents the block","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"P = beginbmatrix\nP_22  P_23\nP_32  P_33\nendbmatrix","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"there is thus no type that represents the full system P above. However, we provide the function partition which allows you to convert from a regular statespace system to an extended statespace object, and it is thus possible to represent P by placing the whole block ","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"P = beginbmatrix\nP_22  P_23\nP_32  P_33\nendbmatrix","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"into P_22 for the purposes of uncertainty analysis (use ss to convert it to a standard statespace object), and later use partition to recover the internal block structure. ","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Given an UncertainSS P, we can close the loop around Delta by calling lft(P, Δ, :u), and given an ExtendedStateSpace, we can close the loop around K by calling starprod(P, K) or lft(P, K) (using positive feedback). This works even if P is a regular statespace object, in which case the convention is that the inputs and outputs are ordered as in the block diagrams above. The number of signals that will be connected by lft is determined by the input-output arity of K and Delta respectively.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We have the following methods for lft (in addition to the standard ones in ControlSystemsBase.jl)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"lft(G::UncertainSS, K::LTISystem) forms the lower LFT closing the loop around K.\nlft(G::UncertainSS, Δ::AbstractArray=G.Δ) forms the upper LFT closing the loop around Delta.\nlft(G::ExtendedStateSpace, K) forms the lower LFT closing the loop around K.","category":"page"},{"location":"uncertainty/#Robust-stability-and-performance","page":"Uncertainty modeling","title":"Robust stability and performance","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"To check robust stability of the system in the last block diagram (with or without z and w), we can use the functions structured_singular_value, robstab and diskmargin.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Currently, structured_singular_value is rather limited and supports diagonal complex blocks only. If Delta is a single full complex block, opnorm(P.M) < 1 is the condition for stability.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Robust performance can be verified by introducing an additional fictitious \"performance perturbation\" Delta_p which is a full complex block, around which we close the loop from z to w and check the structured_singular_value with the augmented perturbation block","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Delta_a = beginbmatrix\nDelta  0\n0       Delta_p\nendbmatrix","category":"page"},{"location":"uncertainty/#Examples","page":"Uncertainty modeling","title":"Examples","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We repeat the first example here, but using MDelta formalism rather than direct Monte-Carlo modeling.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"When we call δc without any arguments, we get a symbolic (or structured) representation of the uncertainty rather than the sampled representation we got from calling δc(100).","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"a = 10\nP = ss([0 a; -a 0], I(2), [1 a; -a 1], 0)\nW0 = makeweight(0.2, (1,1), 2) |> ss\nW = I(2) + W0 .* uss([δc(), δc()]) # Create a diagonal complex uncertainty weighted in frequency by W0\nPs = P*W","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Ps is now represented as a upper linear fractional transform (upper LFT).","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We can draw samples from this uncertainty representation (sampling of Delta and closing the loop starprod(Δ, Ps)) like so","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Psamples = rand(Ps, 100)\nsigmaplot(Psamples, w)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We can extract the nominal model using","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"system_mapping(Ps)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"And obtain M and Delta when the loop is closed with K like this:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"lft(Ps, K).M","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Ps.Δ # Ps.delta also works","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We can evaluate the frequency response of M and calculate the structured singular value mu","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"M = freqresp(lft(Ps, -K).M, w) # -K to get negative feedback\nμ = structured_singular_value(M)\nplot(w, μ, xscale=:log10, title=\"Structured singular value μ\", xlabel=\"Frequency [rad/s]\", ylabel=\"μ\")","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"mu is very high, whenever mu  1, the system is not stable with respect to the modeled uncertainty. The tolerated uncertainty is only about dfrac1mu_infty","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"1/norm(μ, Inf)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"of the modeled uncertainty. Another way of calculating this value is","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"robstab(lft(Ps, -K))","category":"page"},{"location":"uncertainty/#Internals-of-the-M\\Delta-framework","page":"Uncertainty modeling","title":"Internals of the MDelta framework","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"TODO","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"[Skogestad]: Skogestad, \"Multivariable Feedback Control: Analysis and Design\"","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"[Doyle91]: Doyle, Packard, Zhou, \"Review of LFTs, LMIs and μ\". https://www.researchgate.net/publication/257200344_Review_of_LFTs_LMIs_and_mu","category":"page"},{"location":"uncertainty/#Uncertain-time-delays","page":"Uncertainty modeling","title":"Uncertain time delays","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Modeling uncertain time delays can be done in several ways, one approach is to make use of a multiplicative uncertainty weight created using neglected_delay multiplied by an uncertain element created using δc, example:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"using DisplayAs # hide\nusing RobustAndOptimalControl, ControlSystemsBase, MonteCarloMeasurements, Plots, LinearAlgebra\ngr(fmt=:png, size=(640,480)) # hide\na  = 10\nP  = ss([0 a; -a 0], I(2), [1 a; -a 1], 0) # Plant\nW0 = neglected_delay(0.005) |> ss # Weight\nW  = I(2) + W0 .* uss([δc(), δc()]) # Create a diagonal real uncertainty weighted in frequency by W0\nPs = P*W # Uncertain plant\nPsamples = rand(Ps, 1000) # Sample the uncertain plant for plotting\nw = exp10.(LinRange(-1, 3, 300)) # Frequency vector\nbodeplot(Psamples, w, legend=false, N=0, quantile=0)\nbodeplot!(P*[delay(0.005) tf(0); tf(0) delay(0.005)], w) # Compare to the plant with a model of the delay\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"We see that the uncertain model set includes the model with the delay. Note how this approximation approach imparts some uncertainty also in the gain.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"More details on this approach can be found in Skogestad sec. 7.4.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The other alternative is to use use sampled uncertain delays. The next example shows how we can create a system with an uncertain delay, where we know that the delay is an integer number of milliseconds between 1ms and 4ms.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"using RobustAndOptimalControl, ControlSystemsBase, MonteCarloMeasurements, Plots, LinearAlgebra\ngr(fmt=:png, size=(640,480)) # hide\nunsafe_comparisons(true)\nL = Particles(collect((1:4) ./ 1000)) # Uncertain time delay, an integer number of milliseconds between 1ms and 4ms\nP = delay(L)*tf(1, [0.01, 1])\nC = pid(2, 1)\nw = exp10.(-1:0.01:4)\nplot(\n     bodeplot(P, exp10.(-1:0.001:3), legend=false),\n     # plot(step(feedback(P, C), 0:0.0001:0.05), lab=\"L = \" .* string.(P.Tau[].particles'), title=\"Disturbance response\"), # This simulation requires using ControlSystems\n     nyquistplot(P*C, w[1:10:end], points=true, xlims=(-3.5, 2.5), ylims=(-5, 1.5), Ms_circles=[1.5, 2], alpha=1) # Note, the nyquistplot with uncertain coefficients requires manual selection of plot limits\n)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Notice how the gain is completely certain, while the phase starts becoming very uncertain for high frequencies.","category":"page"},{"location":"uncertainty/#Models-of-uncertain-dynamics","page":"Uncertainty modeling","title":"Models of uncertain dynamics","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This section goes through a number of uncertainty descriptions in block-diagram form and shows the equivalent transfer function appearing in feedback with the uncertain element. A common approach is to model an uncertain element as W(s)Delta where Delta leq 1 and W(s) is a frequency-dependent weighting function that is large for frequencies where the uncertainty is large. ","category":"page"},{"location":"uncertainty/#Additive-uncertainty","page":"Uncertainty modeling","title":"Additive uncertainty","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"          ┌────┐         ┌────┐\n        ┌►│ WΔ ├─┐    ┌─►│ WΔ ├──┐\n        │ └────┘ │    │  └────┘  │\n        │        │    │          │\n  ┌───┐ │  ┌───┐ ▼    │ ┌──────┐ │\n┌►│ C ├─┴─►│ P ├─+    │ │  C   │ │\n│ └───┘    └───┘ │    └─┤ ──── │◄┘\n│                │      │ I+PC │\n└────────────────┘      └──────┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The system is made robust with respect to this uncertainty by making","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"WdfracCI+PC  1","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"for all frequencies.","category":"page"},{"location":"uncertainty/#Multiplicative-uncertainty","page":"Uncertainty modeling","title":"Multiplicative uncertainty","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"At the process output","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"                  ┌────┐          ┌────┐\n                ┌►│ WΔ ├┐      ┌─►│ WΔ ├──┐\n                │ └────┘│      │  └────┘  │\n  ┌───┐   ┌───┐ │       ▼      │          │\n┌►│ C ├──►│ P ├─┴───────+─►    │ ┌──────┐ │\n│ └───┘   └───┘         │      │ │  PC  │ │\n│                       │      └─┤ ──── │◄┘\n└───────────────────────┘        │ I+PC │\n                                 └──────┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The system is made robust with respect to this uncertainty by making the complimentary sensitivity function T satisfy","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"WdfracPCI+PC = WT  1","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"for all frequencies.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This means that we must make the transfer function T small for frequencies where the relative uncertainty is large. The relative uncertainty is always > 1 for sufficiently large frequencies, and this gives rise to the common adage of \"apply lowpass filtering to avoid exciting higher-order dynamics at high frequencies\".","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This uncertainty representation was used in the examples above where we spoke about multiplicative uncertainty. For MIMO systems, uncertainty appearing on the plant input may behave different than if it appears on the plant output. In general, the loop-transfer function L_o = PC denotes the output loop-transfer function (the loop is broken at the output of the plant) and L_i = CP denotes the input loop-transfer function (the loop is broken at the input of the plant). For multiplicative uncertainty at the plant input, the corresponding transfer function to be constrained is","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"dfracCPI+CPW_i = TW_i  1","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"with corresponding diagram","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"          ┌───┐                  ┌────┐\n        ┌►│ ΔW├─┐             ┌─►│ ΔW ├───┐\n        │ └───┘ │             │  └────┘   │\n        │       │             │           │\n  ┌───┐ │       ▼  ┌───┐      │ ┌──────┐  │\n┌►│ C ├─┴─────────►│ P ├─┐    │ │  CP  │  │\n│ └───┘            └───┘ │    └─┤ ──── │◄─┘\n│                        │      │ I+CP │\n└────────────────────────┘      └──────┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The input version represents uncertainty in the actuator, and is a particularly attractive object for analysis of SIMO systems, where this transfer function is SISO.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Skogestad and Postlethwaite Sec. 7.5.1","category":"page"},{"location":"uncertainty/#Example","page":"Uncertainty modeling","title":"Example","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"See the example with Uncertain time delays above.","category":"page"},{"location":"uncertainty/#Additive-feedback-uncertainty","page":"Uncertainty modeling","title":"Additive feedback uncertainty","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"          ┌────┐        ┌────┐\n        ┌─┤ WΔ │◄┐   ┌─►│ WΔ ├──┐\n        │ └────┘ │   │  └────┘  │\n        │        │   │          │\n  ┌───┐ ▼  ┌───┐ │   │ ┌──────┐ │\n┌►│ C ├─+─►│ P ├─┤   │ │  P   │ │\n│ └───┘    └───┘ │   └─┤ ──── │◄┘\n│                │     │ I+PC │\n└────────────────┘     └──────┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The system is made robust with respect to this uncertainty by making","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"WdfracPI+PC  1","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"for all frequencies.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This kind of uncertainty can represent uncertainty regarding presence of feedback loops, and uncertainty regarding the implementation of the controller (this uncertainty is equivalent to additive uncertainty in the controller).","category":"page"},{"location":"uncertainty/#Multiplicative-feedback-uncertainty","page":"Uncertainty modeling","title":"Multiplicative feedback uncertainty","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"At the process output","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"                 ┌────┐           ┌────┐\n                ┌┤ WΔ │◄┐      ┌─►│ WΔ ├──┐\n                │└────┘ │      │  └────┘  │\n  ┌───┐   ┌───┐ ▼       │      │          │\n┌►│ C ├──►│ P ├─+───────┼─►    │ ┌──────┐ │\n│ └───┘   └───┘         │      │ │  I   │ │\n│                       │      └─┤ ──── │◄┘\n└───────────────────────┘        │ I+PC │\n                                 └──────┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The system is made robust with respect to this uncertainty by making the (output) sensitivity function S satisfy","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"WdfracII+PC = WS  1","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"for all frequencies.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"This kind of uncertainty can represent uncertainty regarding which half plane poles are located. For frequencies where W is larger than 1, poles can move from the left to the right half plane, and we thus need to make S small (use lots of feedback) for those frequencies.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"At the process input:","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"          ┌────┐                  ┌───┐\n        ┌─┤ WΔ │◄┐             ┌─►│ WΔ├───┐\n        │ └────┘ │             │  └───┘   │\n        │        │             │          │\n  ┌───┐ ▼        │  ┌───┐      │ ┌──────┐ │\n┌►│ C ├─+────────┴─►│ P ├┐     │ │  I   │ │\n│ └───┘             └───┘│     └─┤ ──── │◄┘\n│                        │       │ I+CP │\n└────────────────────────┘       └──────┘","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"The system is made robust with respect to this uncertainty by making the (input) sensitivity function S_i satisfy","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"dfracII+CP W = S_i W  1","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"for all frequencies.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Skogestad and Postlethwaite Sec. 7.5.3","category":"page"},{"location":"uncertainty/#Uncertainty-through-disturbances","page":"Uncertainty modeling","title":"Uncertainty through disturbances","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Uncertainty can of course also be modeled as disturbances acting on the system. Similar to above, we may model disturbances as a signal that has L_2 norm less than 1, scaled by a weight W(s). Additive, norm-bounded disturbances can never make a stable linear system unstable, the uncertainty does not appear *in the loop. The analysis of such disturbances can thus be focused on making the transfer function from the disturbance to the performance output small. ","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Some convenient facts when working with disturbances are that the H_infty norm of a transfer function e = G_edd is equal to the worst-case gain in L_2 norm of signals","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"G_ed_infty = sup_d dfrace_2d_2","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"and that the H_2 norm is equal to the gain in variance","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"sigma_e^2 = G_ed_2 sigma_d^2","category":"page"},{"location":"uncertainty/#Visualizing-uncertainty","page":"Uncertainty modeling","title":"Visualizing uncertainty","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"For any of the uncertainty descriptions above, we may plot the total loop gain excluding the uncertain element Delta, that is, the weight W(s) multiplied by the equivalent transfer function of the nominal part of the loop. For example, for multiplicative uncertainty at the plant output, we would plot WT in a sigmaplot and verify that all singular values are smaller than 1 for all frequencies. Alternatively, for SISO systems, we may plot T and W^-1 in a Bode plot and verify that T  W^-1 for all frequencies. This latter visualization usually provides better intuition.","category":"page"},{"location":"uncertainty/#Example:-Bode-plot","page":"Uncertainty modeling","title":"Example: Bode plot","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Below, we perform this procedure for an multiplicative (relative) uncertainty model at the plant output. The uncertainty weight W(s) is chosen to give 10% uncertainty at low frequencies and 10x uncertainty at high frequencies, indicating that we are absolutely oblivious to the behavior of the plant at high frequencies. This is often the case, either because identification experiments did not contain excitation for high frequencies, or because the plant had nonlinear behavior at higher frequencies.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"using DisplayAs # hide\nusing ControlSystemsBase, RobustAndOptimalControl, Plots\ngr(fmt=:png, size=(640,480)) # hide\nP = tf(1, [1, 2, 1]) # Plant model\nC = pid(19.5, 0)      # Controller\nW = makeweight(0.1, 10, 10) # Low uncertainty (0.1) at low frequencies, large (10) at high frequencies.\nbodeplot([comp_sensitivity(P, C), inv(W)], lab=[\"\\$S\\$\" \"\\$W^{-1}\\$\"], linestyle=[:solid :dash], plotphase=false)","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"As long as the complimentary sensitivity function T(s) stays below the inverse weight W^-1(s), the closed-loop system is robust with respect to the modeled uncertainty.","category":"page"},{"location":"uncertainty/#Example:-Nyquist-plot","page":"Uncertainty modeling","title":"Example: Nyquist plot","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Continuing from the Bode-plot example above, we can translate the multiplicative weight W(s) to a set of circles we could plot in the Nyquist diagram, one for each frequency, that covers the true open-loop system. For sampled representations of uncertainty, this is done using fit_complex_perturbations, but here, we do it manually. For a given frequency omega, the radius of the circle for an additive uncertainty in the loop gain is given by W(iomega), and for a multiplicative (relative) uncertainty, it is scaled by the loop gain W(iomega) P(iomega) C(iomega).[circ] The center of the circle is simply given by the nominal value of the loop-gain P(iomega)C(iomega).","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"w = exp10.(LinRange(-2, 2, 200))\ncenters = freqrespv(P*C, w)\nradii = abs.(freqrespv(W*P*C, w))\nnyquistplot(P*C, w, xlims=(-4,0.1), ylims=(-4,0.1))\nnyquistcircles!(w, centers, radii)\nDisplayAs.PNG(Plots.current()) # hide","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"If the plots above are created using the plotly() backend, each circle is associated with hover information that is accessible by hovering the mouse over the plot. This indicates that the circle that touches the critical point is the one at omega approx 45, which coincides exactly with the point at thich the Bode plot above touches the inverse weightW^-1.","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"[circ]: A relative uncertainty does not apply to P only, it appears after P and thus models the relative uncertainty in the entire loop gain PC.","category":"page"},{"location":"uncertainty/#Converting-between-uncertainty-descriptions","page":"Uncertainty modeling","title":"Converting between uncertainty descriptions","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Any of the representations above, if modeled using uncertainty elements (UncertainSS, δc, δr), may be converted to a sampled uncertainty representation using rand(P_uncertain, 100). The sampled representation can be further converted using fit_complex_perturbations which results in a set of circles, additive or multiplicative (relative), one for each frequency considered, that covers the true system. These can be plotted in a Nyquist diagram using nyquistcircles (see Example: Nyquist plot above).","category":"page"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"A sampled representation can also be converted to a nominal value and a maximum nu-gap, see Model-order reduction for uncertain models for an example of this","category":"page"},{"location":"uncertainty/#More-references","page":"Uncertainty modeling","title":"More references","text":"","category":"section"},{"location":"uncertainty/","page":"Uncertainty modeling","title":"Uncertainty modeling","text":"Skogestad Sec. 8.5.3 contains result for moving uncertainty descriptions between input and output for MIMO systems as well as some additional forms of uncertainty descriptions, with robust stability conditions listed in Sec. 8.6.1.","category":"page"},{"location":"api/#Exported-functions-and-types","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Docstrings","page":"API","title":"Docstrings","text":"","category":"section"},{"location":"api/#RobustAndOptimalControl.Disk","page":"API","title":"RobustAndOptimalControl.Disk","text":"Disk\n\nRepresents a perturbation disc in the complex plane. Disk(0.5, 2) represents all perturbations in the circle centered at 1.25 with radius 0.75, or in other words, a gain margin of 2 and a phase margin of 36.9 degrees.\n\nA disk can be converted to a Nyquist exclusion disk by nyquist(disk) and plotted using plot(disk).\n\nArguments:\n\nγmin: Lower intercept\nγmax: Upper intercept\nc: Center\nr: Radius\nϕm: Angle of tangent line through origin.\n\nIf γmax < γmin the disk is inverted. See diskmargin for disk margin computations. \n\n\n\n\n\n","category":"type"},{"location":"api/#RobustAndOptimalControl.Diskmargin","page":"API","title":"RobustAndOptimalControl.Diskmargin","text":"Diskmargin\n\nThe notation follows \"An Introduction to Disk Margins\", Peter Seiler, Andrew Packard, and Pascal Gahinet\n\nFields:\n\nα: The disk margin ω0: The worst-case frequency f0: The destabilizing perturbation f0 is a complex number with simultaneous gain and phase variation. This critical perturbation causes an instability with closed-loop pole on the imaginary axis at the critical frequency ω0  δ0: The uncertain element generating f0. γmin: The lower real-axis intercept of the disk (analogous to classical lower gain margin). γmax: The upper real-axis intercept of the disk (analogous to classical upper gain margin). ϕm: is analogous to the classical phase margin. σ: The skew parameter that was used to calculate the margin\n\nNote, γmax and ϕm are in smaller than the classical gain and phase margins sicne the classical margins do not consider simultaneous perturbations in gain and phase. \n\nThe \"disk\" margin becomes a half plane for α = 2 and an inverted circle for α > 2. In this case, the upper gain margin is infinite. See the paper for more details, in particular figure 6.\n\n\n\n\n\n","category":"type"},{"location":"api/#RobustAndOptimalControl.ExtendedStateSpace","page":"API","title":"RobustAndOptimalControl.ExtendedStateSpace","text":"ExtendedStateSpace{TE, T} <: AbstractStateSpace{TE}\n\nA type that represents the two-input, two-output system\n\nz  ┌─────┐  w\n◄──┤     │◄──\n   │  P  │\n◄──┤     │◄──\ny  └─────┘  u\n\nwhere\n\nz denotes controlled outputs (sometimes called performance outputs)\ny denotes measured outputs\nw denotes external inputs, such as disturbances or references\nu denotes control inputs\n\nThe call lft(P, K) forms the (lower) linear fractional transform \n\nz  ┌─────┐  w\n◄──┤     │◄──\n   │  P  │\n┌──┤     │◄─┐\n│y └─────┘ u│\n│           │\n│  ┌─────┐  │\n│  │     │  │\n└─►│  K  ├──┘\n   │     │\n   └─────┘\n\ni.e., closing the lower loop around K.\n\nAn ExtendedStateSpace can be converted to a standard StateSpace by ss(P), this will keep all inputs and outputs, effectively removing the partitioning only.\n\nWhen feedback is called on this type, defaults are automatically set for the feedback indices. Other functions defined for this type include\n\nsystem_mapping\nperformance_mapping\nnoise_mapping\nlft\nfeedback has special overloads that sets defaults connections for ExtendedStateSpace.\n\nand the following design functions expect ExtendedStateSpace as inputs\n\nhinfsynthesize\nh2synthesize\nLQGProblem (also accepts other types)\n\nA video tutorial on how to use this type is available here.\n\n\n\n\n\n","category":"type"},{"location":"api/#RobustAndOptimalControl.ExtendedStateSpace-Tuple{AbstractStateSpace}","page":"API","title":"RobustAndOptimalControl.ExtendedStateSpace","text":"se = ExtendedStateSpace(s::AbstractStateSpace; kwargs...)\n\nThe conversion from a regular statespace object to an ExtendedStateSpace creates the following system by default\n\nbeginbmatrix\n    A  B  B \n    C  D  D \n    C  D  D\nendbmatrix\n\ni.e., the system and performance mappings are identical, system_mapping(se) == performance_mapping(se) == s. However, all matrices B1, B2, C1, C2; D11, D12, D21, D22 are overridable by a corresponding keyword argument. In this case, the controlled outputs are the same as measured outputs.\n\nRelated: se = convert(ExtendedStateSpace, s::StateSpace) produces an ExtendedStateSpace with empty performance_mapping from w->z such that ss(se) == s.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.ExtendedStateSpace-Tuple{ExtendedStateSpace}","page":"API","title":"RobustAndOptimalControl.ExtendedStateSpace","text":"ExtendedStateSpace(s::ExtendedStateSpace; A, B1, B2, C1, C2, D11, D12, D21, D22, kwargs...)\n\nCreate an ExtendedStateSpace from an existing one, with the option to override the matrices.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.LQGProblem","page":"API","title":"RobustAndOptimalControl.LQGProblem","text":"G = LQGProblem(sys::ExtendedStateSpace, Q1, Q2, R1, R2; qQ=0, qR=0, SQ=nothing, SR=nothing)\n\nReturn an LQG object that describes the closed control loop around the process sys=ss(A,B,C,D) where the controller is of LQG-type. The controller is specified by weight matrices Q1,Q2 that penalizes state deviations and control signal variance respectively, and covariance matrices R1,R2 which specify state drift and measurement covariance respectively.\n\nsys is an extended statespace object where the upper channel corresponds to disturbances to performance variables (w→z), and the lower channel corresponds to inputs to outputs (u→y), such that lft(sys, K) forms the closed-loop transfer function from external inputs/disturbances to performance variables. \n\nqQ and qR can be set to incorporate loop-transfer recovery, i.e.,\n\nL = lqr(A, B, Q1+qQ*C'C, Q2)\nK = kalman(A, C, R1+qR*B*B', R2)\n\nIncreasing qQ will add more cost in output direction, e.g., encouraging the use of cheap control, while increasing qR adds fictious dynamics noise, makes the observer faster in the direction we control.\n\nExample\n\nIn this example we will control a MIMO system with one unstable pole and one unstable zero. When the system has both unstable zeros and poles, there are fundamental limitations on performance. The unstable zero is in this case faster than the unstable pole, so the system is controllable. For good performance, we want as large separation between the unstable zero dynamics and the unstable poles as possible. \n\ns = tf(\"s\")\nP = [1/(s+1) 2/(s+2); 1/(s+3) 1/(s-1)]\nsys = ExtendedStateSpace(ss(P)) # Controlled outputs same as measured outputs and state noise affects at inputs only. \neye(n) = Matrix{Float64}(I,n,n) # For convinience\n\nqQ = 0\nqR = 0\nQ1 = 10eye(2)\nQ2 = 1eye(2)\nR1 = 1eye(2)\nR2 = 1eye(2)\n\nG = LQGProblem(sys, Q1, Q2, R1, R2, qQ=qQ, qR=qR)\n\nT = comp_sensitivity(G)\nS = sensitivity(G)\nGcl = closedloop(G)*static_gain_compensation(G)\nplot(\n    sigmaplot([S,T, Gcl],exp10.(range(-3, stop=3, length=1000)), lab=[\"S\" \"T\" \"Gry\"]),\n    plot(step(Gcl, 5))\n)\n\nExtended help\n\nSeveral functions are defined for instances of LQGProblem\n\nclosedloop\nextended_controller\nff_controller\ngangoffour\nG_CS\nG_PS\ninput_comp_sensitivity\ninput_sensitivity\noutput_comp_sensitivity\noutput_sensitivity\nsystem_mapping\nperformance_mapping\nstatic_gain_compensation\ngangoffourplot\nkalman\nlft\nlqr\nobserver_controller\n\nA video tutorial on how to use the LQG interface is available here\n\nIntroduction of references\n\nThe most principled way of introducing references is to add references as measured inputs to the extended statespace model, and to let the performance output z be the differences between the references and the outputs for which references are provided. \n\nA less cumbersome way is not not consider references when constructing the LQGProblem, and instead pass the z keyword arugment to extended_controller in order to obtain a closed-loop system from state references to controlled outputs, and use some form of inverse of the DC gain of this system (or one of its subsystems) to pre-compensate the reference input.\n\n\n\n\n\n","category":"type"},{"location":"api/#RobustAndOptimalControl.LQGProblem-Tuple{ExtendedStateSpace}","page":"API","title":"RobustAndOptimalControl.LQGProblem","text":"LQGProblem(P::ExtendedStateSpace)\n\nIf only an ExtendedStateSpace system is provided, e.g. from hinfpartition, the system P is assumed to correspond to the H₂ optimal control problem with\n\nC1'C1    = Q1\nD12'D12  = Q2\nSQ       = C1'D12 # Cross term\n\nB1*B1'   = R1\nD21*D21' = R2\nSR       = B1*D21' # Cross term\n\nand an LQGProblem with the above covariance matrices is returned. The system description in the returned LQGProblem will have B1 = C1 = I. See Ch. 14 in Robust and optimal control for reference. \n\nExample:\n\nAll the following ways of obtaining the H2 optimal controller are (almost) equivalent\n\nusing Test\nG = ss(tf(1, [10, 1]))\nWS = tf(1, [1, 1e-6]) \nWU = makeweight(1e-2, 0.1, 100) \nGd = hinfpartition(G, WS, WU, [])\n\nK, Gcl = h2synthesize(Gd)              # First option, using H2 formulas\nK2, Gcl2 = h2synthesize(Gd, 1000)      # Second option, using H∞ formulas with large γ\n\nlqg = LQGProblem(Gd)                   # Third option, convert to an LQGProblem and obtain controller\nK3 = -observer_controller(lqg)\n\n@test h2norm(lft(Gd, K )) ≈ 3.0568 atol=1e-3\n@test h2norm(lft(Gd, K2)) ≈ 3.0568 atol=1e-3\n@test h2norm(lft(Gd, K3)) ≈ 3.0568 atol=1e-3\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.NamedStateSpace","page":"API","title":"RobustAndOptimalControl.NamedStateSpace","text":"See named_ss for a convenient constructor.\n\n\n\n\n\n","category":"type"},{"location":"api/#RobustAndOptimalControl.UncertainSS","page":"API","title":"RobustAndOptimalControl.UncertainSS","text":"UncertainSS{TE} <: AbstractStateSpace{TE}\n\nRepresents LFT_u(M, Diagonal(Δ))\n\n\n\n\n\n","category":"type"},{"location":"api/#RobustAndOptimalControl.nyquistcircles","page":"API","title":"RobustAndOptimalControl.nyquistcircles","text":"nyquistcircles(w, centers, radii)\n\nPlot the nyquist curve with circles. It only makes sense to call this function if the circles represent additive uncertainty, i.e., were calculated with relative=false.\n\nSee also fit_complex_perturbations\n\n\n\n\n\n","category":"type"},{"location":"api/#RobustAndOptimalControl.δ","page":"API","title":"RobustAndOptimalControl.δ","text":"δ(N=32)\n\nCreate an uncertain element of N uniformly distributed samples ∈ [-1, 1]\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemsBase.G_CS-Tuple{LQGProblem}","page":"API","title":"ControlSystemsBase.G_CS","text":"G_CS(l::LQGProblem)\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemsBase.G_PS-Tuple{LQGProblem}","page":"API","title":"ControlSystemsBase.G_PS","text":"G_PS(l::LQGProblem)\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemsBase.input_comp_sensitivity-Tuple{LQGProblem}","page":"API","title":"ControlSystemsBase.input_comp_sensitivity","text":"input_comp_sensitivity(l::LQGProblem)\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemsBase.input_sensitivity-Tuple{LQGProblem}","page":"API","title":"ControlSystemsBase.input_sensitivity","text":"input_sensitivity(l::LQGProblem)\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemsBase.output_comp_sensitivity-Tuple{LQGProblem}","page":"API","title":"ControlSystemsBase.output_comp_sensitivity","text":"output_comp_sensitivity(l::LQGProblem)\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemsBase.output_sensitivity-Tuple{LQGProblem}","page":"API","title":"ControlSystemsBase.output_sensitivity","text":"output_sensitivity(l::LQGProblem)\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemsBase.ss","page":"API","title":"ControlSystemsBase.ss","text":"ss(A, B1, B2, C1, C2, D11, D12, D21, D22 [, Ts])\n\nCreate an ExtendedStateSpace.\n\n\n\n\n\n","category":"function"},{"location":"api/#DescriptorSystems.dss-Tuple{AbstractStateSpace}","page":"API","title":"DescriptorSystems.dss","text":"DescriptorSystems.dss(sys::AbstractStateSpace)\n\nConvert sys to a descriptor statespace system from DescriptorSystems.jl\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.add_disturbance-Tuple{AbstractStateSpace, AbstractMatrix, AbstractMatrix}","page":"API","title":"RobustAndOptimalControl.add_disturbance","text":"add_disturbance(sys::StateSpace, Ad::Matrix, Cd::Matrix)\n\nSee CCS pp. 144\n\nArguments:\n\nsys: System to augment\nAd: The dynamics of the disturbance\nCd: How the disturbance states affect the states of sys. This matrix has the shape (sys.nx, size(Ad, 1))\n\nSee also add_low_frequency_disturbance, add_resonant_disturbance\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.add_input_differentiator","page":"API","title":"RobustAndOptimalControl.add_input_differentiator","text":"add_input_differentiator(sys::StateSpace, ui = 1:sys.nu; goodwin=false)\n\nAugment the output of sys with the difference u(k+1)-u(k)\n\nArguments:\n\nui: An index or vector of indices indicating which inputs to differentiate.\ngoodwin: If true, the difference operator will use the Goodwin δ operator, i.e., (u(k+1)-u(k)) / sys.Ts.\n\nThe augmented system will have the matrices\n\n[A 0; 0 0]  [B; I]  [C 0; 0 -I]  [D; I]\n\nwith length(ui) added states and outputs.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.add_input_integrator","page":"API","title":"RobustAndOptimalControl.add_input_integrator","text":"add_input_integrator(sys::StateSpace, ui = 1, ϵ = 0)\n\nAugment the output of sys with the integral of input at index ui, i.e.,  y_aug = [y; ∫u[ui]] See also add_low_frequency_disturbance\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.add_low_frequency_disturbance","page":"API","title":"RobustAndOptimalControl.add_low_frequency_disturbance","text":"add_low_frequency_disturbance(sys::StateSpace; ϵ = 0, measurement = false)\nadd_low_frequency_disturbance(sys::StateSpace, Cd; ϵ = 0, measurement = false)\n\nAugment sys with a low-frequency (integrating if ϵ=0) disturbance model. If an integrating input disturbance is used together with an observer, the controller will have integral action.\n\nCd: If adding an input disturbance. this matrix indicates how the disturbance states affect the states of sys, and defaults to sys.B. If measurement=true, this matrix indicates how the disturbance states affect the outputs of sys, and defaults to I(sys.ny).\n\nArguments:\n\nϵ: Move the integrator pole ϵ into the stable region.\nmeasurement: If true, the disturbance is a measurement disturbance, otherwise it's an input diturbance. \n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.add_low_frequency_disturbance-Tuple{AbstractStateSpace, Integer}","page":"API","title":"RobustAndOptimalControl.add_low_frequency_disturbance","text":"add_low_frequency_disturbance(sys::StateSpace, Ai::Integer; ϵ = 0)\n\nA disturbance affecting only state Ai.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.add_measurement_disturbance-Tuple{AbstractStateSpace, AbstractMatrix, AbstractMatrix}","page":"API","title":"RobustAndOptimalControl.add_measurement_disturbance","text":"add_measurement_disturbance(sys::StateSpace{Continuous}, Ad::Matrix, Cd::Matrix)\n\nCreate the system\n\nAe = [A 0; 0 Ad]\nBe = [B; 0]\nCe = [C Cd]\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.add_output_differentiator","page":"API","title":"RobustAndOptimalControl.add_output_differentiator","text":"add_differentiator(sys::StateSpace{<:Discrete})\n\nAugment the output of sys with the numerical difference (discrete-time derivative) of output, i.e., y_aug = [y; (y-y_prev)/sys.Ts] To add both an integrator and a differentiator to a SISO system, use\n\nGd = add_output_integrator(add_output_differentiator(G), 1)\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.add_output_integrator","page":"API","title":"RobustAndOptimalControl.add_output_integrator","text":"add_output_integrator(sys::StateSpace{<:Discrete}, ind = 1; ϵ = 0)\n\nAugment the output of sys with the integral of output at index ind, i.e.,  y_aug = [y; ∫y[ind]] To add both an integrator and a differentiator to a SISO system, use\n\nGd = add_output_integrator(add_output_differentiator(G), 1)\n\nNote: numerical integration is subject to numerical drift. If the output of the system corresponds to, e.g., a velocity reference and the integral to position reference, consider methods for mitigating this drift.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.add_resonant_disturbance-Tuple{AbstractStateSpace, Any, Any, AbstractArray}","page":"API","title":"RobustAndOptimalControl.add_resonant_disturbance","text":"add_resonant_disturbance(sys::AbstractStateSpace, ω, ζ, Bd::AbstractArray)\n\nBd: The disturbance input matrix.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.add_resonant_disturbance-Tuple{AbstractStateSpace, Any, Any, Integer}","page":"API","title":"RobustAndOptimalControl.add_resonant_disturbance","text":"add_resonant_disturbance(sys::StateSpace{Continuous}, ω, ζ, Ai::Int; measurement = false)\n\nAugment sys with a resonant disturbance model.\n\nArguments:\n\nω: Frequency\nζ: Relative damping.\nAi: The affected state\nmeasurement: If true, the disturbace is acting on the output, this will cause the controller to have zeros at ω (roots of poly s² + 2ζωs + ω²). If false, the disturbance is acting on the input, this will cause the controller to have poles at ω (roots of poly s² + 2ζωs + ω²).\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.baltrunc2-Tuple{LTISystem}","page":"API","title":"RobustAndOptimalControl.baltrunc2","text":"sysr, hs = baltrunc2(sys::LTISystem; residual=false, n=missing, kwargs...)\n\nCompute the a balanced truncation of order n and the hankel singular values\n\nFor keyword arguments, see the docstring of DescriptorSystems.gbalmr, reproduced below Base.Docs.DocStr(svec(\"    gbalmr(sys, balance = false, matchdc = false, ord = missing, offset = √ϵ,\\n           atolhsv = 0, rtolhsv = nϵ, atolmin = atolhsv, rtolmin = rtolhsv, \\n           atol = 0, atol1 = atol, atol2 = atol, rtol, fast = true) -> (sysr, hs)\\n\\nCompute for a proper and stable descriptor system sys = (A-λE,B,C,D) with the transfer function\\nmatrix G(λ), a reduced order realization sysr = (Ar-λEr,Br,Cr,Dr) and the vector hs of decreasingly \\nordered Hankel singular values of the system sys. If balance = true, a balancing-based approach\\nis used to determine a reduced order minimal realization \\nof the form sysr = (Ar-λI,Br,Cr,Dr). For a continuous-time system sys, the resulting realization sysr\\nis balanced, i.e., the controllability and observability grammians are equal and diagonal. \\nIf additonally matchdc = true, the resulting sysr is computed using state rezidualization formulas \\n(also known as singular perturbation approximation) which additionally preserves the DC-gain of sys. \\nIn this case, the resulting realization sysr is balanced (for both continuous- and discrete-time systems).\\nIf balance = false, an enhanced accuracy balancing-free approach is used to determine the \\nreduced order system sysr. \\n\\nIf ord = nr, the resulting order of sysr is min(nr,nrmin), where nrmin is the order of a minimal  \\nrealization of sys determined as the number of Hankel singular values exceeding max(atolmin,rtolmin*HN), with\\nHN, the Hankel norm of G(λ). If ord = missing, the resulting order is chosen as the number of Hankel \\nsingular values exceeding max(atolhsv,rtolhsv*HN). \\n\\nTo check the stability of the eigenvalues of the pencil A-λE, the real parts of eigenvalues must be less than -β\\nfor a continuous-time system or \\nthe moduli of eigenvalues must be less than 1-β for a discrete-time system, where β is the stability domain boundary offset.  \\nThe offset  β to be used can be specified via the keyword parameter offset = β. \\nThe default value used for β is sqrt(ϵ), where ϵ is the working machine precision. \\n\\nThe keyword arguments atol1, atol2, and rtol, specify, respectively, \\nthe absolute tolerance for the nonzero elements of A, B, C, D,  \\nthe absolute tolerance for the nonzero elements of E,  \\nand the relative tolerance for the nonzero elements of A, B, C, D and E.  \\nThe default relative tolerance is nϵ, where ϵ is the working machine epsilon \\nand n is the order of the system sys. The keyword argument atol can be used \\nto simultaneously set atol1 = atol and atol2 = atol. \\n\\nIf E is singular, the uncontrollable infinite eigenvalues of the pair (A,E) and\\nthe non-dynamic modes are elliminated using minimal realization techniques.\\nThe rank determinations in the performed reductions\\nare based on rank revealing QR-decompositions with column pivoting \\nif fast = true or the more reliable SVD-decompositions if fast = false. \\n\\nMethod:  For the order reduction of a standard system, the balancing-free method of [1] or \\nthe balancing-based method of [2] are used. For a descriptor system the balancing related order reduction \\nmethods of [3] are used. To preserve the DC-gain of the original system, the singular perturbation \\napproximation method of [4] is used in conjunction with the balancing-based or balancing-free\\napproach of [5]. \\n\\nReferences\\n\\n[1] A. Varga. \\n    Efficient minimal realization procedure based on balancing.\\n    In A. El Moudni, P. Borne, and S.G. Tzafestas (Eds.), \\n    Prepr. of the IMACS Symp. on Modelling and Control of Technological \\n    Systems, Lille, France, vol. 2, pp.42-47, 1991.\\n\\n[2] M. S. Tombs and I. Postlethwaite. \\n    Truncated balanced realization of a stable non-minimal state-space \\n    system. Int. J. Control, vol. 46, pp. 1319–1330, 1987.\\n\\n[3] T. Stykel. \\n    Gramian based model reduction for descriptor systems. \\n    Mathematics of Control, Signals, and Systems, 16:297–319, 2004.\\n\\n[4] Y. Liu Y. and B.D.O. Anderson \\n    Singular Perturbation Approximation of Balanced Systems,\\n    Int. J. Control, Vol. 50, pp. 1379-1405, 1989.\\n\\n[5] Varga A.\\n    Balancing-free square-root algorithm for computing singular perturbation approximations.\\n    Proc. 30-th IEEE CDC,  Brighton, Dec. 11-13, 1991, Vol. 2, pp. 1062-1065.\\n\"), nothing, Dict{Symbol, Any}(:typesig => Union{Tuple{DescriptorSystems.DescriptorStateSpace{T, ET, MT} where {ET<:Union{LinearAlgebra.UniformScaling{Bool}, AbstractMatrix{T}}, MT<:AbstractMatrix{T}}}, Tuple{T}} where T, :module => DescriptorSystems, :linenumber => 461, :binding => DescriptorSystems.gbalmr, :path => \"/home/runner/.julia/packages/DescriptorSystems/7S3aT/src/order_reduction.jl\"))\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.baltrunc_coprime-Union{Tuple{Any}, Tuple{F}, Tuple{Any, Any}} where F","page":"API","title":"RobustAndOptimalControl.baltrunc_coprime","text":"sysr, hs, info = baltrunc_coprime(sys; residual = false, n = missing, factorization::F = DescriptorSystems.gnlcf, kwargs...)\n\nCompute a balanced truncation of the left coprime factorization of sys. See baltrunc2 for additional keyword-argument help.\n\nCoprime-factor reduction performs a coprime factorization of the model into P(s) = M(s)^-1N(s) where M and N are stable factors even if P contains unstable modes. After this, the system NM = beginbmatrixN  M endbmatrix is reduced using balanced truncation and the final reduced-order model is formed as P_r(s) = M_r(s)^-1N_r(s). For this method, the Hankel signular values of NM are reported and the reported errors are NM - N_rM_r_infty. This method is of particular interest in closed-loop situations, where a model-reduction error NM - N_rM_r_infty no greater than the normalized-coprime margin of the plant and the controller, guaratees that the closed loop remains stable when either P or K are reduced. The normalized-coprime margin can be computed with ncfmargin(P, K) (ncfmargin).\n\nArguments:\n\nfactorization: The function to perform the coprime factorization. A non-normalized factorization may be used by passing RobustAndOptimalControl.DescriptorSystems.glcf.\nkwargs: Are passed to DescriptorSystems.gbalmr, the docstring of which is reproduced below:\n\nBase.Docs.DocStr(svec(\"    gbalmr(sys, balance = false, matchdc = false, ord = missing, offset = √ϵ,\\n           atolhsv = 0, rtolhsv = nϵ, atolmin = atolhsv, rtolmin = rtolhsv, \\n           atol = 0, atol1 = atol, atol2 = atol, rtol, fast = true) -> (sysr, hs)\\n\\nCompute for a proper and stable descriptor system sys = (A-λE,B,C,D) with the transfer function\\nmatrix G(λ), a reduced order realization sysr = (Ar-λEr,Br,Cr,Dr) and the vector hs of decreasingly \\nordered Hankel singular values of the system sys. If balance = true, a balancing-based approach\\nis used to determine a reduced order minimal realization \\nof the form sysr = (Ar-λI,Br,Cr,Dr). For a continuous-time system sys, the resulting realization sysr\\nis balanced, i.e., the controllability and observability grammians are equal and diagonal. \\nIf additonally matchdc = true, the resulting sysr is computed using state rezidualization formulas \\n(also known as singular perturbation approximation) which additionally preserves the DC-gain of sys. \\nIn this case, the resulting realization sysr is balanced (for both continuous- and discrete-time systems).\\nIf balance = false, an enhanced accuracy balancing-free approach is used to determine the \\nreduced order system sysr. \\n\\nIf ord = nr, the resulting order of sysr is min(nr,nrmin), where nrmin is the order of a minimal  \\nrealization of sys determined as the number of Hankel singular values exceeding max(atolmin,rtolmin*HN), with\\nHN, the Hankel norm of G(λ). If ord = missing, the resulting order is chosen as the number of Hankel \\nsingular values exceeding max(atolhsv,rtolhsv*HN). \\n\\nTo check the stability of the eigenvalues of the pencil A-λE, the real parts of eigenvalues must be less than -β\\nfor a continuous-time system or \\nthe moduli of eigenvalues must be less than 1-β for a discrete-time system, where β is the stability domain boundary offset.  \\nThe offset  β to be used can be specified via the keyword parameter offset = β. \\nThe default value used for β is sqrt(ϵ), where ϵ is the working machine precision. \\n\\nThe keyword arguments atol1, atol2, and rtol, specify, respectively, \\nthe absolute tolerance for the nonzero elements of A, B, C, D,  \\nthe absolute tolerance for the nonzero elements of E,  \\nand the relative tolerance for the nonzero elements of A, B, C, D and E.  \\nThe default relative tolerance is nϵ, where ϵ is the working machine epsilon \\nand n is the order of the system sys. The keyword argument atol can be used \\nto simultaneously set atol1 = atol and atol2 = atol. \\n\\nIf E is singular, the uncontrollable infinite eigenvalues of the pair (A,E) and\\nthe non-dynamic modes are elliminated using minimal realization techniques.\\nThe rank determinations in the performed reductions\\nare based on rank revealing QR-decompositions with column pivoting \\nif fast = true or the more reliable SVD-decompositions if fast = false. \\n\\nMethod:  For the order reduction of a standard system, the balancing-free method of [1] or \\nthe balancing-based method of [2] are used. For a descriptor system the balancing related order reduction \\nmethods of [3] are used. To preserve the DC-gain of the original system, the singular perturbation \\napproximation method of [4] is used in conjunction with the balancing-based or balancing-free\\napproach of [5]. \\n\\nReferences\\n\\n[1] A. Varga. \\n    Efficient minimal realization procedure based on balancing.\\n    In A. El Moudni, P. Borne, and S.G. Tzafestas (Eds.), \\n    Prepr. of the IMACS Symp. on Modelling and Control of Technological \\n    Systems, Lille, France, vol. 2, pp.42-47, 1991.\\n\\n[2] M. S. Tombs and I. Postlethwaite. \\n    Truncated balanced realization of a stable non-minimal state-space \\n    system. Int. J. Control, vol. 46, pp. 1319–1330, 1987.\\n\\n[3] T. Stykel. \\n    Gramian based model reduction for descriptor systems. \\n    Mathematics of Control, Signals, and Systems, 16:297–319, 2004.\\n\\n[4] Y. Liu Y. and B.D.O. Anderson \\n    Singular Perturbation Approximation of Balanced Systems,\\n    Int. J. Control, Vol. 50, pp. 1379-1405, 1989.\\n\\n[5] Varga A.\\n    Balancing-free square-root algorithm for computing singular perturbation approximations.\\n    Proc. 30-th IEEE CDC,  Brighton, Dec. 11-13, 1991, Vol. 2, pp. 1062-1065.\\n\"), nothing, Dict{Symbol, Any}(:typesig => Union{Tuple{DescriptorSystems.DescriptorStateSpace{T, ET, MT} where {ET<:Union{LinearAlgebra.UniformScaling{Bool}, AbstractMatrix{T}}, MT<:AbstractMatrix{T}}}, Tuple{T}} where T, :module => DescriptorSystems, :linenumber => 461, :binding => DescriptorSystems.gbalmr, :path => \"/home/runner/.julia/packages/DescriptorSystems/7S3aT/src/order_reduction.jl\"))\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.baltrunc_unstab","page":"API","title":"RobustAndOptimalControl.baltrunc_unstab","text":"baltrunc_unstab(sys::LTISystem; residual = false, n = missing, kwargs...)\n\nBalanced truncation for unstable models. An additive decomposition of sys into sys = sys_stable + sys_unstable is performed after which sys_stable is reduced. The order n must not be less than the number of unstable poles.\n\nSee baltrunc2 for other keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.bilinearc2d-Tuple{AbstractArray, AbstractArray, AbstractArray, AbstractArray, Number}","page":"API","title":"RobustAndOptimalControl.bilinearc2d","text":"bilinearc2d(Ac::AbstractArray, Bc::AbstractArray, Cc::AbstractArray, Dc::AbstractArray, Ts::Number; tolerance=1e-12)\n\nBalanced Bilinear transformation in State-Space. This method computes a discrete time equivalent of a continuous-time system, such that\n\nG_d(z) = s2zG_c(s)\n\nin a manner which accomplishes the following   (i)   Preserves the infinity L-infinity norm over the transformation   (ii)  Finds a system which balances B and C, in the sense that B_2=C_2   (iii) Satisfies G_c(s) = z2ss2zG_c(s) for some map z2s[]\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.bilinearc2d-Tuple{ExtendedStateSpace{Continuous}, Number}","page":"API","title":"RobustAndOptimalControl.bilinearc2d","text":"bilinearc2d(sys::ExtendedStateSpace, Ts::Number)\n\nApplies a Balanced Bilinear transformation to a discrete-time extended statespace object\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.bilinearc2d-Tuple{StateSpace{Continuous}, Number}","page":"API","title":"RobustAndOptimalControl.bilinearc2d","text":"bilinearc2d(sys::StateSpace, Ts::Number)\n\nApplies a Balanced Bilinear transformation to a discrete-time statespace object\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.bilineard2c-Tuple{AbstractArray, AbstractArray, AbstractArray, AbstractArray, Number}","page":"API","title":"RobustAndOptimalControl.bilineard2c","text":"bilineard2c(Ad::AbstractArray, Bd::AbstractArray, Cd::AbstractArray, Dd::AbstractArray, Ts::Number; tolerance=1e-12)\n\nBalanced Bilinear transformation in State-Space. This method computes a continuous time equivalent of a discrete time system, such that\n\nG_c(z) = z2s[G_d(z)]\n\nin a manner which accomplishes the following   (i)   Preserves the infinity L-infinity norm over the transformation   (ii)  Finds a system which balances B and C, in the sense that ||B||2=||C||2   (iii) Satisfies Gd(z) = s2z[z2s[Gd(z)]] for some map s2z[]\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.bilineard2c-Tuple{ExtendedStateSpace}","page":"API","title":"RobustAndOptimalControl.bilineard2c","text":"bilineard2c(sys::ExtendedStateSpace)\n\nApplies a Balanced Bilinear transformation to continuous-time extended statespace object\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.bilineard2c-Tuple{StateSpace}","page":"API","title":"RobustAndOptimalControl.bilineard2c","text":"bilineard2c(sys::StateSpace)\n\nApplies a Balanced Bilinear transformation to continuous-time statespace object\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.blocksort-Tuple{UncertainSS}","page":"API","title":"RobustAndOptimalControl.blocksort","text":"blocks, M = blocksort(P::UncertainSS)\n\nReturns the block structure of P.Δ as well as P.M permuted according to the sorted block structure. blocks is a vector of vectors with the block structure of perturbation blocks as described by μ-tools, i.e.\n\n[-N, 0] denotes a repeated real block of size N\n[N, 0] denotes a repeated complex block of size N\n[ny, nu] denotes a full complex block of size ny × nu\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.broken_feedback-Tuple{LTISystem, Any}","page":"API","title":"RobustAndOptimalControl.broken_feedback","text":"broken_feedback(L, i)\n\nCloses all loops in square MIMO system L except for loops i. Forms L1 in fig 14. of \"An Introduction to Disk Margins\", Peter Seiler, Andrew Packard, and Pascal Gahinet\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.closedloop","page":"API","title":"RobustAndOptimalControl.closedloop","text":"closedloop(l::LQGProblem, L = lqr(l), K = kalman(l))\n\nClosed-loop system as defined in Glad and Ljung eq. 8.28. Note, this definition of closed loop is not the same as lft(P, K), which has B1 instead of B2 as input matrix. Use lft(l) to get the system from disturbances to controlled variables w -> z.\n\nThe return value will be the closed loop from filtred reference only, other disturbance signals (B1) are ignored. See feedback for a more advanced option. This function assumes that the control signal is computed as u = r̃ - Lx̂ (not u = L(xᵣ - x̂)), i.e., the feedforward signal r̃ is added directly to the plant input. r̃ must thus be produced by an inverse-like model that takes state references and output the feedforward signal.\n\nUse static_gain_compensation to adjust the gain from references acting on the input B2, dcgain(closedloop(l))*static_gain_compensation(l) ≈ I\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.connect-Tuple{Any, AbstractVector{<:Pair}}","page":"API","title":"RobustAndOptimalControl.connect","text":"connect(systems, connections; external_inputs, external_outputs = (:), verbose = true, unique = true, kwargs...)\n\nCreate block connections using named inputs and outputs.\n\nAddition and subtraction nodes are achieved by creating a linear combination node, i.e., a system with a D matrix only.\n\nArguments:\n\nsystems: A vector of named systems to be connected\nconnections: a vector of pairs output => input, where each pair maps an output to an input. Each output must appear as an output in one of systems, and similarly each input must appear as an input in one of systems. All inputs must have unique names and so must all outputs, but an input may have the same name as an output. In the example below the connection :uP => :uP connects the output :uP of the addP block to P's input :uP\nexternal_inputs: external signals to be used as inputs in the constructed system. Use (:) to indicate all signals\nexternal_outputs: outputs of the constructed system. Use (:) to indicate all signals\nverbose: Issue warnings for signals that have no connection\nunique: If true, all input names must be unique. If false, a single external input signal may be connected to multiple input ports with the same name.\n\nNote: Positive feedback is used, controllers that are intended to be connected with negative feedback must thus be negated.\n\nExample: The following complicated feedback interconnection\n\n                 yF\n               ┌────────────────────────────────┐\n               │                                │\n    ┌───────┐  │  ┌───────┐        ┌───────┐    │    ┌───────┐\nuF  │       │  │  │       | yR     │       │ yC │ uP │       │   yP\n────►   F   ├──┴──►   R   │────+───►   C   ├────+────►   P   ├───┬────►\n    │       │     │       │    │   │       │         │       │   │\n    └───────┘     └───────┘    │   └───────┘         └───────┘   │\n                               │                                 │\n                               └─────────────────────────────────┘\n\ncan be created by\n\nF = named_ss(ssrand(1, 1, 2, proper=true), x=:xF, u=:uF, y=:yF)\nR = named_ss(ssrand(1, 1, 2, proper=true), x=:xR, u=:uR, y=:yR)\nC = named_ss(ssrand(1, 1, 2, proper=true), x=:xC, u=:uC, y=:yC)\nP = named_ss(ssrand(1, 1, 3, proper=true), x=:xP, u=:uP, y=:yP)\n\naddP = sumblock(\"uP = yF + yC\") # Sum node before P\naddC = sumblock(\"uC = yR - yP\") # Sum node before C\n\nconnections = [\n    :yP => :yP # Output to input\n    :uP => :uP\n    :yC => :yC\n    :yF => :yF\n    :yF => :uR\n    :uC => :uC\n    :yR => :yR\n]\nexternal_inputs = [:uF] # External inputs\n\nG = connect([F, R, C, P, addP, addC], connections; external_inputs)\n\nIf an external input is to be connected to multiple points, use a splitter to split up the signal into a set of unique names which are then used in the connections.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.controller_reduction","page":"API","title":"RobustAndOptimalControl.controller_reduction","text":"controller_reduction(P::ExtendedStateSpace, K, r, out=true; kwargs...)\n\nMinimize    ||(K-Kᵣ) W||∞ if out=false             ||W (K-Kᵣ)||∞ if out=true See Robust and Optimal Control Ch 19.1 out indicates if the weight will be applied as output or input weight.\n\nThis function expects a *positive feedback controller K.\n\nThis method corresponds to the methods labelled SW1/SW2(SPA) in  Andreas Varga, \"Controller Reduction Using Accuracy-Enhancing Methods\" SW1 is the default method, corresponding to out=true.\n\nThis method does not support unstable controllers. See the reference above for alternatives. See also stab_unstab and baltrunc_unstab.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.controller_reduction_plot","page":"API","title":"RobustAndOptimalControl.controller_reduction_plot","text":"controller_reduction_plot(G, K)\n\nPlot the normalized-coprime margin (ncfmargin) as a function of controller order when baltrunc_coprime is used to reduce the controller. Red, orange and green bands correspond to rules of thumb for bad, okay and good coprime uncertainty margins. A value of 0 indicate an unstable closed loop.\n\nIf G is an ExtendedStateSpace system, a second plot will be shown indicating the H_ norm between inputs and performance outputs T_zw_infty when the function controller_reduction is used to reduce the controller.\n\nThe order of the controller can safely be reduced as long as the normalized coprime margin remains sufficiently large. If the controller contains integrators, it may be advicable to protect the integrators from the reduction, e.g., if the controller is obtained using glover_mcfarlane, perform the reduction on info.Gs, info.Ks rather than on K, and form Kr using the reduced Ks.\n\nSee glover_mcfarlane or the docs for an example.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.controller_reduction_weight-Tuple{ExtendedStateSpace, Any}","page":"API","title":"RobustAndOptimalControl.controller_reduction_weight","text":"controller_reduction_weight(P::ExtendedStateSpace, K)\n\nLemma 19.1 See Robust and Optimal Control Ch 19.1\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.dare3-Tuple{AbstractStateSpace{<:Discrete}, AbstractMatrix, AbstractMatrix, AbstractMatrix}","page":"API","title":"RobustAndOptimalControl.dare3","text":"dare3(P::AbstractStateSpace, Q1::AbstractMatrix, Q2::AbstractMatrix, Q3::AbstractMatrix; full=false)\n\nSolve the discrete-time algebraic Riccati equation for a discrete LQR cost augmented with control differences\n\nx^T Q_1 x + u^T Q_2 u + Δu^T Q_3 Δu quad\nΔu = u(k) - u(k-1)\n\nIf full, the returned matrix will include the state u(k-1), otherwise the returned matrix will be of the same size as Q1.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.diskmargin","page":"API","title":"RobustAndOptimalControl.diskmargin","text":"diskmargin(L, σ = 0)\ndiskmargin(L, σ::Real, ω)\n\nCalculate the disk margin of LTI system L. L is supposed to be a loop-transfer function, i.e., it should be square. If L = PC the disk margin for output perturbations is computed, whereas if L = CP, input perturbations are considered. If the method diskmargin(P, C, args...) is used, both are computed. Note, if L is MIMO, a simultaneous margin is computed, see loop_diskmargin for single loop margins of MIMO systems.\n\nThe implementation and notation follows \"An Introduction to Disk Margins\", Peter Seiler, Andrew Packard, and Pascal Gahinet.\n\nThe margins are aviable as fields of the returned objects, see Diskmargin.\n\nArguments:\n\nL: A loop-transfer function.\nσ: If little is known about the distribution of gain variations then σ = 0 is a reasonable choice as it allows for a gain increase or decrease by the same relative amount. The choice σ < 0 is justified if the gain can decrease by a larger factor than it can increase. Similarly, the choice σ > 0 is justified when the gain can increase by a larger factor than it can decrease. If σ = −1 then the disk margin condition is αmax = inv(MT). This margin is related to the robust stability condition for models with multiplicative uncertainty of the form P (1 + δ). If σ = +1 then the disk margin condition is αmax = inv(MS)\nkwargs: Are sent to the hinfnorm calculation\nω: If a vector of frequencies is supplied, the frequency-dependent disk margin will be computed, see example below.\n\nExample:\n\nL = tf(25, [1,10,10,10])\ndm = diskmargin(L, 0)\nplot(dm) # Plot the disk margin to illustrate maximum allowed simultaneous gain and phase variations.\n\nnyquistplot(L)\nplot!(dm, nyquist=true) # plot a nyquist exclusion disk. The Nyquist curve will be tangent to this disk at `dm.ω0`\nnyquistplot!(dm.f0*L) # If we perturb the system with the worst-case perturbation `f0`, the curve will pass through the critical point -1.\n\n## Frequency-dependent margin\nw = exp10.(LinRange(-2, 2, 500))\ndms = diskmargin(L, 0, w)\nplot(dms; lower=true, phase=true)\n\nExample: relation to Ms and Mt\n\nMs, wMs = hinfnorm(input_sensitivity(P, C)) # Input Ms\ndm = diskmargin(C*P, 1) # Input diskmargin, skew = +1\nisapprox(Ms/(Ms-1), dm.gainmargin[2], rtol=1e-2) # Guaranteed gain margin based on Ms\nisapprox(inv(Ms), dm.margin, rtol=1e-2)\nisapprox(dm.ω0, wMs, rtol=1e-1)\n\n\nMt, wMt = hinfnorm(input_comp_sensitivity(P, C)) # Input Mt\ndm = diskmargin(C*P, -1) # Input diskmargin, skew = -1\nisapprox(inv(Mt), dm.margin, rtol=1e-2)\nisapprox(dm.ω0, wMt, rtol=1e-1)\n\nSee also ncfmargin and loop_diskmargin.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.diskmargin-Tuple{LTISystem, LTISystem, Any, AbstractVector, Vararg{Any}}","page":"API","title":"RobustAndOptimalControl.diskmargin","text":"diskmargin(P::LTISystem, C::LTISystem, σ, w::AbstractVector, args...; kwargs...)\n\nSimultaneuous diskmargin at outputs, inputs and input/output simultaneously of P.  Returns a named tuple with the fields input, output, simultaneous_input, simultaneous_output, simultaneous where input and output represent loop-at-a-time margins, simultaneous_input is the margin for simultaneous perturbations on all inputs and simultaneous is the margin for perturbations on all inputs and outputs simultaneously.\n\nNote: simultaneous margins are more conservative than single-loop margins and are likely to be much lower than the single-loop margins. Indeed, with several simultaneous perturbations, it's in general easier to make the system unstable. It's not uncommon for a simultaneous margin involving two signals to be on the order of half the size of the single-loop margins.\n\nSee also ncfmargin and loop_diskmargin.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.diskmargin-Tuple{LTISystem, Real, AbstractArray}","page":"API","title":"RobustAndOptimalControl.diskmargin","text":"diskmargin(L::LTISystem, σ::Real, ω)\n\nCalculate the diskmargin at a particular frequency or vector of frequencies. If ω is a vector, you get a frequency-dependent diskmargin plot if you plot the returned value. See also ncfmargin.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.expand_symbol-Tuple{Symbol, Int64}","page":"API","title":"RobustAndOptimalControl.expand_symbol","text":"expand_symbol(s::Symbol, n::Int)\n\nTakes a symbol and an integer and returns a vector of symbols with increasing numbers appended to the end. E.g., (:x, 3) -> [:x1, :x2, :x3]\n\nThe short-hand syntax s^n is also available, e.g., :x^3 == expand_symbol(:x, 3).\n\nUseful to create signal names for named systems.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.extended_controller","page":"API","title":"RobustAndOptimalControl.extended_controller","text":"extended_controller(l::LQGProblem, L = lqr(l), K = kalman(l); z = nothing)\n\nReturns a statespace system representing the controller that is obtained when state-feedback u = L(xᵣ-x̂) is combined with a Kalman filter with gain K that produces state estimates x̂. The controller is an instance of ExtendedStateSpace where C2 = -L, D21 = L and B2 = K.\n\nThe returned system has inputs [xᵣ; y] and outputs the control signal u. If a reference model R is used to generate state references xᵣ, the controller from (ry, y) -> u  where ry - y = e is given by\n\nCe = extended_controller(l)\nCe = named_ss(ss(Ce); x = :xC, y = :u, u = [R.y; :y^l.ny]) # Name the inputs of Ce the same as the outputs of `R`.\nconnect([R, Ce]; u1 = R.y, y1 = R.y, w1 = [R.u; :y^l.ny], z1=[:u])\n\nSince the negative part of the feedback is built into the returned system, we have\n\nC = observer_controller(l)\nCe = extended_controller(l)\nsystem_mapping(Ce) == -C\n\nPlease note, without the reference pre-filter, the DC gain from references to controlled outputs may not be identity. If a vector of output indices is provided through the keyword argument z, the closed-loop system from state reference xᵣ to outputs z is returned as a second return argument. The inverse of the DC-gain of this closed-loop system may be useful to compensate for the DC-gain of the controller.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.extended_controller-Tuple{AbstractStateSpace}","page":"API","title":"RobustAndOptimalControl.extended_controller","text":"extended_controller(K::AbstractStateSpace)\n\nTakes a controller and returns an ExtendedStateSpace version which has augmented input [r; y] and output y (z output is 0-dim).\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.feedback_control-Tuple{Any, Any}","page":"API","title":"RobustAndOptimalControl.feedback_control","text":"G = feedback_control(P, K)\n\nReturn the (negative feedback) closed-loop system from input of K to output of P while outputing also the control signal (output of K), i.e., G maps references to [y; u]\n\nExample:\n\nThe following are two equivalent ways of achieving the same thing\n\nG = ssrand(3,4,2)\nK = ssrand(4,3,2)\n\nGcl1 = feedback_control(G, K) # First option\n\n# Second option using named systems and connect\nG = named_ss(G, :G)\nK = named_ss(K, :K)\nS = sumblock(\"Ku = r - Gy\", n=3) # Create a sumblock that computes r - Gy for vectors of length 3\n\nz1 = [G.y; K.y] # Output both plant and controller outputs\nw1 = :r^3       # Extenal inputs are the three references into the sum block\nconnections = [K.y .=> G.u; G.y .=> G.y; K.u .=> K.u] # Since the sumblock uses the same names as the IO signals of G,K, we can reuse these names here\nGcl2 = connect([G, K, S], connections; z1, w1)\n\n@test linfnorm(minreal(Gcl1 - Gcl2.sys))[1] < 1e-10 # They are the same\n\nTo include also an input disturbance, use\n\nGcl = feedback(K, P, W2=:, Z2=:, Zperm=[(1:ny).+nu; 1:nu]) # y,u from r,d\n\nSee also extended_gangoffour.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.ff_controller","page":"API","title":"RobustAndOptimalControl.ff_controller","text":"ff_controller(l::LQGProblem, L = lqr(l), K = kalman(l))\n\nReturn the feedforward controller C_ff that maps references to plant inputs: u = C_fby + C_ffr\n\nThe following should hold\n\nCff = RobustAndOptimalControl.ff_controller(l)\nCfb = observer_controller(l)\nGcl = feedback(system_mapping(l), Cfb) * Cff # Note the comma in feedback, P/(I + PC) * Cff\ndcgain(Gcl) ≈ I # Or some I-like non-square matrix \n\nNote, if extended_controller is used, the DC-gain compensation above cannot be used. The extended_controller assumes that the references enter like u = L(xᵣ - x̂). \n\nSee also observer_controller.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.find_lft-Union{Tuple{F}, Tuple{N}, Tuple{StateSpace{<:Any, <:MonteCarloMeasurements.AbstractParticles{<:Any, N}}, Any}, Tuple{StateSpace{<:Any, <:MonteCarloMeasurements.AbstractParticles{<:Any, N}}, Any, F}} where {N, F}","page":"API","title":"RobustAndOptimalControl.find_lft","text":"l, res = find_lft(sys::StateSpace{<:Any, <:StaticParticles{<:Any, N}}, δ) where N\n\nNOTE: This function is experimental. \n\nGiven an systems sys with uncertain coefficients in the form of StaticParticles, search for a lower linear fractional transformation M such that lft(M, δ) ≈ sys. \n\nδ can be either the source of uncertainty in sys, i.e., a vector of the unique uncertain parameters that were used to create sys. These should be constructed as uniform randomly distributed particles for most robust-control theory to be applicable.  δ can also be an integer, in which case a numer of δ sources of uncertainty are automatically created. This could be used for order reduction if the number of uncertainty sources in sys is large.\n\nNote, uncertainty in sys is only supported in A and B, C and D must be deterministic.\n\nReturns l::LFT that internaly contains all four blocks of M as well as δ. Call ss(l,sys) do obtain lft(M, δ) ≈ sys.\n\nCall Matrix(l) to obtain M = [M11 M12; M21 M22]\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.fit_complex_perturbations-Tuple{Any, Any}","page":"API","title":"RobustAndOptimalControl.fit_complex_perturbations","text":"centers, radii = fit_complex_perturbations(P, w; relative=true, nominal=:mean)\n\nFor each frequency in w, fit a circle in the complex plane that contains all models in the model set P, represented as an LTISystem with Particles coefficients. Note, the resulting radii can be quite unstable if the number of particles is small, in particular if the particles are normally distributed instead of uniformly.\n\nIf realtive = true, circles encompassing |(P - Pn)/Pn| will be returned (multiplicative/relative uncertainty). If realtive = false, circles encompassing |P - Pn| will be returned (additive uncertainty).\n\nIf nominal = :mean, the mean of P will be used as nominal model. If nominal = :first, the first particle will be used. See MonteCarloMeasurements.with_nominal to set the nominal value in the first particle. If nominal = :center, the middle point (pmaximum(ri)+pminimum(ri))/2 will be used. This typically gives the smallest circles.\n\nSee also nyquistcircles to plot circles (only if relative=false).\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.frequency_separation-Tuple{Any, Any}","page":"API","title":"RobustAndOptimalControl.frequency_separation","text":"frequency_separation(sys, ω)\n\nDecomponse sys into sys = sys_slow + sys_fast, where sys_slow contain all modes with eigenvalues with absolute value less than ω and sys_fast contain all modes with eigenvalues with absolute value greater than or equal to ω.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.frequency_weighted_reduction","page":"API","title":"RobustAndOptimalControl.frequency_weighted_reduction","text":"sysr, hs = frequency_weighted_reduction(G, Wo, Wi, r=nothing; residual=true)\n\nFind Gr such that Wₒ(G-Gr)Wᵢ is minimized. For a realtive reduction, set Wo = inv(G) and Wi = I.\n\nIf residual = true, matched static gain is achieved through \"residualization\", i.e., setting\n\n0 = A_21x_1 + A_22x_2 + B_2u\n\nwhere indices 1/2 correspond to the remaining/truncated states respectively. This choice typically results in a better match in the low-frequency region and a smaller overall error.\n\nRef: Andras Varga and Brian D.O. Anderson, \"Accuracy enhancing methods for the frequency-weighted balancing related model reduction\"\n\nNote: This function only handles exponentially stable models. To reduce unstable  and marginally stable models, decompose the system into stable and unstable parts using stab_unstab, reduce the stable part and then add the unstable part back.\n\nExample:\n\nThe following example performs reduction with a frequency focus between frequencies w1 and w2.\n\nusing DSP\nw1 = 1e-4\nw2 = 1e-1\nfc = DSP.analogfilter(DSP.Bandpass(w1, w2), DSP.Butterworth(2))\ntfc = DSP.PolynomialRatio(fc)\nW = tf(DSP.coefb(tfc), DSP.coefa(tfc))\nrsys, hs = frequency_weighted_reduction(sys, W, 1)\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.fudge_inv","page":"API","title":"RobustAndOptimalControl.fudge_inv","text":"fudge_inv(s::AbstractStateSpace, ε = 0.001)\n\nAllow inverting a proper statespace system by adding a tiny (ε) feedthrough term to the D matrix. The system must still be square.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.gain_and_delay_uncertainty-Tuple{Any, Any, Any}","page":"API","title":"RobustAndOptimalControl.gain_and_delay_uncertainty","text":"gain_and_delay_uncertainty(kmin, kmax, Lmax)\n\nReturn a multiplicative weight to represent the uncertainty coming from neglecting the dynamics k*exp(-s*L) where k ∈ [kmin, kmax] and L ≤ Lmax. This weight is slightly optimistic, an expression for a more exact weight appears in eq (7.27), \"Multivariable Feedback Control: Analysis and Design\"\n\nSee also neglected_lag and neglected_delay.\n\nExample:\n\na = 10\nP = ss([0 a; -a 0], I(2), [1 a; -a 1], 0) # Plant\nW0 = gain_and_delay_uncertainty(0.5, 2, 0.005) |> ss # Weight\nW = I(2) + W0*I(2) * uss([δc(), δc()]) # Create a diagonal real uncertainty weighted in frequency by W0\nPs = P*W # Uncertain plant\nPsamples = rand(Ps, 500) # Sample the uncertain plant for plotting\nw = exp10.(LinRange(-1, 3, 300)) # Frequency vector\nbodeplot(Psamples, w)\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.gainphaseplot","page":"API","title":"RobustAndOptimalControl.gainphaseplot","text":"gainphaseplot(P)\ngainphaseplot(P, re, im)\n\nPlot complex perturbantions to the plant P and indicate whether or not the closed-loop system is stable. The diskmargin is the largest disk that can be fit inside the green region that only contains stable variations.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.glover_mcfarlane","page":"API","title":"RobustAndOptimalControl.glover_mcfarlane","text":"K, γ, info = glover_mcfarlane(G::AbstractStateSpace, γ = 1.1; W1=1, W2=1)\n\nDesign a controller for G that maximizes the stability margin ϵ = 1/γ with normalized coprime factor uncertainty using the method of Glover and McFarlane\n\nγ = 1/ϵ = ||[K;I] inv(I-G*K)*inv(M)||∞\nG = inv(M + ΔM)*(N + ΔN)\n\nγ is given as a relative factor above γmin and must be greater than 1, i.e., if γ = 1.1, the controller will be designed for γ = 1.1*γmin.\n\nWe want γmin (which is always ≥ 1) as small as possible, and we usually require that γmin is less than 4, corresponding to 25% allowed coprime uncertainty.\n\nPerformance modeling is incorporated in the design by calling glover_mcfarlane on the shaped system Gs = W2*G*W1 and then forming the controller as K = W1*Ks*W2. Using this formulation, traditional loop shaping can be done on Gs = W2*G*W1. The plant shaping is handled internally if keyword arguments W1, W2 are used and the returned controller is already scaled. In this case, Gs and Ks are included in the info named tuple for inspection. \n\nSee also glover_mcfarlane_2dof to design a feedforward filter as well and baltrunc_coprime for controller order reduction. When reducing the order of the calculated controller, reduce the order of info.Ks and form Kr=W1*Ksred*W2. Verify the robustness using ncfmargin(info.Gs, Ksred) as well as ncfmargin(G, Kr).\n\nExample:\n\nExample 9.3 from the reference below.\n\nusing RobustAndOptimalControl, ControlSystemsBase, Plots, Test\nG = tf(200, [10, 1])*tf(1, [0.05, 1])^2     |> ss\nGd = tf(100, [10, 1])                       |> ss\nW1 = tf([1, 2], [1, 1e-6])                  |> ss\nK, γ, info = glover_mcfarlane(G, 1.1; W1)\n@test info.γmin ≈ 2.34 atol=0.005\nGcl = extended_gangoffour(G, K) # Form closed-loop system\n\nfig1 = bodeplot([G, info.Gs, G*K], lab=[\"G\" \"\" \"G scaled\" \"\" \"Loop transfer\"])\nfig2 = bodeplot(Gcl, lab=[\"S\" \"KS\" \"PS\" \"T\"], plotphase=false) # Plot gang of four\n\nfig3 = plot(step(Gd*feedback(1, info.Gs), 3), lab=\"Initial controller\")\nplot!(step(Gd*feedback(1, G*K), 3), lab=\"Robustified\")\nfig4 = nyquistplot([info.Gs, G*K], ylims=(-2,1), xlims=(-2, 1),\n    Ms_circles = 1.5,\n    lab = [\"Initial controller\" \"Robustified\"],\n    title = \"Loop transfers with and without robustified controller\"\n)\nplot(fig1, fig2, fig3, fig4)\n\nExample of controller reduction: The order of the controller designed above can be reduced maintaining at least 2/3 of the robustness margin like this\n\ne,_ = ncfmargin(info.Gs, info.Ks)\nKr, hs, infor = baltrunc_coprime(info.Ks, n=info.Ks.nx)\nn = findlast(RobustAndOptimalControl.error_bound(hs) .> 2e/3) # 2/3 e sets the robustness margin\nKsr, hs, infor = baltrunc_coprime(info.Ks; n)\n@test ncfmargin(info.Gs, Ksr)[1] >= 2/3 * e\nKr = W1*Ksr\nbodeplot([G*K, G*Kr], lab=[\"L original\" \"\" \"L Reduced\" \"\"])\n\nThis gives a final controller Kr of order 3 instead of order 5, but a very similar robustness margin. You may also call\n\ncontroller_reduction_plot(info.Gs, info.Ks)\n\nto help you select the controller order.\n\nRef: Sec 9.4.1 of Skogestad, \"Multivariable Feedback Control: Analysis and Design\"\n\nExtended help\n\nSkogestad gives the following general advice:\n\nScale the plant outputs and inputs. This is very important for most design  procedures and is sometimes forgotten. In general, scaling improves the  conditioning of the design problem, it enables meaningful analysis to be made  of the robustness properties of the feedback system in the frequency domain,  and for loop-shaping it can simplify the selection of weights. There are a variety  of methods available including normalization with respect to the magnitude of  the maximum or average value of the signal in question. If one is to go straight to a design the following variation has  proved useful in practice:\nThe outputs are scaled such that equal magnitudes of cross-coupling into each   of the outputs is equally undesirable.\nEach input is scaled by a given percentage (say 10%) of its expected range   of operation. That is, the inputs are scaled to reflect the relative actuator   capabilities.\nOrder the inputs and outputs so that the plant is as diagonal as possible. The  relative gain array relative_gain_array can be useful here. The purpose of this pseudo-diagonalization  is to ease the design of the pre- and post-compensators which, for simplicity, will  be chosen to be diagonal.\nNext, we discuss the selection of weights to obtain the shaped plant G_s = W_2 G W_1  where W_1 = W_p W_a W_g\nSelect the elements of diagonal pre- and post-compensators W_p and W_2 so that  the singular values of W_2 G W_p are desirable. This would normally mean high  gain at low frequencies, roll-off rates of approximately 20 dB/decade (a slope of  about 1) at the desired bandwidth(s), with higher rates at high frequencies. Some  trial and error is involved here. W_2 is usually chosen as a constant, reflecting the  relative importance of the outputs to be controlled and the other measurements  being fed back to the controller. For example, if there are feedback measurements  of two outputs to be controlled and a velocity signal, then W_2 might be chosen  to be diag([1, 1, 0.1]), where 0.1 is in the velocity signal channel. W_p contains the  dynamic shaping. Integral action, for low frequency performance; phase-advance  for reducing the roll-off rates at crossover, and phase-lag to increase the roll-off  rates at high frequencies should all be placed in W_p if desired. The weights should  be chosen so that no unstable hidden modes are created in G_s.\nOptional: Introduce an additional gain matrix W_g cascaded with W_a to provide  control over actuator usage. W_g is diagonal and is adjusted so that actuator rate  limits are not exceeded for reference demands and typical disturbances on the  scaled plant outputs. This requires some trial and error.\nRobustly stabilize the shaped plant G_s = W_2 G W_1 , where W_1 = W_p W_a W_g,  using glover_mcfarlane. First, the maximum stability  margin ϵ_max = 1γ_min is calculated. If the margin is too small, ϵmax  025, then go back and modify the weights. Otherwise, a γ-suboptimal controller is synthesized. There is usually no advantage to be gained by using the optimal controller. When ϵ_max > 0.25  (respectively γ_min < 4) the design is usually successful. In this case, at least  25% coprime factor uncertainty is allowed, and we also find that the shape of the  open-loop singular values will not have changed much after robust stabilization.  A small value of ϵmax indicates that the chosen singular value loop-shapes are  incompatible with robust stability requirements. That the loop-shapes do not  change much following robust stabilization if γ is small (ϵ large), is justified  theoretically in McFarlane and Glover (1990).\nAnalyze the design and if all the specifications are not met make further  modifications to the weights.\nImplement the controller. The configuration shown in below has been found  useful when compared with the conventional set up. This is because  the references do not directly excite the dynamics of K, which can result in large amounts of overshoot (classical derivative kick). The constant prefilter ensures a steady-state gain of 1 between r and y, assuming integral action in W_1 or G (note, the K returned by this function has opposite sign compared to that of Skogestad, so we use negative feedback here).\n\nAnti-windup can be added to W_1 but putting W_1 on Hanus form after the synthesis, see hanus.\n\n       ┌─────────┐      ┌────────┐      ┌────────┐\n    r  │         │    us│        │  u   │        │  y\n   ───►│(K*W2)(0)├──+──►│   W1   ├─────►│   G    ├────┬──►\n       │         │  │-  │        │      │        │    │\n       └─────────┘  │   └────────┘      └────────┘    │\n                    │                                 │\n                    │                                 │\n                    │   ┌────────┐      ┌────────┐    │\n                    │   │        │  ys  │        │    │\n                    └───┤   K    │◄─────┤   W2   │◄───┘\n                        │        │      │        │\n                        └────────┘      └────────┘\n\nKeywords: nfcsyn, coprimeunc\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.glover_mcfarlane-2","page":"API","title":"RobustAndOptimalControl.glover_mcfarlane","text":"K, γ, info = glover_mcfarlane(G::AbstractStateSpace{<:Discrete}, γ = 1.1; W1=1, W2=1, strictly_proper=false)\n\nFor discrete systems, the info tuple contains also feedback gains F, L and observer gain Hkf such that the controller on observer form is given by\n\nx^+ = Ax + Bu + H_kf (Cx - y)\nu = Fx + L (Cx - y)\n\nNote, this controller is not strictly proper, i.e., it has a non-zero D matrix. The controller can be transformed to observer form for the scaled plant (info.Gs) by Ko = observer_controller(info), in which case the following holds G*K == info.Gs*Ko (realizations are different).\n\nIf strictly_proper = true, the returned controller K will have D == 0. This can be advantageous in implementations where computational delays are present. In this case, info.L == 0 as well.\n\nRef discrete version: Iglesias, \"The Strictly Proper Discrete-Time Controller for the Normalized Left-Coprime Factorization Robust Stabilization Problem\"\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.glover_mcfarlane_2dof","page":"API","title":"RobustAndOptimalControl.glover_mcfarlane_2dof","text":"K, γ, info = glover_mcfarlane_2dof(G::AbstractStateSpace{Continuous}, Tref::AbstractStateSpace{Continuous}, γ = 1.1, ρ = 1.1;\nW1 = 1, Wo = I, match_dc = true, kwargs...)\n\nJoint design of feedback and feedforward compensators\n\nK = beginbmatrix K_1  K_2 endbmatrix\n\n   ┌──────┐   ┌──────┐        ┌──────┐    ┌─────┐\nr  │      │   │      │        │      │    │     │\n──►│  Wi  ├──►│  K1  ├───+───►│  W1  ├───►│  G  ├─┐y\n   │      │   │      │   │    │      │    │     │ │\n   └──────┘   └──────┘   │    └──────┘    └─────┘ │\n                         │                        │\n                         │    ┌──────┐            │\n                         │    │      │            │\n                         └────┤  K2  ◄────────────┘\n                              │      │\n                              └──────┘\n\nWhere the returned controller K takes the measurement vector [r; y] (positive feedback),  i.e., it includes all blocks Wi, K1, K2, W1. If match_dc = true, Wi is automatically computed to make sure the static gain matches Tref exactly, otherwise Wi is set to I. The info named tuple contains the feedforward filter for inspection (info.K1 = K1*Wi).\n\nArguments:\n\nG: Plant model\nTref: Reference model\nγ: Relative γ\nρ: Design parameter, typically 1 < ρ < 3. Increase to emphasize model matching at the expense of robustness.\nW1: Pre-compensator for loop shaping.\nWo: Output selction matrix. If there are more measurements than controlled variables, this matrix let's you select which measurements are to be controlled. \nkwargs: Are sent to hinfsynthesize.\n\nRef: Sec. 9.4.3 of Skogestad, \"Multivariable Feedback Control: Analysis and Design\". The reference contains valuable pointers regarding gain-scheduling implementation of the designed controller as an observer with feedback from estimated states. In order to get anti-windup protection when W1 contains an integrator, transform W1 to self-conditioned Hanus form (using hanus) and implement the controller like this\n\nW1h = hanus(W1)             # Perform outside loop\n\n# Each iteration\nus = filter(Ks, [r; y])     # filter inputs through info.Ks (filter is a fictive function that applies the transfer function)\nu  = filter(W1h, [us; ua])  # filter us and u-actual (after input saturation) through W1h\nua = clamp(u, lower, upper) # Calculate ua for next iteration as the saturated value of u\n\nExample:\n\nusing RobustAndOptimalControl, Plots\nP = tf([1, 5], [1, 2, 10]) # Plant\nW1 = tf(1,[1, 0]) |> ss    # Loop shaping controller\n\nTref = tf(1, [1, 1])^2 |> ss # Reference model (preferably of same order as P)\n\nK1dof, γ1, info1 = glover_mcfarlane(ss(P), 1.1; W1)\nK2dof, γ2, info2 = glover_mcfarlane_2dof(ss(P), Tref, 1.1, 1.1; W1)\n\nG1 = feedback(P*K1dof)\nG2 = info2.Gcl\n\nw = exp10.(LinRange(-2, 2, 200))\nbodeplot(info2.K1, w, lab=\"Feedforward filter\")\nplot([step(G1, 15), step(G2, 15), step(Tref, 15)], lab=[\"1-DOF\" \"2-DOF\" \"Tref\"])\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.h2norm-Tuple{LTISystem}","page":"API","title":"RobustAndOptimalControl.h2norm","text":"n = h2norm(sys::LTISystem; kwargs...)\n\nA numerically robust version of norm using DescriptorSystems.jl\n\nFor keyword arguments, see the docstring of DescriptorSystems.gh2norm, reproduced below Base.Docs.DocStr(svec(\"    gh2norm(sys, fast = true, offset = sqrt(ϵ), atol = 0, atol1 = atol, atol2 = atol, atolinf = atol, rtol = nϵ) \\n\\nCompute for a descriptor system sys = (A-λE,B,C,D) the H2 norm of its transfer function  matrix G(λ).\\nThe H2 norm is infinite, if G(λ) has unstable poles, or, for a continuous-time, the system has nonzero gain at infinity.\\nIf the pencil A-λE has uncontrollable and/or unobservable unstable eigenvalues on the boundary of the stability domain,\\nthen a reduced order realization is determined first (see below) to eliminate these eigenvalues. \\n\\nTo check the stability, the eigenvalues of the pole pencil A-λE must have real parts less \\nthan -β for a continuous-time system or \\nhave moduli less than 1-β for a discrete-time system, where β is the stability domain boundary offset.\\nThe offset  β to be used can be specified via the keyword parameter offset = β. \\nThe default value used for β is sqrt(ϵ), where ϵ is the working machine precision. \\n\\nFor a continuous-time system sys with E singular, a reduced order realization is determined first, without \\nuncontrollable and unobservable finite and infinite eigenvalues of the pencil A-λE. \\nFor a discrete-time system or for a system with invertible E, a reduced order realization is determined first, without \\nuncontrollable and unobservable finite eigenvalues of the pencil A-λE.\\nThe rank determinations in the performed reductions\\nare based on rank revealing QR-decompositions with column pivoting \\nif fast = true or the more reliable SVD-decompositions if fast = false.   \\n\\nThe keyword arguments atol1, atol2, and rtol, specify, respectively, \\nthe absolute tolerance for the nonzero elements of A, B, C, D,  \\nthe absolute tolerance for the nonzero elements of E,  \\nand the relative tolerance for the nonzero elements of A, B, C, D and E.  \\nThe keyword argument atolinf is the absolute tolerance for the gain of G(λ) at λ = ∞. \\nThe used default value is atolinf = 0. \\nThe default relative tolerance is `nϵ, whereϵis the working machine epsilon \\nandnis the order of the systemsys. The keyword argumentatolcan be used \\nto simultaneously setatol1 = atolandatol2 = atol`.  \\n\"), nothing, Dict{Symbol, Any}(:typesig => Union{Tuple{DescriptorSystems.DescriptorStateSpace{T, ET, MT} where {ET<:Union{LinearAlgebra.UniformScaling{Bool}, AbstractMatrix{T}}, MT<:AbstractMatrix{T}}}, Tuple{T}} where T, :module => DescriptorSystems, :linenumber => 537, :binding => DescriptorSystems.gh2norm, :path => \"/home/runner/.julia/packages/DescriptorSystems/7S3aT/src/analysis.jl\"))\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.h2synthesize","page":"API","title":"RobustAndOptimalControl.h2synthesize","text":"K, Cl = h2synthesize(P::ExtendedStateSpace, γ = nothing)\n\nSynthesize H₂-optimal controller K and calculate the closed-loop transfer function from w to z. Ref: Cha. 14.5 in Robust and Optimal Control.\n\nIf γ = nothing, use the formulas for H₂ in Ch 14.5. If γ is a large value, the H∞ formulas are used. As γ → ∞, these two are equivalent. The h∞ formulas do a coordinate transfromation that handles slightly more general systems so if you run into an error, it might be worth trying setting γ to something large, e.g., 1000.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.hankelnorm-Tuple{LTISystem}","page":"API","title":"RobustAndOptimalControl.hankelnorm","text":"n, hsv = hankelnorm(sys::LTISystem; kwargs...)\n\nCompute the hankelnorm and the hankel singular values\n\nFor keyword arguments, see the docstring of DescriptorSystems.ghanorm, reproduced below Base.Docs.DocStr(svec(\"    ghanorm(sys, fast = true, atol = 0, atol1 = atol, atol2 = atol, rtol = nϵ) -> (hanorm, hs)\\n\\nCompute for a proper and stable descriptor system sys = (A-λE,B,C,D) with the transfer function\\nmatrix G(λ), the Hankel norm hanorm = small G(lambda)_H and \\nthe vector of Hankel singular values hs of the minimal realizatioj of the system.\\n\\nFor a non-minimal system, the uncontrollable and unobservable finite and infinite eigenvalues of the pair (A,E) and\\nthe non-dynamic modes are elliminated using minimal realization techniques.\\nThe rank determinations in the performed reductions\\nare based on rank revealing QR-decompositions with column pivoting \\nif fast = true or the more reliable SVD-decompositions if fast = false. \\n\\nThe keyword arguments atol1, atol2, and rtol, specify, respectively, \\nthe absolute tolerance for the nonzero elements of A, B, C, D,  \\nthe absolute tolerance for the nonzero elements of E,  \\nand the relative tolerance for the nonzero elements of A, B, C, D and E.  \\nThe default relative tolerance is `nϵ, whereϵis the working machine epsilon \\nandnis the order of the systemsys. The keyword argumentatolcan be used \\nto simultaneously setatol1 = atolandatol2 = atol`. \\n\"), nothing, Dict{Symbol, Any}(:typesig => Union{Tuple{DescriptorSystems.DescriptorStateSpace{T, ET, MT} where {ET<:Union{LinearAlgebra.UniformScaling{Bool}, AbstractMatrix{T}}, MT<:AbstractMatrix{T}}}, Tuple{T}} where T, :module => DescriptorSystems, :linenumber => 466, :binding => DescriptorSystems.ghanorm, :path => \"/home/runner/.julia/packages/DescriptorSystems/7S3aT/src/analysis.jl\"))\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hanus-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.hanus","text":"Wh = hanus(W)\n\nReturn Wh on Hanus form. Wh has twice the number of inputs, where the second half of the inputs are \"actual inputs\", e.g., potentially saturated. This is used to endow W with anti-windup protection. W must have an invertable D matrix and be minimum phase.\n\nRef: Sec 9.4.5 of Skogestad, \"Multivariable Feedback Control: Analysis and Design\"\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hess_form-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.hess_form","text":"sysm, T, HF = hess_form(sys)\n\nBring sys to Hessenberg form form.\n\nThe Hessenberg form is characterized by A having upper Hessenberg structure. T is the similarity transform applied to the system such that \n\nsysm ≈ similarity_transform(sys, T)\n\nHF is the Hessenberg-factorization of A.\n\nSee also modal_form and schur_form\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hinfassumptions-Tuple{ExtendedStateSpace}","page":"API","title":"RobustAndOptimalControl.hinfassumptions","text":"flag = hinfassumptions(P::ExtendedStateSpace; verbose=true)\n\nCheck the assumptions for using the γ-iteration synthesis in Theorem 1.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hinfgrad-Tuple{Any, Any, Any}","page":"API","title":"RobustAndOptimalControl.hinfgrad","text":"∇A, ∇B, ∇C, ∇D, hn, ω = hinfgrad(sys; rtolinf=1e-8, kwargs...)\n∇A, ∇B, ∇C, ∇D        = hinfgrad(sys, hn, ω)\n\nCompute the gradient of the H∞ norm w.r.t. the statespace matrices A,B,C,D. If only a system is provided, the norm hn and the peak frequency ω are automatically calculated. kwargs are sent to hinfnorm2. Note, the default tolerance to which the norm is calculated is set smaller than default for hinfnorm2, gradients will be discontinuous with any non-finite tolerance, and sensitive optimization algorithms may require even tighter tolerance.\n\nIn cases where the maximum singular value is reached at more than one frequency, a random frequency is used.\n\nIf the system is unstable, the gradients are NaN. Strategies to find an initial stabilizing controllers are outlined in Apkarian and D. Noll, \"Nonsmooth H∞ Synthesis\" in IEEE Transactions on Automatic Control.\n\nAn rrule for ChainRules is defined using this function, so hn is differentiable with any AD package that derives its rules from ChainRules (only applies to the hn return value, not ω).\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hinfnorm2-Tuple{LTISystem}","page":"API","title":"RobustAndOptimalControl.hinfnorm2","text":"n, ω = hinfnorm2(sys::LTISystem; kwargs...)\n\nA numerically robust version of hinfnorm using DescriptorSystems.jl\n\nFor keyword arguments, see the docstring of DescriptorSystems.ghinfnorm, reproduced below Base.Docs.DocStr(svec(\"    ghinfnorm(sys, rtolinf = 0.001, fast = true, offset = sqrt(ϵ), atol = 0, atol1 = atol, atol2 = atol, rtol = nϵ) -> (hinfnorm, fpeak)\\n\\nCompute for a descriptor system sys = (A-λE,B,C,D) with the transfer function  matrix G(λ) \\nthe H∞ norm hinfnorm (i.e.,  the peak gain of G(λ)) and \\nthe corresponding peak frequency fpeak, where the peak gain is achieved. \\nThe H∞ norm is infinite if G(λ) has unstable poles. \\nIf the pencil A-λE has uncontrollable and/or unobservable unstable eigenvalues,\\nthen a reduced order realization is determined first (see below) to eliminate these eigenvalues. \\n\\nTo check the stability, the eigenvalues of the pencil A-λE must have real parts less than -β for a continuous-time system or \\nhave moduli less than 1-β for a discrete-time system, where β is the stability domain boundary offset.\\nThe offset  β to be used can be specified via the keyword parameter offset = β. \\nThe default value used for β is sqrt(ϵ), where ϵ is the working machine precision. \\n\\nThe keyword argument rtolinf specifies the relative accuracy for the computed infinity norm. \\nThe  default value used for rtolinf is 0.001.\\n\\nFor a continuous-time system sys with E singular, a reduced order realization is determined first, without \\nuncontrollable and unobservable finite and infinite eigenvalues of the pencil A-λE. \\nFor a discrete-time system or for a system with invertible E, a reduced order realization is determined first, without \\nuncontrollable and unobservable finite eigenvalues of the pencil A-λE.\\nThe rank determinations in the performed reductions\\nare based on rank revealing QR-decompositions with column pivoting \\nif fast = true or the more reliable SVD-decompositions if fast = false.   \\n\\nThe keyword arguments atol1, atol2, and rtol, specify, respectively, the absolute tolerance for the \\nnonzero elements of matrices A, B, C, D, the absolute tolerance for the nonzero elements of E,  \\nand the relative tolerance for the nonzero elements of A, B, C, D and E. \\nThe default relative tolerance is `nϵ, whereϵis the working machine epsilon  \\nandnis the order of the systemsys. \\nThe keyword argumentatolcan be used to simultaneously setatol1 = atolandatol2 = atol`. \\n\"), nothing, Dict{Symbol, Any}(:typesig => Union{Tuple{DescriptorSystems.DescriptorStateSpace{T, ET, MT} where {ET<:Union{LinearAlgebra.UniformScaling{Bool}, AbstractMatrix{T}}, MT<:AbstractMatrix{T}}}, Tuple{T}} where T, :module => DescriptorSystems, :linenumber => 683, :binding => DescriptorSystems.ghinfnorm, :path => \"/home/runner/.julia/packages/DescriptorSystems/7S3aT/src/analysis.jl\"))\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hinfpartition-NTuple{4, Any}","page":"API","title":"RobustAndOptimalControl.hinfpartition","text":"P = hinfpartition(G, WS, WU, WT)\n\nTransform a SISO or MIMO system G, with weighting functions W_S W_U W_T into an LFT with an isolated controller, and write the resulting system, P(s), on a state-space form. Valid inputs for G are transfer functions (with dynamics, can be both MIMO and SISO, both in tf and ss forms). Valid inputs for the weighting functions are empty arrays, numbers (static gains), and LTISystems.\n\nNote, system_mapping(P) is equal to -G.\n\nExtended help\n\nFor ill-conditioned MIMO plants, the S CS T weighting may result in controllers that \"invert\" the plant, which may result in poor robustness. For such systems, penalizing GS and T may be more appropriate. Ref: \"Inverting and noninverting H∞ controllers\", Urs Christen, Hans Geering\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hinfsignals-Tuple{ExtendedStateSpace, LTISystem, LTISystem}","page":"API","title":"RobustAndOptimalControl.hinfsignals","text":"Pcl, S, CS, T = hinfsignals(P::ExtendedStateSpace, G::LTISystem, C::LTISystem)\n\nUse the extended state-space model, a plant and the found controller to extract the closed loop transfer functions.\n\nPcl : w → z : From input to the weighted functions\nS   : w → e : From input to error\nCS  : w → u : From input to control\nT   : w → y : From input to output\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hinfsynthesize-Union{Tuple{ExtendedStateSpace{Continuous, T}}, Tuple{T}} where T","page":"API","title":"RobustAndOptimalControl.hinfsynthesize","text":"K, γ, mats = hinfsynthesize(P::ExtendedStateSpace; gtol = 1e-4, interval = (0, 20), verbose = false, tolerance = 1.0e-10, γrel = 1.01, transform = true, ftype = Float64, check = true)\n\nComputes an H-infinity optimal controller K for an extended plant P such that F_l(P K)  γ(lft(P, K)) for the smallest possible γ given P. The routine is known as the γ-iteration, and is based on the paper \"State-space formulae for all stabilizing controllers that satisfy an H∞-norm bound and relations to risk sensitivity\" by Glover and Doyle.\n\nArguments:\n\ngtol: Tolerance for γ.\ninterval: The starting interval for the bisection.\nverbose: Print progress?\ntolerance: For detecting eigenvalues on the imaginary axis.\nγrel: If γrel > 1, the optimal γ will be found by γ iteration after which a controller will be designed for γ = γopt * γrel. It is often a good idea to design a slightly suboptimal controller, both for numerical reasons, but also since the optimal controller may contain very fast dynamics. If γrel → ∞, the computed controller will approach the 𝑯₂ optimal controller. Getting a mix between 𝑯∞ and 𝑯₂ properties is another reason to choose γrel > 1.\ntransform: Apply coordiante transform in order to tolerate a wider range or problem specifications.\nftype: construct problem matrices in higher precision for increased numerical robustness. If the calculated controller achieves \ncheck: Perform a post-design check of the γ value achieved by the calculated controller. A warning is issued if the achieved γ differs from the γ calculated during design. If this warning is issued, consider using a higher-precision number type like ftype = BigFloat.\n\nSee the example folder for example usage.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.hsvd-Tuple{AbstractStateSpace}","page":"API","title":"RobustAndOptimalControl.hsvd","text":"hsvd(sys::AbstractStateSpace)\n\nReturn the Hankel singular values of sys, computed as the eigenvalues of QP Where Q and P are the Gramians of sys.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.ispassive-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.ispassive","text":"ispassive(P; kwargs...)\n\nDetermine if square system P is passive, i.e., P(s) + Pᴴ(s)  0.\n\nA passive system has a Nyquist curve that lies completely in the right half plane, and satisfies the following inequality (dissipation of energy)\n\nint_0^T y^T u dt  0  T\n\nThe negative feedback-interconnection of two passive systems is stable and  parallel connections of two passive systems as well as the inverse of a passive system are also passive. A passive controller will thus always yeild a stable feedback loop for a passive system. A series connection of two passive systems is not always passive.\n\nSee also passivityplot, passivity_index.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.loop_diskmargin-Tuple{LTISystem, LTISystem, Vararg{Any}}","page":"API","title":"RobustAndOptimalControl.loop_diskmargin","text":"loop_diskmargin(P, C, args...; kwargs...)\n\nCalculate the loop-at-a-time diskmargin for each output and input of P. See also diskmargin, sim_diskmargin. Ref: \"An Introduction to Disk Margins\", Peter Seiler, Andrew Packard, and Pascal Gahinet\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.loop_diskmargin-Tuple{LTISystem, Vararg{Any}}","page":"API","title":"RobustAndOptimalControl.loop_diskmargin","text":"loop_diskmargin(L, args...; kwargs...)\n\nCalculate the loop-at-a-time diskmargin for each output of L.\n\nSee also diskmargin, sim_diskmargin. Ref: \"An Introduction to Disk Margins\", Peter Seiler, Andrew Packard, and Pascal Gahinet\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.loop_scale","page":"API","title":"RobustAndOptimalControl.loop_scale","text":"loop_scale(L::LTISystem, w = 0)\n\nFind the optimal diagonal scaling matrix D such that D\\L(iw)*D has a minimized condition number at frequency w. Applicable to square L only. Use loop_scaling to obtain D.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.loop_scaling","page":"API","title":"RobustAndOptimalControl.loop_scaling","text":"loop_scaling(M0::Matrix, tol = 0.0001)\n\nFind the optimal diagonal scaling matrix D such that D\\M0*D has a minimized condition number. Applicable to square M0 only. See also structured_singular_value with option dynamic=true. Use loop_scale to find and apply the scaling to a loop-transfer function.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.lqr3-Tuple{AbstractStateSpace{<:Discrete}, AbstractMatrix, AbstractMatrix, AbstractMatrix}","page":"API","title":"RobustAndOptimalControl.lqr3","text":"lqr3(P::AbstractStateSpace, Q1::AbstractMatrix, Q2::AbstractMatrix, Q3::AbstractMatrix)\n\nCalculate the feedback gain of the discrete LQR cost function augmented with control differences\n\nx^T Q_1 x + u^T Q_2 u + Δu^T Q_3 Δu quad\nΔu = u(k) - u(k-1)\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.makeweight-Tuple{Any, Number, Any}","page":"API","title":"RobustAndOptimalControl.makeweight","text":"makeweight(low, f_mid, high)\nmakeweight(low, (f_mid, gain_mid), high)\n\nCreate a weighting function that goes from gain low at zero frequency, through gain gain_mid to gain high at ∞\n\nArguments:\n\nlow: A number specifying the DC gain \nmid: A number specifying the frequency at which the gain is 1, or a tuple (freq, gain). If gain_mid is not specified, the geometric mean of high and low is used.\nhigh: A number specifying the gain at ∞\n\nusing ControlSystemsBase, Plots\nW = makeweight(10, (5,2), 1/10)\nbodeplot(W)\nhline!([10, 2, 1/10], l=(:black, :dash), primary=false)\nvline!([5], l=(:black, :dash), primary=false)\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.measure-Tuple{NamedStateSpace, Any}","page":"API","title":"RobustAndOptimalControl.measure","text":"measure(s::NamedStateSpace, names)\n\nReturn a system with specified state variables as measurement outputs.\n\nSee also ControlSystemsBase.add_output.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.mo_sys_from_particles-Tuple{AbstractStateSpace}","page":"API","title":"RobustAndOptimalControl.mo_sys_from_particles","text":"mo_sys_from_particles(P::AbstractStateSpace; sparse = nparticles(P.A) > 500)\n\nConverts a state-space model with Particles coefficients to a single state-space model with the same number of inputs as P, but with nparticles(P.A) times the output and state dimensions.\n\nIf sparse is true, the resulting model will be a HeteroStateSpace with sparse A, C, and D matrices.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.modal_form-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.modal_form","text":"sysm, T, E = modal_form(sys; C1 = false)\n\nBring sys to modal form.\n\nThe modal form is characterized by being tridiagonal with the real values of eigenvalues of A on the main diagonal and the complex parts on the first sub and super diagonals. T is the similarity transform applied to the system such that \n\nsysm ≈ similarity_transform(sys, T)\n\nIf C1, then an additional convention for SISO systems is used, that the C-matrix coefficient of real eigenvalues is 1. If C1 = false, the B and C coefficients are chosen in a balanced fashion.\n\nE is an eigen factorization of A.\n\nThe modal form makes apparent which modes are controllable from which inputs, and which are observable from which outputs. Non-minimal realizations may trigger singularity exceptions.\n\nSee also hess_form and schur_form\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.muplot","page":"API","title":"RobustAndOptimalControl.muplot","text":"muplot(sys, args...; hz=false)\nmuplot(LTISystem[sys1, sys2...], args...; hz=false)\n\nPlot the structured singular values (assuming time-varying diagonal complex uncertainty) of the frequency response of the LTISystem(s). This plot is similar to sigmaplot, but scales the loop-transfer function to minimize the maximum singular value. Only applicable to square systems. A frequency vector w can be optionally provided.\n\nIf hz=true, the plot x-axis will be displayed in Hertz, the input frequency vector is still treated as rad/s.\n\nkwargs is sent as argument to Plots.plot.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.mvnyquistplot","page":"API","title":"RobustAndOptimalControl.mvnyquistplot","text":"fig = mvnyquistplot(sys, w;  unit_circle=true, hz = false, kwargs...)\n\nCreate a Nyquist plot of the LTISystem. A frequency vector w must be provided.\n\nunit_circle: if the unit circle should be displayed\n\nIf hz=true, the hover information will be displayed in Hertz, the input frequency vector is still treated as rad/s.\n\nkwargs is sent as argument to plot.\n\nExample\n\nw = 2π .* exp10.(LinRange(-2, 2, 500))\nW = makeweight(0.40, 15, 3) # frequency weight for uncertain dynamics\nPn = tf(1, [1/60, 1]) |> ss # nominal plant\nd = δss(1,1)                # Uncertain dynamics\n\nPd = Pn*(I(1) + W*d)        # weighted dynamic uncertainty on the input of Pn\nPp = rand(Pd, 200)          # sample the uncertain plant\nGcl = lft(Pd, ss(-1))       # closed loop system\nstructured_singular_value(Gcl) # larger than 1 => not robustly stable\nunsafe_comparisons(true)\nmvnyquistplot(Pp, w, points=true) # MV Nyquist plot encircles origin for some samples => not robustly stable\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.named_ss-Tuple{AbstractStateSpace, Any}","page":"API","title":"RobustAndOptimalControl.named_ss","text":"named_ss(sys::AbstractStateSpace, name; x, y, u)\n\nIf a single name of the system is provided, the outputs, inputs and states will be automatically named y,u,x with name as prefix.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.named_ss-Union{Tuple{AbstractStateSpace{T}}, Tuple{T}} where T","page":"API","title":"RobustAndOptimalControl.named_ss","text":"named_ss(sys::AbstractStateSpace{T}; x, u, y)\n\nCreate a NamedStateSpace system. This kind of system uses names rather than integer indices to refer to states, inputs and outputs.\n\nIf a single name is provided but a vector of names is expected, this name will be used as prefix followed by a numerical index.\nIf no name is provided, default names (x,y,u) will be used.\n\nArguments:\n\nsys: A system to add names to.\nx: A list of symbols with names of the states.\nu: A list of symbols with names of the inputs.\ny: A list of symbols with names of the outputs.\n\nExample\n\nG1 = ss(1,1,1,0)\nG2 = ss(1,1,1,0)\ns1 = named_ss(G1, x = :x, u = :u1, y=:y1)\ns2 = named_ss(G2, x = :z, u = :u2, y=:y2)\n\ns1[:y1, :u1] # Index using symbols. Uses prefix matching if no exact match is found.\n\nfb = feedback(s1, s2, r = :r) # \n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.named_ss-Union{Tuple{ExtendedStateSpace{T}}, Tuple{T}, Tuple{ExtendedStateSpace{T}, Any}} where T","page":"API","title":"RobustAndOptimalControl.named_ss","text":"named_ss(sys::ExtendedStateSpace;       kwargs...)\nnamed_ss(sys::ExtendedStateSpace, name; kwargs...)\n\nAssign names to an ExtendedStateSpace. If no specific names are provided for signals z,y,w,u and statesx, names will be generated automatically.\n\nArguments:\n\nname: Prefix to add to all automatically generated names.\nx\nu\ny\nw\nz\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.ncfmargin-Tuple{Any, Any}","page":"API","title":"RobustAndOptimalControl.ncfmargin","text":"m, ω = ncfmargin(P, K)\n\nNormalized coprime factor margin, defined has the inverse of\n\nbeginVmatrix\nbeginbmatrix\nI  K\nendbmatrix (I + PK)^-1 beginbmatrix\nI  P\nendbmatrix\nendVmatrix_infty\n\nA margin ≥ 0.25-0.3 is a reasonable for robustness. \n\nIf controller K stabilizes P with margin m, then K will also stabilize P̃ if nugap(P, P̃) < m.\n\nSee also extended_gangoffour, diskmargin, controller_reduction_plot.\n\nExtended help\n\nRobustness with respect to coprime factor uncertainty does not necessarily imply robustness with respect to input uncertainty. Skogestad p. 96 remark 4\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.neglected_delay-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.neglected_delay","text":"neglected_delay(Lmax)\n\nReturn a multiplicative weight to represent the uncertainty coming from neglecting the dynamics exp(-s*L) where L ≤ Lmax. \"Multivariable Feedback Control: Analysis and Design\" Ch 7.4.5\n\nSee also gain_and_delay_uncertainty and neglected_lag.\n\nExample:\n\na = 10\nP = ss([0 a; -a 0], I(2), [1 a; -a 1], 0) # Plant\nW0 = neglected_delay(0.005) |> ss # Weight\nW = I(2) + W0*I(2) * uss([δc(), δc()]) # Create a diagonal real uncertainty weighted in frequency by W0\nPs = P*W # Uncertain plant\nPsamples = rand(Ps, 500) # Sample the uncertain plant for plotting\nw = exp10.(LinRange(-1, 3, 300)) # Frequency vector\nbodeplot(Psamples, w)\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.neglected_lag-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.neglected_lag","text":"neglected_lag(τmax)\n\nReturn a multiplicative weight to represent the uncertainty coming from neglecting the dynamics 1/(s*τ + 1) where τ ≤ τmax. \"Multivariable Feedback Control: Analysis and Design\" Ch 7.4.5\n\nSee also gain_and_delay_uncertainty and neglected_delay.\n\nExample:\n\na = 10\nP = ss([0 a; -a 0], I(2), [1 a; -a 1], 0) # Plant\nW0 = neglected_lag(0.05) |> ss # Weight\nW = I(2) + W0*I(2) * uss([δc(), δc()]) # Create a diagonal real uncertainty weighted in frequency by W0\nPs = P*W # Uncertain plant\nPsamples = rand(Ps, 100) # Sample the uncertain plant for plotting\nw = exp10.(LinRange(-1, 3, 300)) # Frequency vector\nsigmaplot(Psamples, w)\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.noise_mapping","page":"API","title":"RobustAndOptimalControl.noise_mapping","text":"noise_mapping(P::ExtendedStateSpace)\n\nReturn the system from w -> y See also performance_mapping, system_mapping, noise_mapping\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.nu_reduction","page":"API","title":"RobustAndOptimalControl.nu_reduction","text":"nu_reduction(G, g=0.1; gap = nugap(G))\n\nReduce the number of particles in an uncertain system G by removing all particles that are within the νgap g of the nominal system Gₙ.\n\nNote: If G has a stochastic interpretation, i.e., the coefficients come from some distribution, this interpretation will be lost after reduction, mean values and standard deviations will not be preserved. The reduced system should instead be interpreted as preserving worst-case uncertainty.\n\nIf the gap = nugap(G) has already been precomputed, it can be supplied as an argument to avoid potentially costly recomputation.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.nu_reduction_recursive","page":"API","title":"RobustAndOptimalControl.nu_reduction_recursive","text":"nu_reduction_recursive(G, g = 0.1; gap = nugap(G), keepinds = Set{Int}(1), verbose = false)\n\nFind a νgap cover of balls of radius g (in the νgap metric) that contain all realizations in G. \n\nIf the gap = nugap(G) has already been precomputed, it can be supplied as an argument to avoid potentially costly recomputaiton. If a manually computed gap is supplied, you must also supply keepinds=Set{Int}(index) where index is the index of the nominal system in G used to compute gap.\n\nThe returned cover Gr is of the same type as G, but with a smaller number of particles. A controller designed for Gr that achieves a ncfmargin of at least g for all realizations in Gr will stabilize all realizations in the original G. The extreme case cover where Gr = Gnominal is a single realization only can be computed by calling g = nugap(G, i) where i is the index of the nominal system in G.\n\nArguments:\n\nG: An uncertain model in the form of a StateSpace{TE, Particles} (a multi-model).\ng: The radius of the balls in the νgap cover.\ngap: An optional precomputed gap\nverbose: Print progress\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.nugap","page":"API","title":"RobustAndOptimalControl.nugap","text":"nugap(G; map = map)\n\nCompute the νgap between the nominal system Gₙ represented by the first particle index in G, and all other systems in G. Returns a Particles object with the νgap for each system in G.\n\nSee with_nominal to endow uncertain values with a nominal value, and nominal to extract the nominal value.\n\nThe value returned by this function, νᵧ is useful for robust synthesis, by designing a controller for the nominal system Gₙ, that achieves an ncfmargin of at least νᵧ is guaranteed to stabilize all realizations within G. \n\nTo speed up computation for large systems, a threaded or distributed map function can be supplied, e.g., ThreadTools.tmap or Distributed.pmap.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.nugap-Tuple{LTISystem, LTISystem}","page":"API","title":"RobustAndOptimalControl.nugap","text":"nugap(sys0::LTISystem, sys1::LTISystem; kwargs...)\n\nCompute the ν-gap metric between two systems. See also ncfmargin.\n\nFor keyword arguments, see the docstring of DescriptorSystems.gnugap, reproduced below Base.Docs.DocStr(svec(\"   \\n    gnugap(sys1, sys2; freq = ω, rtolinf = 0.00001, fast = true, offset = sqrt(ϵ), \\n           atol = 0, atol1 = atol, atol2 = atol, rtol = nϵ) -> (nugapdist, fpeak)\\n\\nCompute the ν-gap distance nugapdist between two descriptor systems sys1 = (A1-λE1,B1,C1,D1) and \\nsys2 = (A2-λE2,B2,C2,D2) and the corresponding frequency fpeak (in rad/TimeUnit), where the ν-gap \\ndistance achieves its peak value. \\n\\nIf freq = missing, the resulting nugapdist satisfies 0 <= nugapdist <= 1. \\nThe value nugapdist = 1 results, if the winding number is different of zero in which case fpeak = []. \\n\\nIf freq = ω, where ω is a given vector of real frequency values, the resulting nugapdist is a vector \\nof pointwise ν-gap distances of the dimension of ω, whose components satisfies 0 <= maximum(nugapdist) <= 1. \\nIn this case, fpeak is the frequency for which the pointwise distance achieves its peak value. \\nAll components of nugapdist are set to 1 if the winding number is different of zero in which case fpeak = [].\\n\\nThe stability boundary offset, β, to be used to assess the finite zeros which belong to the\\nboundary of the stability domain can be specified via the keyword parameter offset = β.\\nAccordingly, for a continuous-time system, these are the finite zeros having \\nreal parts within the interval [-β,β], while for a discrete-time system, \\nthese are the finite zeros having moduli within the interval [1-β,1+β]. \\nThe default value used for β is sqrt(ϵ), where ϵ is the working machine precision. \\n\\nPencil reduction algorithms are employed to compute range and coimage spaces \\nwhich perform rank decisions based on rank \\nrevealing QR-decompositions with column pivoting \\nif fast = true or the more reliable SVD-decompositions if fast = false.\\n\\nThe keyword arguments atol1, atol2 and rtol, specify, respectively, \\nthe absolute tolerance for the nonzero elements of A1, A2, B1, B2, C1, C2, D1 and D2,\\nthe absolute tolerance for the nonzero elements of E1 and E2,   \\nand the relative tolerance for the nonzero elements of all above matrices.  \\nThe default relative tolerance is `nϵ, whereϵis the working machine epsilon \\nandnis the maximum of the orders of the systemssys1andsys2. \\nThe keyword argumentatolcan be used to simultaneously setatol1 = atol,atol2 = atol. \\n\\nThe keyword argumentrtolinfspecifies the relative accuracy to be used \\nto compute the ν-gap as the infinity norm of the relevant system according to [1]. \\nThe default value used forrtolinfis0.00001`.\\n   \\nMethod: The evaluation of ν-gap uses the definition proposed in [1],\\nextended to generalized LTI (descriptor) systems. The computation of winding number\\nis based on enhancements covering zeros on the boundary of the \\nstability domain and infinite zeros.\\n\\nReferences:\\n\\n[1] G. Vinnicombe. Uncertainty and feedback: H∞ loop-shaping and the ν-gap metric. \\n    Imperial College Press, London, 2001. \\n\"), nothing, Dict{Symbol, Any}(:typesig => Union{Tuple{T2}, Tuple{T1}, Tuple{DescriptorSystems.DescriptorStateSpace{T1, ET, MT} where {ET<:Union{LinearAlgebra.UniformScaling{Bool}, AbstractMatrix{T1}}, MT<:AbstractMatrix{T1}}, DescriptorSystems.DescriptorStateSpace{T2, ET, MT} where {ET<:Union{LinearAlgebra.UniformScaling{Bool}, AbstractMatrix{T2}}, MT<:AbstractMatrix{T2}}}} where {T1, T2}, :module => DescriptorSystems, :linenumber => 1033, :binding => DescriptorSystems.gnugap, :path => \"/home/runner/.julia/packages/DescriptorSystems/7S3aT/src/analysis.jl\"))\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.partition-Tuple{AbstractStateSpace, Int64, Int64}","page":"API","title":"RobustAndOptimalControl.partition","text":"partition(P::AbstractStateSpace, nw::Int, nz::Int)\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.partition-Tuple{AbstractStateSpace}","page":"API","title":"RobustAndOptimalControl.partition","text":"partition(P::AbstractStateSpace; u, y, w=!u, z=!y)\n\nPartition P into an ExtendedStateSpace.\n\nu indicates the indices of the controllable inputs.\ny indicates the indices of the measurable outputs.\nw indicates the indices of the disturbance inputs (uncontrollable), by default w is the complement of u.\nz indicates the indices of the performance outputs (not neccesarily measurable), by default z is the complement of y.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.passivity_index-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.passivity_index","text":"passivity_index(P; kwargs...)\n\nReturn\n\nγ = beginVmatrix\n(I-P)(I+P)^-1\nendVmatrix_\n\nIf γ  1, the system is passive. If the system has unstable zeros, γ = \n\nThe negative feedback interconnection of two systems with passivity indices γ₁ and γ₂ is stable if γ₁γ₂  1.\n\nA passive system has a Nyquist curve that lies completely in the right half plane, and satisfies the following inequality (dissipation of energy)\n\nint_0^T y^T u dt  0  T\n\nThe negative feedback-interconnection of two passive systems is stable and  parallel connections of two passive systems as well as the inverse of a passive system are also passive. A passive controller will thus always yeild a stable feedback loop for a passive system. A series connection of two passive systems is not always passive.\n\nSee also ispassive, passivityplot.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.passivityplot","page":"API","title":"RobustAndOptimalControl.passivityplot","text":"passivityplot(sys, args...; hz=false)\npassivityplot(LTISystem[sys1, sys2...], args...; hz=false)\n\nPlot the passivity index of a LTISystem(s). The system is passive for frequencies where the index is < 0.\n\nA frequency vector w can be optionally provided.\n\nIf hz=true, the plot x-axis will be displayed in Hertz, the input frequency vector is still treated as rad/s.\n\nkwargs is sent as argument to Plots.plot.\n\nSee passivity_index for additional details. See also ispassive, passivity_index.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.performance_mapping","page":"API","title":"RobustAndOptimalControl.performance_mapping","text":"performance_mapping(P::ExtendedStateSpace)\n\nReturn the system from w -> z See also performance_mapping, system_mapping, noise_mapping\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.robstab-Tuple{UncertainSS, Vararg{Any}}","page":"API","title":"RobustAndOptimalControl.robstab","text":"robstab(M0::UncertainSS, w=exp10.(LinRange(-3, 3, 1500)); kwargs...)\n\nReturn the robust stability margin of an uncertain model, defined as the inverse of the structured singular value. Currently, only diagonal complex perturbations supported.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.schur_form-Tuple{Any}","page":"API","title":"RobustAndOptimalControl.schur_form","text":"sysm, T, SF = schur_form(sys)\n\nBring sys to Schur form.\n\nThe Schur form is characterized by A being Schur with the real values of eigenvalues of A on the main diagonal. T is the similarity transform applied to the system such that \n\nsysm ≈ similarity_transform(sys, T)\n\nSF is the Schur-factorization of A.\n\nSee also modal_form and hess_form\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.show_construction-Tuple{IO, LTISystem}","page":"API","title":"RobustAndOptimalControl.show_construction","text":"show_construction([io::IO,] sys::LTISystem; name = \"temp\", letb = true)\n\nPrint code to io that reconstructs sys.\n\nletb: If true, the code is surrounded by a let block.\n\njulia> sys = ss(tf(1, [1, 1]))\nStateSpace{Continuous, Float64}\nA = \n -1.0\nB = \n 1.0\nC = \n 1.0\nD = \n 0.0\n\nContinuous-time state-space model\n\njulia> show_construction(sys, name=\"Jörgen\")\nJörgen = let\n    JörgenA = [-1.0;;]\n    JörgenB = [1.0;;]\n    JörgenC = [1.0;;]\n    JörgenD = [0.0;;]\n    ss(JörgenA, JörgenB, JörgenC, JörgenD)\nend\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.sim_diskmargin","page":"API","title":"RobustAndOptimalControl.sim_diskmargin","text":"sim_diskmargin(P::LTISystem, C::LTISystem, σ::Real = 0)\n\nSimultaneuous diskmargin at both outputs and inputs of P. Ref: \"An Introduction to Disk Margins\", Peter Seiler, Andrew Packard, and Pascal Gahinet https://arxiv.org/abs/2003.04771 See also ncfmargin.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.sim_diskmargin-2","page":"API","title":"RobustAndOptimalControl.sim_diskmargin","text":"sim_diskmargin(L, σ::Real = 0, l=1e-3, u=1e3)\n\nReturn the smallest simultaneous diskmargin over the grid l:u See also ncfmargin.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.sim_diskmargin-Tuple{LTISystem, Real, AbstractVector}","page":"API","title":"RobustAndOptimalControl.sim_diskmargin","text":"sim_diskmargin(L, σ::Real, w::AbstractVector)\nsim_diskmargin(L, σ::Real = 0)\n\nSimultaneuous diskmargin at the outputs of L.  Users should consider using diskmargin.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.specificationplot","page":"API","title":"RobustAndOptimalControl.specificationplot","text":"specificationplot([S,CS,T], [WS,WU,WT])\n\nThis function visualizes the control synthesis using the hinfsynthesize with the three weighting functions W_S(s) W_U(s) W_T(s) inverted and scaled by γ, against the corresponding transfer functions S(s) C(s)S(s) T(s), to verify visually that the specifications are met. This may be run using both MIMO and SISO systems.\n\nKeyword args\n\nwint: (-3, 5) frequency range (log10)\nwnum: 201 number of frequency points\nhz: true\nnsigma: typemax(Int) number of singular values to show\ns_labels: `[   \"σ(S)\",   \"σ(CS)\",   \"σ(T)\",\n\n]`\n\nw_labels: `[   \"γ σ(Wₛ⁻¹)\",   \"γ σ(Wᵤ⁻¹)\",   \"γ σ(Wₜ⁻¹)\",\n\n]`\n\ncolors: [:blue, :red, :green] colors for S, CS and T\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.splitter","page":"API","title":"RobustAndOptimalControl.splitter","text":"splitter(u::Symbol, n::Int, timeevol = Continuous())\n\nReturn a named system that splits an input signal into n signals. This is useful when an external signal entering a block diagram is to be connected to multiple inputs. See the tutorial  https://juliacontrol.github.io/RobustAndOptimalControl.jl/dev/hinf_connection/ for example usage. An alternative way of connecting an external input to several input ports with the same name is to pass connect(..., unique=false).\n\nArguments:\n\nu: Named of the signal to split\nn: Number of splits\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.ss2particles-Tuple{Vector{<:AbstractStateSpace}}","page":"API","title":"RobustAndOptimalControl.ss2particles","text":"ss2particles(G::Vector{<:AbstractStateSpace})\n\nConverts a vector of state space models to a single state space model with coefficient type MonteCarloMeasurements.Particles.\n\nSee also sys_from_particles.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.ssdata_e-Tuple{ExtendedStateSpace}","page":"API","title":"RobustAndOptimalControl.ssdata_e","text":"A, B1, B2, C1, C2, D11, D12, D21, D22 = ssdata_e(sys)\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.static_gain_compensation","page":"API","title":"RobustAndOptimalControl.static_gain_compensation","text":"static_gain_compensation(l::LQGProblem, L = lqr(l))\nstatic_gain_compensation(A, B, C, D, L)\n\nFind L_r such that\n\ndcgain(closedloop(G)*Lr) ≈ I\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.structured_singular_value-Tuple{LTISystem, AbstractVector}","page":"API","title":"RobustAndOptimalControl.structured_singular_value","text":"structured_singular_value(M0::UncertainSS, [w::AbstractVector]; kwargs...)\n\nw: Frequency vector, if none is provided, the maximum μ over a grid 1e-3 : 1e3 will be returned.\n\nAn example is provided in the documentation\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.structured_singular_value-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T","page":"API","title":"RobustAndOptimalControl.structured_singular_value","text":"μ = structured_singular_value(M; tol=1e-4, scalings=false, dynamic=false)\n\nCompute (an upper bound of) the structured singular value μ for diagonal Δ of complex perturbations (other structures of Δ are not yet supported). M is assumed to be an (n × n × N_freq) array or a matrix.\n\nWe currently don't have any methods to compute a lower bound, but if all perturbations are complex the spectral radius ρ(M) is always a lower bound (usually not a good one).\n\nIf scalings = true, return also a n × nf matrix Dm with the diagonal scalings D such that\n\nD = Diagonal(Dm[:, i])\nσ̄(D\\M[:,:,i]*D)\n\nis minimized.\n\nIf dynamic = true, the perturbations are assumed to be time-varying Δ(t). In this case, the same scaling is used for all frequencies and the returned D if scalings=true is a vector d such that D = Diagonal(d).\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.sumblock-Tuple{String}","page":"API","title":"RobustAndOptimalControl.sumblock","text":"sumblock(ex::String; Ts = 0, n = 1)\n\nCreate a summation node (named statespace system) that sums (or subtracts) vectors of length n.\n\nArguments:\n\nTs: Sample time\nn: The length of the input and output vectors. Set n=1 for scalars.\n\nWhen using sumblock to form block diagrams, note how the system returned from sumblock has input names corresponding to the right-hand side of the expression and output names corresponding to the variable on the left-hand side. You will thus typically list connections like :y => :y in the connection list to the connect function. See the tutorials\n\nhttps://juliacontrol.github.io/RobustAndOptimalControl.jl/dev/hinf_connection/\nhttps://juliacontrol.github.io/RobustAndOptimalControl.jl/dev/api/#RobustAndOptimalControl.connect-Tuple{Any}\n\nfor example usage\n\nExamples:\n\njulia> sumblock(\"uP = vf + yL\")\nNamedStateSpace{Continuous, Int64}\nD = \n 1  1\n\nWith state  names: \n     input  names: vf yL\n     output names: uP\n\n\njulia> sumblock(\"x_diff = xr - xh\"; n=3)\nNamedStateSpace{Continuous, Int64}\nD = \n 1  0  0  -1   0   0\n 0  1  0   0  -1   0\n 0  0  1   0   0  -1\n\nWith state  names: \n     input  names: xr1 xr2 xr3 xh1 xh2 xh3\n     output names: x_diff1 x_diff2 x_diff3\n     \n\njulia> sumblock(\"a = b + c - d\")\nNamedStateSpace{Continuous, Int64}\nD = \n 1  1  -1\n\nWith state  names: \n     input  names: b c d\n     output names: a\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.sys_from_particles-Tuple{Any, Any}","page":"API","title":"RobustAndOptimalControl.sys_from_particles","text":"sys_from_particles(P, i)\nsys_from_particles(P)\n\nReturn the ith system from a system P with Particles coefficients.\n\nIf called without an index, return a vector of systems, one for each possible i.\n\nThis function is used to convert from an uncertain representation using Particles to a \"multi-model\" representation using multiple StateSpace models.\n\nSee also ss2particles, mo_sys_from_particles and MonteCarloMeasurements.nominal.\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.system_mapping","page":"API","title":"RobustAndOptimalControl.system_mapping","text":"system_mapping(P::ExtendedStateSpace)\n\nReturn the system from u -> y See also performance_mapping, system_mapping, noise_mapping\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.uss","page":"API","title":"RobustAndOptimalControl.uss","text":"uss(d::AbstractVector{<:δ}, Ts = nothing)\n\nCreate a diagonal uncertain statespace object with the uncertain elements d on the diagonal.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.uss-2","page":"API","title":"RobustAndOptimalControl.uss","text":"uss(D::AbstractArray, Δ, Ts = nothing)\n\nIf only a single D matrix is provided, it's treated as D11 if Δ is given, and as D22 if no Δ is provided.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.uss-3","page":"API","title":"RobustAndOptimalControl.uss","text":"uss(D11, D12, D21, D22, Δ, Ts = nothing)\n\nCreate an uncertain statespace object with only gin matrices.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.uss-Union{Tuple{δ{C, F}}, Tuple{F}, Tuple{C}, Tuple{δ{C, F}, Any}} where {C, F}","page":"API","title":"RobustAndOptimalControl.uss","text":"uss(d::δ{C, F}, Ts = nothing)\n\nConvert a δ object to an UncertainSS\n\n\n\n\n\n","category":"method"},{"location":"api/#RobustAndOptimalControl.vec2sys","page":"API","title":"RobustAndOptimalControl.vec2sys","text":"vec2sys(v::AbstractArray, ny::Int, nu::Int, ts = nothing)\n\nCreate a statespace system from the parameters\n\nv = vec(sys) = [vec(sys.A); vec(sys.B); vec(sys.C); vec(sys.D)]\n\nUse vec(sys) to create v.\n\nThis can be useful in order to convert to and from vectors for, e.g., optimization.\n\njulia> sys  = ss(tf(1, [1, 1]))\nStateSpace{Continuous, Float64}\nA = \n -1.0\nB = \n 1.0\nC = \n 1.0\nD = \n 0.0\n\nContinuous-time state-space model\n\njulia> v    = vec(sys)\n4-element Vector{Float64}:\n -1.0\n  1.0\n  1.0\n  0.0\n\njulia> sys2 = vec2sys(v, sys.ny, sys.nu)\nStateSpace{Continuous, Float64}\nA = \n -1.0\nB = \n 1.0\nC = \n 1.0\nD = \n 0.0\n\nContinuous-time state-space model\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.δc","page":"API","title":"RobustAndOptimalControl.δc","text":"δc(val::Complex = complex(0.0), radius::Real = 1.0, name)\n\nCreate a complex, uncertain parameter. If no name is given, a boring name will be generated automatically.\n\n\n\n\n\n","category":"function"},{"location":"api/#RobustAndOptimalControl.δr","page":"API","title":"RobustAndOptimalControl.δr","text":"δr(val::Real = 0.0, radius::Real = 1.0, name)\n\nCreate a real, uncertain parameter. If no name is given, a boring name will be generated automatically.\n\n\n\n\n\n","category":"function"},{"location":"similarity/#When-are-two-systems-similar?","page":"When are systems similar?","title":"When are two systems similar?","text":"","category":"section"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"What does it mean for two systems to be similar to each other? Well, it depends on how we measure similarity. How we chose to measure similarity between two systems, or two models of the same system, may depend on what we are going to use the models for. In this little example, borrowed from the nice book","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"Feedback Systems: An Introduction for Scientists and Engineers, by Åström and Murray","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"we will consider three different system models:","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"P_1 = dfrac100s + 1 quad P_2 = dfrac100(s+1)(0025s+1)^2 quad P_3 = dfrac100s-1","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"using ControlSystemsBase, RobustAndOptimalControl, Plots\ns = tf(\"s\")\nP1 = 100 / (s + 1)\nP2 = 100 / ((s+1)*(0.025s+1)^2)\nP3 = 100 / (s - 1)\nnothing # hide","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"We start by having a look at the step responses of models P_1 and P_2:","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"plot(step.([P1, P2], 6), lab=[\"P1\" \"P2\"])","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"They sure look very similar, don't they? If we observed some noisy data from an experiment that look something like this","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"using Random; Random.seed!(8) # hide\nres = step(P1, 0:0.1:6)\nscatter!(res.t, res.y' .+ 2 .* randn.(), lab=\"Noisy observed data\")","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"it would be very difficult to tell which of the two models P_1 and P_2 that best fit the data. However, if we now close the loop around these two \"similar\" models, we get the following:","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"plot(step.([feedback(P1), feedback(P2)], 0.3))","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"Wow, that's a pretty big difference! Closing the loop around P_1 resulted in a stable system, while closing the loop around P_2 resulted in an unstable system! Surely, these two models cannot be considered similar to each other? ","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"Let's move on and compare the step responses of models P_1 and P_3:","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"plot(step.([P1, P3], 2), lab=[\"P1\" \"P3\"], c=[1 3])","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"These two are obviously very dissimilar, one being stable and the other one not, yet, when we close the loop around these two models, we get the following:","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"plot(step.([feedback(P1,1), feedback(P3,1)], 0.3), c=[1 3])","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"we get very similar step responses! So, what does it really mean for two systems to be similar to each other? Simply looking at a simulation of the system might not always be sufficient. Let's have a look at the classical Bode and Nyquist curves:","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"plot(\n    bodeplot([P1, P2, P3], lab=[\"P1\" \"\" \"P2\" \"\" \"P3\" \"\"]),\n    nyquistplot([P1, P2, P3], lab=[\"P1\" \"P2\" \"P3\"], xlims=(-5,5), ylims=(-20,1), unit_circle=true),\n)","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"Interestingly, all three models have the same gain for low frequencies, but the phase curves, and thus also the Nyquist curves, differ a lot. The Nyquist curve gives us an intuitive indication of how the system will perform when we close the loop. Here, the two models that are similar to each other are P_1 and P_3 (at least with these axis limits), while the model P_2 clearly encircles the critical point -1 in an unfortunate way.[1]","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"What measure of similarity could we then use that takes into account how the system will perform when we close the loop? If we have a look at a standard similarity measure such as the H_infty norm, we get that the models P_1 and P_2 are somewhat similar to each other, while P_1 and P_3 are not:","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"hinfnorm(P1 - P2)[1], hinfnorm(P1 - P3)[1]","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"this does not align at all with how the systems behaved under feedback. Another metric, suitable for measuring similarity between systems when they are used in feedback, is the nu-gap metric (nugap or νgap):","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"νgap(P1, P2)[1], νgap(P1, P3)[1]","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"this metric is always between 0 and 1, and a small \"gap\" indicates that the two models compared are similar. This metric aligns much better with how the systems behaved under feedback, indicating that P_1 and P_3 are similar to each other, while P_1 and P_2 are not.","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"This metric has an interesting relation to the normalized-coprime factor margin, ncfmargin: If controller K stabilizes P with an ncfmargin(P, K) = m, then K will also stabilize all systems P with a nu-gap from P of at most m. This means that if our model error is small in the sense that the nu-gap is small, and we design a controller with a large NCF-margin, then we can be confident that the controller will still stabilize the system even if the model is not perfect!","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"This property of the nu-gap metric and the NCF-margin is very useful in practice, and can be used for model-order reduction with guaranteed preservation of stability etc. see baltrunc_coprime and Model-order reduction for uncertain models for more info on this topic.","category":"page"},{"location":"similarity/#Summary","page":"When are systems similar?","title":"Summary","text":"","category":"section"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"This example has demonstrated that what it means for two models to be similar to each other might not always be a straightforward question to answer. Models that have very similar step responses, and simulation characteristics in general, might behave dramatically different when placed in a feedback loop. ","category":"page"},{"location":"similarity/","page":"When are systems similar?","title":"When are systems similar?","text":"[1]: The experienced control theorist might recognize that it's in this case enough to lower the feedback gain to get a stable closed-loop system also for the system P_2. With feedback gain 0.2 instead of 1, we get a reasonable well-damped response with a phase margin of 47° and a gain margin above 4.","category":"page"},{"location":"cartpole/#Control-design-for-a-pendulum-on-a-cart","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"In this example we will consider control design for the basic inverted pendulum on a cart. This system has two equilibria, one where the pendulum is hanging straight down, and one where it's balancing straight up. The upper one is unstable, making it slightly more interesting to design a controller for (even if the lower equilibrium is highly relevant, it's a good model for an overhead crane moving goods).","category":"page"},{"location":"cartpole/#System-model","page":"Control design for a pendulum on a cart","title":"System model","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"In this tutorial, we assume that we have the nonlinear dynamics of the system encodeed as a julia function ẋ = cartpole(x, u), and linearize this to get a statespace system","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"beginaligned\nx = Ax + Bu\ny = Cx\nendaligned","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We make use of ForwardDiff.jl for the linearization. We start by defining the dynamics function","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"using ControlSystemsBase, RobustAndOptimalControl, ForwardDiff, LinearAlgebra, Plots\ndefault(label=\"\") # hide\n\nfunction cartpole(x, u)\n    mc, mp, l, g = 1.0, 0.2, 0.5, 9.81\n\n    q  = x[1:2]\n    qd = x[3:4]\n\n    s = sin(q[2])\n    c = cos(q[2])\n\n    H = [mc+mp mp*l*c; mp*l*c mp*l^2]\n    C = [0.1 -mp*qd[2]*l*s; 0 0]\n    G = [0, mp * g * l * s]\n    B = [1, 0]\n\n    qdd = -H \\ (C * qd + G - B * u[1])\n    return [qd; qdd]\nend\n\nnu = 1    # number of control inputs\nnx = 4    # number of states\nny = 2    # number of outputs (here we assume that the cart position and the pendulum angle are measurable)\nnothing # hide","category":"page"},{"location":"cartpole/#Linearization","page":"Control design for a pendulum on a cart","title":"Linearization","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The next step is to choose an operating point around which to linearize and to calculate the Jacobians A and B:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"x0 = [0, π, 0, 0]\nu0 = [0]\n\nAc = ForwardDiff.jacobian(x->cartpole(x, u0), x0)\nBc = ForwardDiff.jacobian(u->cartpole(x0, u), u0)\nCc = [1 0 0 0; 0 1 0 0]\nΛ = Diagonal([0.4, deg2rad(25)]) # Maximum output ranges\nCc = Λ\\Cc # This normalizes expected outputs to be ∈ [-1, 1], a good practice for MIMO systems\nnothing # hide","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"we package everything into a StateSpace object and visualize its poles and zeros:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"sys = ss(Ac, Bc, Cc, 0)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"pzmap(sys)","category":"page"},{"location":"cartpole/#Control-design","page":"Control design for a pendulum on a cart","title":"Control design","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We will design a number of different controllers. We will start with a basic PID controller. Since the PID controller in its standard form really only handles SISO systems, we will also design a state-feedback controller with an observer to estimate the full state vector x based on the two measurements y. Lastly, we will attempt to \"robustify\" the state-feedback controller using the glover_mcfarlane procedure.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Since the system has an unstable pole p approx 485rad/s, there wil be fundamental limitations on the performance of the closed loop system. A common rule-of-thumb (see, e.g., Åström and Murray) is that a single RHP pole p puts a lower limit on the gain crossover frequency omega_gc  2p, something to take into consideration when tuning our controllers. ","category":"page"},{"location":"cartpole/#PID-controller","page":"Control design for a pendulum on a cart","title":"PID controller","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Since the PID controller only accepts a single measurement, we choose the measurement of the pendulum angle for feedback. While doing so, we notice that the number of states in the model can be reduced by the function sminreal","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"P = sminreal(sys[2,1]) # Position state goes away, not observable","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"this indicates that the state corresponding to the position of the cart is not observable from the measurement of the pendulum angle. This is slightly worrisome, but we nevertheless proceed to design a controller. By using a single measurement only, we have also introduced a zero in the system","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"pzmap(P)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"A PID controller can be constructed using the function pid. We start our tuning by a simple P controller","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"C = pid(1, 0, 0)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We will attempt to perform loop shaping using the PID controller, and plot the stability margins in a Bode plot using the function marginplot","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"w = exp10.(LinRange(-2.5, 3, 500))\nfunction pid_marginplot(C)\n    f1 = marginplot(P*C, w)\n    vline!([2*4.85], sp=1, lab=\"Fundamental limitation\", l=(:dash, :black))\n    ylims!((1e-3, 1e2), sp=1)\n    f2 = nyquistplot(P*C)\n    plot(f1, f2)\nend\npid_marginplot(C)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We notice that the gain of the loop-transfer function L = PC is much too low, and increase it, we also notice that the Nyquist plot fails to encircle to critical point, which it has to do once since we have one unstable pole. We will solve this in the end by adding integral action, but proceed for now to shape other parts of the loop. We start by lifting the Bode curve by increasing the gain:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"C = pid(20, 0, 0)\npid_marginplot(C)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"we are now getting close to the rule-of-thumb for omega_gc, but have a low loop gain at low frequencies. Remember, to get good disturbance rejection, we typically want a high loop gain at low frequencies. We also have an extremely small phase margin at 0.66 degrees. To fix the phase margin, we add some derivative gain. While adding derivative gain, it's also a good idea to add noise filtering (with a pure derivative term, the PID controller is not proper and can not be realized as a statespace system)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"C = pid(20, 0, 0.2, Tf=0.01)\npid_marginplot(C)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The derivative term lifted the phase at omega_gc and we now have very nice phase margins. We also got a slight increase in omega_gc while at it. ","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The closed-loop system will still be unstable since the Nyquist curve fails to encircle the point -1, something we can check by calling","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"isstable(feedback(P*C))","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We make the Nyquist curve wrap around the -1 point by adding integral gain:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"C = pid(20, 1.25, 0.2, Tf=0.01)\npid_marginplot(C)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Now, the Nyquist curve looks fine and the system is stable","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"isstable(minreal(feedback(P*C)))","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"If we simulate a disturbance acting on this system (feedback(P, C) is the transfer function from load disturbance to output)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"plot(step(feedback(P,C), 8), ylab=\"ϕ\")","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"we see that we have a reasonable disturbance response. ","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"To verify robustness properties, we plot the gang-of-four sensitivity functions:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"f1 = gangoffourplot(P,C,w, Ms_lines=[1.4], Mt_lines=[1.5])\nf2 = nyquistplot(P*C, Ms_circles=[1.4], Mt_circles=[1.5], ylims=(-2, 2), xlims=(-4,1))\nplot(f1, f2, size=(1000,800))","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"This all looks nice and we appear to have reasonable robustness margins, the Nyquist curve stays outside the M_S = 14 circle and the M_T = 15 circle.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"However, there is a dragon lurking behind these plots. Remember the state corresponding the the cart position that was removed above? What has happened to this state? To investigate this, we form an ExtendedStateSpace model where we have both cart position and pendulum angle as controlled outputs, while keeping only the pendulum angle as measured output:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Pe = ExtendedStateSpace(sys, C2 = sys.C[2:2, :]) # Indicate that we can only measure the pendulum angle\nGecl = feedback(Pe, ss(C)) |> minreal\nplot(step(Gecl, 8), ylab=[\"Cart pos\" \"ϕ\"])","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We see that the cart position drifts away without ever thinking about stopping. Indeed, the PID controller is unaware of this and can not really do anything about it. We could attempt to design a second control loop that would close the loop around the cart position, but we would have to carefully manage the interactions between the two loops. Instead, we move on to a state-feedback design, a methodology that makes handling multiple outputs much more straightforward. ","category":"page"},{"location":"cartpole/#Pole-placement-and-observer-design","page":"Control design for a pendulum on a cart","title":"Pole placement and observer design","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The design of a state-feedback controller typically involves two steps, designing the feedback gain and designing an observer. We will arrive at the feedback gain through pole placement, but will design the observer as a Kalman filter, i.e., by solving a Riccati equation rather than using Ackermann's formula. ","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"When performing pole placement, there are a number of design guidlines that help you arrive at a robust design. One of these are that past process poles should be matched with an equally fast closed-loop pole. We can get an overview of the open-loop poles with dampreport","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"dampreport(sys)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"we see that we have two poles at roughly pm 485rad/s, and almost two integrators. We thus keep the fast pole, and place the unstable pole at the same location (same bandwidth but stable instead of unstable). We also try to move the integrator poles to -5 to make the system nice and fast. ","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"desired_poles = [-4.85, -4.85, -5, -5]\nL = place(sys, desired_poles, :c)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"For the observer, we make use of the function kalman. We choose the covariance matrices R1, R2 that determine the amount of noise acting on the system and on the measurements respectively. We assume that there are two noise components, both entering as forces. One disturbance force acts on the cart and the other on the pendulum. We indicate this using the matrix B_w. ","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Bw = [0 0; 0 0; 1 0; 0 1]\nR1 = Bw*I(2)*Bw'\nR2 = 0.0001I(ny)\nK = kalman(sys, R1, R2)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"With our feedback gain L and the Kalman gain K, we form the controller using observer_controller","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"controller = observer_controller(sys, L, K)\n@assert isstable(controller)\n@assert isstable(feedback(sys * controller))","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We may have a look at the Nyquist plot and the gang-of-four to assess robustness margins. In this case we look at the loop transfer function at the input simply because this function is SISO while the standard output-loop transfer is MIMO. This will allow us to asses robustness w.r.t. input perturbations only","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"nyquistplot(controller*sys, w, Ms_circles=[2.7], Mt_circles=[3], xlims=(-2, 2), ylims=(-1, 3))","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The Nyquist plot shows a rather weak robustness margin, with a peak in the input sensitivity of about","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"round(hinfnorm2(input_sensitivity(sys, controller))[1], digits=2) # hide","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"and a peak in the complementary sensitivity function of around","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"round(hinfnorm2(input_comp_sensitivity(sys, controller))[1], digits=2) # hide","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"These can be verified by calling hinfnorm2","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"hinfnorm2(input_comp_sensitivity(sys, controller))","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"note: Hover information\nIf you plot with the Plotly backend, activated by calling plotly() if you have Plotly.jl installed, you can hover the mouse over the Nyquist curve and the gain circles to see frequency information etc. This is not possible when using the default GR backend, used in this documentation.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Also the gang-of-four indicate rather poor margins:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"gangoffourplot(sys, controller, w, xlabel=\"\", sigma=false, titlefont=8)","category":"page"},{"location":"cartpole/#Robustification-using-Glover-McFarlane","page":"Control design for a pendulum on a cart","title":"Robustification using Glover-McFarlane","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"In an attempt at improving this initial design, we call glover_mcfarlane. This can be seen as a semi-automatic approach to robustifying an initial design, and will yield us an updated controller Kgmf with, hopefully, improved robustness properties.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Kgmf, γ, info = glover_mcfarlane(sys, 1.05; W1=controller)\n@assert isstable(Kgmf)\nγ","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The γ is an indication of the achieved robustness. A value of γ  4 is typically desired, this time we did not quite achieve that, but will nevertheless proceed and look deeper into the robustness using other means.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"note: Controller order reduction\nThe Glover-McFarlane procedure often leads to high-order controllers. These controllers can sometimes be simplified by calling controller_reduction, i.e., like thisKgmfr, hs = controller_reduction(ExtendedStateSpace(sys), -Kgmf, 9) # Expects positive-feedback controller\nKgmfr = -Kgmfr # Flip sign again\nKgmfr.D .*= 0.0 # a hack to get better rolloff after reduction\nnothing # hide","category":"page"},{"location":"cartpole/#Robustness-verification","page":"Control design for a pendulum on a cart","title":"Robustness verification","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We will now verify these designs in a number of ways. We start by inspecting sensitivity functions at the input, this function tells you how a load disturbance at the plant input translates to total plant input (including control action)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"f1 = bodeplot([controller*sys, Kgmf*sys], w, plot_title=\"Input Loop transfers\", lab=[\"Pole placement\" \"\" \"GMF\" \"\"]); vline!([2*4.85], sp=1, lab=\"Fundamental limitation\", l=(:dash, :black))\nf2 = nyquistplot([controller*sys, Kgmf*sys], xlims=(-4, 4), ylims=(-1, 5), Ms_circles=[2.7], Mt_circles=[3], lab=[\"Pole placement\" \"GMF\"])\nf3 = bodeplot(controller, w, lab=\"Pole placement\")\nbodeplot!(Kgmf, w, plot_title=\"Controllers\", lab=\"GMF\", legend=:bottomleft)\nf4 = sigmaplot([\n    input_sensitivity(sys, controller),\n    input_sensitivity(sys, Kgmf)\n    ], w, title=\"Input S\", lab=[\"Pole placement\" \"GMF\"], legend=:bottomright)\nplot(f1,f2,f3,f4, size=(1000,1000))","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We see that the Glover-Mcfarlane method increased the gain crossover frequency omega_gc slightly compared to the initial pole-placement controller, as well as lifted the phase even further. It also increased the roll-off, providing better filtering of high-frequency noise. However, it uses quite a bit more gain from the measurement of the pendulum angle.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The gang-of-four, shown below, looks slightly better for the GMF controller, shown in orange.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"gangoffourplot(sys, [controller, Kgmf], w, xlabel=\"\", sigma=false, titlefontsize=8)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The robustified controller has better disturbance rejection (P(I + PC)) and slightly lower peaks in the sensitivity and complementary sensitivity functions.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Inspecting the singular values of the output sensitivity, we see that the GMF controller reduces the peak and improves the disturbance rejection for the lower singular value, while leaving the upper singular value more or less where it is for low frequencies.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"sigmaplot(sensitivity.(Ref(sys), [controller, Kgmf]), w, lab=[\"Pole placement\" \"GMF\"], legend=:bottomright)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Further verification of robustness properties can be conducted by inspecting the diskmargins at inputs and at outputs","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"dmf1 = plot(diskmargin(sys*controller), title=\"Simultaneous Output diskmargin\", lab=\"Pole placement\")\ndmf2 = plot(diskmargin(controller*sys), title=\"Input diskmargin\", lab=\"Pole placement\")\nplot!(dmf1, diskmargin(sys*Kgmf), title=\"Simultaneous Output diskmargin\", lab=\"GMF\")\nplot!(dmf2, diskmargin(Kgmf*sys), title=\"Input diskmargin\", lab=\"GMF\")\nplot(dmf1, dmf2)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"With the robustified controller, ee can tolerate a gain variation of about 1.6 at the plant input, but only 1.23 at the plant output. Please note that simultaneous margins can be quite conservative, it's much less likely that both outputs have equally large gain errors at the same time. One can also investigate the margins for one loop at a time using loop_diskmargin.","category":"page"},{"location":"cartpole/#Simulation","page":"Control design for a pendulum on a cart","title":"Simulation","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Finally, it's time to simulate the system. First we simulate the response to a reference step for the cart position, to make sure the cart takes a reasonalbe smooth step, keeping the pendulum angle within the validity range of the linearization, we let the step be a ramp from 0 to 1 over the course of one second, implemented by passing the input function u(xt) rightarrow operatornamemin(t 1)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"rampsim(sys) = lsim(sys[:, 1], (x,t)->[min(t, 1)], 0:0.01:3.5, method=:zoh) # helper function to simulate ramp input\nplot([\n    rampsim(feedback(sys*controller)),\n    rampsim(feedback(sys*Kgmf)),\n], ylab=[\"Pos\" \"Angle\"], plot_title=\"Position command step response\", lab=[\"Pole placement\" \"\" \"GMF\" \"\"], legend=:bottomright)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Then we simulate the response to an impulsive disturbance acting on the cart (i.e., someone hit it with a hammer)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"plot([\n    impulse(feedback(sys, controller), 8, method=:zoh),\n    impulse(feedback(sys, Kgmf), 8, method=:zoh),\n], ylab=[\"Pos\" \"Angle\"], plot_title=\"Disturbance step response\", lab=[\"Pole placement\" \"\" \"GMF\" \"\"], legend=:bottomright)","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"This time, the controllers control also the cart position while keeping the pendulum stabilized. Interestingly, while the GMF controller appears a bit slower during the reference change, maintaining a more conservative maximum angle of the pendulum, it is significantly faster in recovering from the disturbance.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We can also animate the system:","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"sim_pp  = rampsim(feedback(sys*controller))\nsim_gmf = rampsim(feedback(sys*Kgmf))\n@gif for i in 1:3:length(sim_pp.t)\n    p, a = sim_pp.y[:, i]\n    plot([p; p - 0.5sin(a)], [0; 0.5cos(a)], lw = 1, markershape = :square, markersize=[8, 1], lab = \"PP\", dpi = 200, size=(700, 200))\n\n    p, a = sim_gmf.y[:, i]\n    plot!([p; p - 0.5sin(a)], [0; 0.5cos(a)], lw = 1, markershape = :square, markersize=[8, 1], lab = \"GMF\", xlims = (-1, 2.2),\n        ylims = (-0.2, 0.6), title = \"Inverted pendulum control\",\n        dpi = 200, aspect_ratio = 1)\nend","category":"page"},{"location":"cartpole/#Cascade-control","page":"Control design for a pendulum on a cart","title":"Cascade control","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The system considered in this example has a single input, but more than one output (position and angle). When we neglected the measurement of the position of the cart and closed the loop around the angle only, we got an unstable system when considering the cart position as well. However, we could add an \"outer controller\" in cascade with the inner PID controller we designed above, and let the outer controller control the position of the cart. This kind of control architecture is often called a cascade controller, and this is a common and simple way to design a controller for a SIMO system. Below, we add a PI controller for the cart position and simulate the same response to an input disturbance as we did above. It's important to not tune this outer controller too hard or it will start to destabilize the inner system.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"Cp = pid(-1, 5; state_space=true) # Position controller\nGtotal = feedback(Gecl, Cp, Y1=[1]) # Indicate that the outer controller can only see the cart position (y1)\nplot(step.([Gecl, Gtotal], 20), lab=[\"Only angle feedback\" \"\" \"Cascade control\" \"\"], legend=:bottomright, ylims=[(-5, 0.2) (-Inf, Inf)])","category":"page"},{"location":"cartpole/#Conclusion","page":"Control design for a pendulum on a cart","title":"Conclusion","text":"","category":"section"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We started out designing a PID controller and used the Bode plot to guide the tuning. While we ended up with a controller with good robustness margins, we had completely forgotten about the cart position and the controller turned out to not stabilize this \"hidden state\". We include this example here as an example of following a mostly sound procedure, leading to a robust controller, but failing to meet real-world constraints due to lack of observability. To stabilize also the cart position, we added an outer position controller in cascade with the inner angle controller.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"The loop-shaping procedure yielded a controller that stabilized all states of the plant, but with questionable robustness margins. In practice, pole placement can be rather difficult and it's not always obvious where to place the poles to achieve a robust design. In this case, a robust design is very hard to achieve with a pole-placement controller without model augmentation, the poor robustness of the pole-placement controller compared to the PID controller is due to the low gain at low frequencies, indeed, the pole placement controller lacks integral action! See Disturbance modeling and rejection with LQG controllers for a tutorial on how to add integral action to state-feedback controllers by augmenting the system model with a disturbance model.","category":"page"},{"location":"cartpole/","page":"Control design for a pendulum on a cart","title":"Control design for a pendulum on a cart","text":"We looked at several different ways of quantifying robustness of a system with multiple outputs, and tried our luck with a procedure for automatic robustification, glover_mcfarlane. In this case, the procedure worked and we got a slightly more robust controller as a result, this controller also increased the gain for low frequencies significantly, further indicating that the low-frequency gain was a source of problems for the pole-placement controller. The result of the Glover-McFarlane procedure may either be used directly as the final controller, or to provide insight into how the procedure modifies the existing controller in order to improve robustness.","category":"page"},{"location":"hinf_DC/#Mixed-sensitivity-H_\\infty-control-design","page":"Simple mixed-sensitivity H_infty design","title":"Mixed-sensitivity H_infty control design","text":"","category":"section"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"In this tutorial, we will design a controller for a DC-servo (electrical motor).","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"The servo takes a torque command as input and we are interested in controlling the angle of the output shaft. An approximate model for a DC servo, valid for low frequencies, is","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"tau = k ( J ddotphi + cdotphi )","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"where tau is the torque and phi is the angle. The parameter J denotes the inertia of the motor and load, c is a viscous friction parameter and k is a torque constant (gain). ","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"This is a simple SISO example with a pole in the origin. Poles on the stability boundary are problematic for several numerical routines, and this tutorial demonstrates a common trick applied in these situations. ","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"We start by defining the process model. We will use the parameter values J=1 c=012 k=112 which yields the transfer function","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"G(s) = dfracks(Js + c) = dfrac112s^2 + 012s + 0","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"using RobustAndOptimalControl, ControlSystemsBase, Plots\nGtrue = tf([11.2], [1, 0.12, 0])\nnothing # hide","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"When designing a controller using H_infty synthesis, we formally specify an optimization problem where the cost function is the H_infty norm of a suitably chosen transfer function, and the optimization variable is the controller. The function hinfpartition helps us to build the transfer function that appears in the following H_infty optimization problem[1]","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"operatornameminimize_K beginVmatrix\nW_S S \nW_U KS \nW_T T\nendVmatrix_infty","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"[1]: For ill-conditioned MIMO plants, the S KS T weighting may result in controllers that \"invert\" the plant, which may result in poor robustness. For such systems, penalizing GS and T may be more appropriate. Ref: \"Inverting and noninverting H∞ controllers\", Urs Christen, Hans Geering.","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"where K is the controller and S is the sensitivity function (1+GK)^-1. The transfer functions W_S, W_T and W_U are weight functions that emphasize different frequency ranges, for example, if W_S(iomega) is large for a particular frequency omega, then S is forced to be small at omega in order for the H_infty norm to be small. ","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"In this case, we will omit the penalty on the transfer function T, and thus solve","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"operatornameminimize_K beginVmatrix\nW_S S \nW_U KS\nendVmatrix_infty","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"# Sensitivity weight function\nWS = makeweight(1e5, 0.05, 0.5) |> tf\n\n# Output sensitivity weight function. Increase this value to penalize controller effort more\nWU = ss(1.0)\n\n# Complementary sensitivity weight function\nWT = [] # We do not put any weight on T in this example\nnothing # hide","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"To solve this problem, we partition the system P in a two-input, two output configuration such that  operatornamelft_l(PK) forms the system we want to minimize the H_infty norm of with respect to K. To help with this partitioning, we have the function hinfpartition:","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"P = hinfpartition(Gtrue, WS, WU, WT)\nnothing # hide","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"The object P will now be of type ExtendedStateSpace, and represent the following P, with two input ports w,u and two output ports z,y:","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"     ┌─────────┐\nz◄───┤         │◄────w\n     │    P    │\ny┌───┤         │◄───┐u\n │   └─────────┘    │\n │                  │\n │      ┌───┐       │\n │      │   │       │\n └─────►│ K ├───────┘\n        │   │\n        └───┘","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"The operation lft(P, K) forms the feedback interconnection in the diagram, and the H_infty optimization will minimize the H_infty norm of the transfer function from w to z with respect to K.","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"Before solving, we may check if the synthesis problem is feasible","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"hinfassumptions(P, verbose=true)","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"The problem is not feasible, in this case due to the integrator pole on the stability margin. We thus modify the plant description by moving the integrator pole in the origin slightly (varepsilon) into the stable region","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"ε = 1e-4\nG = tf([11.2], [1, 0.12]) * tf([1], [1, ε])\nnothing # hide","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"If we now perform the assumption check again, it passes","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"P = hinfpartition(G, WS, WU, WT)\nhinfassumptions(P)","category":"page"},{"location":"hinf_DC/#Synthesize-the-H-infinity-optimal-controller","page":"Simple mixed-sensitivity H_infty design","title":"Synthesize the H-infinity optimal controller","text":"","category":"section"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"With the problem properly defined, we may call hinfsynthesize to solve it. The result is the controller K and a performance index gamma:","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"K, γ = hinfsynthesize(P, γrel=1.05)\nγ","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"The achieved performance level is indicated by gamma, this number is the norm we are optimizing (the H_infty norm) and it should be as low as possible.","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"note: $H_2$ optimization\nIf we instead of hinfsynthesize had called h2synthesize, we had solved the same optimization problem, but under the H_2 norm instead of the H_infty norm.","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"For verification purposes, we may extract some transfer functions defining common sensitivity functions:","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"Pcl, S, KS, T = hinfsignals(P, G, K)\nnothing # hide","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"We may also verify that the closed-loop system has H_infty norm gamma","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"Pcl == lft(P, K)\nisapprox(hinfnorm2(Pcl)[1], γ, rtol=1e-5)","category":"page"},{"location":"hinf_DC/#Plot-the-specifications","page":"Simple mixed-sensitivity H_infty design","title":"Plot the specifications","text":"","category":"section"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"The resulting sensitivity functions can be plotted together with the inverse weighting functions multiplied by gamma to get a feeling for where the constraints are active. ","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"specificationplot([S, KS, T], [WS, WU, WT], γ)","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"In this case, the noise amplification constraint is active between about 10^0 - 10^1 rad/s and the sensitivity function is pushed down for lower frequencies. In this case, the complimentary sensitivity function T = (1+GK)^-1GK has desireable properties without us specifying and penalizing this function in the optimization problem. If we would like to push this function down at certain frequencies, we may specify a non-empty weight W_T as well. The transfer function KS (labeled CS in the figure) has some natural roll-off for high frequencies. If we want steeper roll-off (more filtering), we could change the weight function WU to a transfer function with high gain for high frequencies.","category":"page"},{"location":"hinf_DC/#Generate-C-code-for-the-controller","page":"Simple mixed-sensitivity H_infty design","title":"Generate C-code for the controller","text":"","category":"section"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"The controller K is given in the form of a statespace system. The package SymbolicControlSystemsBase.jl can be used to generate C-code for such systems, making it easy to implement the controller.","category":"page"},{"location":"hinf_DC/#Video","page":"Simple mixed-sensitivity H_infty design","title":"Video","text":"","category":"section"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"For a video tutorial using this functionality, see ","category":"page"},{"location":"hinf_DC/","page":"Simple mixed-sensitivity H_infty design","title":"Simple mixed-sensitivity H_infty design","text":"<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/huYRrn--AKc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"measurable_disturbance/#Feedforward-from-known-disturbances","page":"H_2 design with a known disturbance","title":"Feedforward from known disturbances","text":"","category":"section"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"This example will demonstrate how you can make use of a known/measurable disturbance and achieve effective disturbance rejection using an mathcalH_2 controller. For simplicity, we will consider a simple first-order system G","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"beginaligned\ndotx = -ax + b(u + d) \ny_x = cx + e_y \ny_d = d + e_d\nendaligned","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"where a load disturbance d is acting on the input of the system. We have access to a measurement y_x of the state and a measurement y_d of the disturbance. Both of them are assumed corrupted by measurement noise (this fact is crucial, if there is no measurement noise on the disturbance measurement, the controller will ignore the measurement of the state).","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"We start by defining the process model.","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"using RobustAndOptimalControl, ControlSystemsBase, Plots, LinearAlgebra\nG = ss(tf(1, [10, 1])) # Process model","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"We then choose the parameters of the mathcalH_2 controller, i.e., noise variances and how much we penalize state and inputs. When tuning a mathcalH_2 controller, we do not choose matrices in quite the same way as when we tune an LQG controller, but an LQG controller is actually a mathcalH_2 in disguise, see sec. 9.3.3 in Skogestad for more details. ","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"We will partition the system according to","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"beginbmatrix\ndot x  hline z_y  z_u  hline y_x  y_d\nendbmatrix=\nbeginbmatrix\nA    B_d  0  0  B_u  hline\nC_z  0    0  0  0   \n0    0    0  0  r    hline\nC    0    1  0  0   \n0    1    0  1  0   \nendbmatrix\nbeginbmatrix\nx  hline d  e_y  e_d  hline u\nendbmatrix","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"where C_z = qC and B_d = w_d B.","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"σye = 1  # standard deviation of output measurement\nσyd = 10 # standard deviation of known-disturbance measurement\nwd = 100 # Disturbance suppression weight\n\nq = 10   # Penalty on output\nr = 0.1  # Penalty on input\n\nGe = ExtendedStateSpace(G,\n    B1 = [wd*G.B 0 0],     # Load disturbance, y measurement noise, d measurement noise\n    C1 = [q*G.C; 0G.C],    # Q1 = C1'C1\n    C2 = [G.C; 0G.C],      # Measure output and load disturbance, load disturbance is not a function of state\n    D12 = [0; r],              # Penalize control action Q2 = D12'D12\n    D21 = [0 σye 0; 1 0 σyd],  # direct feedthrough of load disturbance and measurement noise\n)\n\n# We design be optimizing both H2 and H∞ just for fun\nK, Cl = h2synthesize(Ge, 100)\nK∞, γ, mats = hinfsynthesize(Ge)\nCl∞ = lft(Ge, K∞)","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"We perform a simulation to verify the systems performance in the presence of a step disturbance in d. We create a function disturbance that takes the state and time, and outputs a step at the disturbance input between 10  t  20. The other two inputs correspond to e_y e_d, where you can add some measurement noise for more realistic simulations.","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"Ts = 0.01\ndisturbance = (x, t) -> [10 < t < 20; 0randn(); 0randn()] # This is our load disturbance, a step at ``t = 10``\n\nres = lsim(c2d(Cl, Ts), disturbance, 40)\nres∞ = lsim(c2d(Cl∞, Ts), disturbance, 40)\nplot([res, res∞], lab=[\"H2\" \"\" \"H∞\" \"\"], ylab=[\"zy\" \"zu\"])","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"It looks like the disturbance, that had a magnitude of 1, has been amplified quite dramatically! However, the output is scaled by the performance weights w_d*q = 1000, and factoring in this, the disturbance has been suppressed by a factor 50 for the mathcalH_2 controller and 130 for the mathcalH_ controller.","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"Before we feel confident about deploying the LQG controller, we investigate its closed-loop properties. The (negative) feedback controller is given by -K[1,1] (the - sign since h2synthesize returns a positive-feedback controller).","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"w = exp10.(LinRange(-3, 4, 300))\ngangoffourplot(G, [-K[1,1], -K∞[1,1]], w, lab=[\"H2\" \"H∞\"], legend = :bottomright)","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"We see that our design led to a system with reasonable disturbance-rejection properties, however, since we assume that we can measure the disturbance, it's relevant to also consider the transfer function from this disturbance to the output. This transfer function is given by Cl[1,1] and has been scaled by the disturbance-suppression weight w_d and the performance penalty weight q, so we rescale it to get back the original units.","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"bodeplot!((1/q/wd)Cl[1,1], w, plotphase=false, sp=2, lab=\"Gyd\", l=:dash)","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"we see that it overlaps completely with the classical sensitivity function PS, which is expected.","category":"page"},{"location":"measurable_disturbance/","page":"H_2 design with a known disturbance","title":"H_2 design with a known disturbance","text":"Comparing the mathcalH_2 controller with the mathcalH_ controller, we see that the latter pushes down the peak in the sensitivity function further and also increases the closed-loop bandwidth, at the expense of considerably higher high-frequency gain in the controller.","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"                           ▲\n                           │uw      │dw              │do\n                         ┌─┴─┐    ┌─▼─┐            ┌─▼─┐\n                         │   │    │   │            │   │\n                         │ Wu│    │ Wi│            │ Wd│\n                         │   │    │   │            │   │\n    ┌────┐       ┌─────┐ └─▲─┘    └───┘   ┌─────┐  └─┬─┘    ┌───┐\n r  │    │       │     │   │      di▼     │     │   d│  y   │   │ e\n ──►│ Wr ├──►+──►│  K  ├───┴────────+────►│  P  ├────▼───┬─►│ We├──►\n    │    │   ▲   │     │   u              │     │ Py     │  │   │\n    └────┘   │-  └─────┘                  └─────┘        │  └───┘\n             │                                           │\n             │                                           │  ┌───┐\n             │                                           ▼  │   │\n             └───────────────────────────────────────────+◄─┤ Wn│◄─\n                                                          n │   │ ni\n                                                            └───┘","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"In this example we will show how to manually construct the following transfer function, the H_infty norm of which is commonly a performance metric for H_infty synthesis.","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"beginbmatrix\nW_e S_o W_d \nW_u K S_o W_d\nendbmatrix","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"(Note, the function hinfpartition exists to make special instances of this kind of partitioning smoother, this example shows how general transfer matrices can be constructed for more complicated H_infty designs)","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"We note that the first transfer function is the transfer function from d_o rightarrow e and the second transfer function is from d_o rightarrow u_w. It's thus enough for this example to define the blocks PW_eW_dW_u. To form the feedback interconnection, we also need to define a summation node after P. Note, K is the output of the synthesis procedure, we're thus going to break the loop at K and place the inputs and outputs to K (u y) in the system_mapping, while the external inputs and outputs (w z) go in the performance_mapping.","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"Using the connect function, we can then form the closed-loop transfer function automatically, without forming the intermediate output sensitivity function S_o.","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"The code below constructs all transfer functions using the same names as in the block diagram above. Before we start, it really helps to have a block diagram in front of you to not get lost. We redraw the diagram focusing on the relevant signals and blocks only","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"               ▲\n               │uw              │do\n             ┌─┴─┐            ┌─▼─┐\n             │   │            │   │\n             │ Wu│            │ Wd│\n             │   │            │   │\n     ┌─────┐ └─▲─┘   ┌─────┐  └─┬─┘    ┌───┐\n     │     │   │     │     │   d│  y   │   │ e\n┌───►│  K  ├───┴─────┤  P  ├────▼───┬─►│ We├──►\n│    │     │   u     │     │        │  │   │\n│    └─────┘         └─────┘        │  └───┘\n│                                   │\n│                                   │\n│                                   │\n└───────────────────────────────────┘","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"using RobustAndOptimalControl, ControlSystemsBase, Plots\nP = named_ss(ss(tf(1, [1, 0.02, 1])), :P)\nWe = named_ss(10P.sys,  :We, u=:y, y=:e)  # Weigh sensitivity by magnitude of plant\nWu = named_ss(makeweight(1e-3, 10, 10), :Wu, u=:Wu, y=:uw) # Above ω=100, we want to limit the control effort\nWd = named_ss(makeweight(10, 1, 1e-3),  :Wd, u=:do, y=:d) # d is low frequency","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"We also create the summation node after P","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"sumP = sumblock(\"y = Py + d\")","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"We also need a splitter to split the external input :u (remember, the loop was broken at K) into two signals with unique names. ","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"split_u = splitter(:u, 2)","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"The next step is to list all the connections","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"connections = [\n    :u1 => :Wu # splitter to input of Wu\n    :u2 => :Pu # splitter to input of P\n    :Py => :Py # P output to first input of sumblock\n    :d => :d   # output of Wd to second input of sumblock\n    :y => :y   # output of sumblock to input of We\n]\nnothing # hide","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"When we specify the external inputs and outputs to connect, we include y and u since they are external from the view of connect:","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"external_inputs = [\n    :do, :u\n]\nexternal_outputs = [\n    :e, :uw, :y\n]\nnothing # hide","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"We are now ready to form the system we want to minimize the norm of","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"G = connect([P,We,Wu,Wd,sumP,split_u], connections; external_outputs, external_inputs)","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"At this stage, it's good practice to check that the poles, inputs and outputs of G looks correct, it's easy to forget some signal..","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"Before we perform the H_infty synthesis, we need to partition this system to indicate which outputs go to and from the controller and which are part of the performance specification","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"Gsyn = partition(G, u = [:u], y = [:y]) # You can provide either u or w, and either y or z","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"Let's perform some checks to see that we have a sound problem specification","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"hinfassumptions(Gsyn)","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"we also check the equivalences we know should hold","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"system_mapping(Gsyn) == P.sys","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"sminreal(G[:uw, :u].sys) == Wu.sys","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"These will not be identical, the realization might differ, but they should represent the same system","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"hinfnorm2(G[:e, :do].sys - (We * Wd).sys)[1] < 1e-8","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"hinfnorm2(G[:e, :u].sys - (We * P).sys)[1] < 1e-8","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"Now, let's synthesize!","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"K, γ = hinfsynthesize(Gsyn, γrel=1.1, transform=false)\nγ, K","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"We may now form the closed-loop system and check the calculated H_infty norm","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"Gcl = lft(Gsyn, K)\nhinfnorm2(Gcl) # Should be equal to γ","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"The calculated gamma is quite small, indicating that our performance specifications were easy to satisfy. Let's plot the resulting performance mapping with the lower loop closed around K as well as some interesting sensitivity functions","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"w = exp10.(LinRange(-3, 3, 300))\nbodeplot(Gcl, w, plotphase=false, title=[\"do -> e\" \"do -> uw\"])","category":"page"},{"location":"hinf_connection/","page":"General H_infty design","title":"General H_infty design","text":"S, PS, CS, T = gangoffour(P, K)\nspecificationplot([S, CS, T], ylims=(1e-3, 1e2))","category":"page"},{"location":"","page":"Home","title":"Home","text":"<p style=\"text-align:center\">\n\n<img src=\"https://avatars.githubusercontent.com/u/10605979?s=400&u=7b2efdd404c4db3b3f067f04c305d40c025a8961&v=4\" alt=\"JuliaControl logo\">\n\n<br> \n\n<a class=\"github-button\" href=\"https://github.com/JuliaControl/RobustAndOptimalControl.jl\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-show-count=\"true\" aria-label=\"Star JuliaControl/RobustAndOptimalControl.jl on GitHub\">Star</a>\n\n<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n</p> ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using RobustAndOptimalControl\nusing ControlSystemsBase ","category":"page"},{"location":"#RobustAndOptimalControl.jl","page":"Home","title":"RobustAndOptimalControl.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is an extension to ControlSystems.jl that provides methods for robust and optimal analysis and synthesis of linear control systems.","category":"page"},{"location":"#Robust-control","page":"Home","title":"Robust control","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Robust control refers to a set of design and analysis methods that attempt to guarantee stability and performance of a closed-loop control system in the presence of uncertainties, such as plant model mismatch and unknown disturbances.","category":"page"},{"location":"","page":"Home","title":"Home","text":"From classical control, we get robustness measures such as gain and phase margins. These provide a quick and intuitive way to assess robustness of single-input, single-output systems, but also have a number of downsides, such as optimism in the presence of simultaneous gain and phase variations as well as limited applicability for MIMO systems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"More generally applicable measures of robustness include analysis of sensitivity functions, notably the peaks of the sensitivity function","category":"page"},{"location":"","page":"Home","title":"Home","text":"S(s) = (I + P(s)C(s))^-1","category":"page"},{"location":"","page":"Home","title":"Home","text":"and the complementary sensitivity function","category":"page"},{"location":"","page":"Home","title":"Home","text":"T(s) = I - S(s) = (I + P(s)C(s))^-1P(s)C(s)","category":"page"},{"location":"","page":"Home","title":"Home","text":"A modern robustness measure is the diskmargin, that analyses the robustness of a SISO or MIMO system to simultaneous gain and phase variations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the presence of structured uncertainty, such as parameter uncertainty or other explicitly modeled uncertainty, the structured singular value (often referred to as mu), provides a way to analyze robustness with respect to the modeled uncertainty.","category":"page"},{"location":"#Package-highlights","page":"Home","title":"Package highlights","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Named statespace systems (named_ss) where states, inputs and outputs are accessible by names rather than indices. This also facilitates creating complicated feedback interconnections using connect.\nAn interface to DescriptorSystems.jl. Call dss on a statespace system to get a descriptor system. We also forward some methods to implementations in DescriptorSystems.\nRobust/optimal design methods such as H_infty, H_2, LQG and Glover-McFarlane.\nRobustness-related metrics such as nugap (nu-gap), ncfmargin, diskmargin etc.\nUncertainty modeling with the MDelta framework (and more). Analysis methods for this framework are still limited.\nModel augmentation.\nAn ExtendedStateSpace type that represents a partitioned statespace system wu rightarrow zy.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"pkg> add RobustAndOptimalControl","category":"page"},{"location":"#Named-systems","page":"Home","title":"Named systems","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Named systems can be created with named_ss and indexed with their names, e.g.,","category":"page"},{"location":"","page":"Home","title":"Home","text":"G = ssrand(2,2,2);\ns1 = named_ss(G, x = :x, u = [:u_temp, :u_current]) # Create a named system\ns1[:y1, :u_temp] # Access inputs and outputs using their names","category":"page"},{"location":"","page":"Home","title":"Home","text":"but also using incomplete names, e.g., if G contains outputs :y1, :y2, :y3, :z1, :z2, the following retrieves the three outputs that has the prefix :y","category":"page"},{"location":"","page":"Home","title":"Home","text":"s1[:y, :] # Prefix matching is used if no exact match is found.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See the example under Connecting systems together below as well as complicated-feedback example.","category":"page"},{"location":"#Connecting-systems-together","page":"Home","title":"Connecting systems together","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Advanced interconnected systems can be created using the function connect.  See the following example, as well as complicated-feedback example.","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The following complicated feedback interconnection","category":"page"},{"location":"","page":"Home","title":"Home","text":"                 yF\n              ┌────────────────────────────────┐\n              │                                │\n    ┌───────┐ │  ┌───────┐ yR   ┌─────────┐    │    ┌───────┐\nuF  │       │ │  │       ├──────►         │ yC │  uP│       │    yP\n────►   F   ├─┴──►   R   │      │    C    ├────+────►   P   ├────┬────►\n    │       │    │       │   ┌──►         │         │       │    │\n    └───────┘    └───────┘   │  └─────────┘         └───────┘    │\n                             │                                   │\n                             └───────────────────────────────────┘","category":"page"},{"location":"","page":"Home","title":"Home","text":"can be created by","category":"page"},{"location":"","page":"Home","title":"Home","text":"F = named_ss(ssrand(1, 1, 2, proper=true), x=:xF, u=:uF, y=:yF)\nR = named_ss(ssrand(1, 1, 2, proper=true), x=:xR, u=:uR, y=:yR)\nC = named_ss(ssrand(1, 1, 2, proper=true), x=:xC, u=:uC, y=:yC)\nP = named_ss(ssrand(1, 1, 3, proper=true), x=:xP, u=:uP, y=:yP)\n\naddP = sumblock(\"uP = yF + yC\") # Sum node before P\naddC = sumblock(\"uC = yR - yP\") # Sum node before C (drawn as two arrows into C in the diagram)\n\nconnections = [\n    :yP => :yP # Output to input\n    :uP => :uP # addP's output is called the same as P's input\n    :yC => :yC\n    :yF => :yF\n    :yF => :uR\n    :uC => :uC\n    :yR => :yR\n]\nexternal_inputs  = [:uF]\nexternal_outputs = [:yP] # Optional, if not provided, all outputs are considered external\n\nG = connect([F, R, C, P, addP, addC], connections; external_inputs, external_outputs)","category":"page"},{"location":"","page":"Home","title":"Home","text":"If an external input is to be connected to multiple points, use a splitter to split up the signal into a set of unique names which are then used in the connections.","category":"page"},{"location":"#Model-augmentation","page":"Home","title":"Model augmentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Add disturbance and performance models to your system model.","category":"page"},{"location":"","page":"Home","title":"Home","text":"add_disturbance\nadd_measurement_disturbance\nadd_input_differentiator\nadd_output_differentiator\nadd_input_integrator\nadd_output_integrator\nadd_low_frequency_disturbance\nadd_resonant_disturbance","category":"page"},{"location":"#H_\\infty-and-H_2-design","page":"Home","title":"H_infty and H_2 design","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Examples are available in the example folder.","category":"page"},{"location":"","page":"Home","title":"Home","text":"hinfsynthesize\nh2synthesize\nhinfpartition\nhinfassumptions\nspecificationplot\nglover_mcfarlane\nglover_mcfarlane_2dof\nhanus","category":"page"},{"location":"#Example:-Glover-McFarlane-design","page":"Home","title":"Example: Glover McFarlane design","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This example will design a robust controller using the Glover-McFarlane method. This method requires the user to perform an initial loop-shaping design, i.e., by tuning a standard PI controller etc. The glover_mcfarlane method then takes the loop-shaping controller and the plant model and returns a robustified controller. This is example 9.3 from Skogestad, \"Multivariable Feedback Control: Analysis and Design\".","category":"page"},{"location":"","page":"Home","title":"Home","text":"using RobustAndOptimalControl, ControlSystemsBase, Plots, Test\nG = tf(200, [10, 1])*tf(1, [0.05, 1])^2     |> ss # Plant model\nGd = tf(100, [10, 1])                       |> ss # Disturbance model\nW1 = tf([1, 2], [1, 1e-6])                  |> ss # Loop-shaping controller\nK, γ, info = glover_mcfarlane(G, 1.1; W1)         # K is robustified controller\n@test info.γmin ≈ 2.34 atol=0.005\nGcl = extended_gangoffour(G, K) # Form closed-loop system\n\nfig1 = bodeplot([G, info.Gs, G*K], lab=[\"G\" \"\" \"Initial GK\" \"\" \"Robustified GK\"])\nfig2 = bodeplot(Gcl, lab=[\"S\" \"KS\" \"PS\" \"T\"], plotphase=false) # Plot gang of four\n\n# Simulate the response to a disturbance (Gd*feedback(1, G*K) = Gd*S is the closed-loop transfer function from an additive output disturbance)\nfig3 = plot(step(Gd*feedback(1, info.Gs), 3), lab=\"Initial controller\")\nplot!(step(Gd*feedback(1, G*K), 3), lab=\"Robustified controller\")\nfig4 = nyquistplot([info.Gs, G*K], ylims=(-2,1), xlims=(-2, 1),\n    Ms_circles = 1.5,\n    lab = [\"Initial controller\" \"Robustified controller\"],\n    title = \"Loop transfers with and without robustified controller\"\n)\nplot(fig1, fig2, fig3, fig4, titlefontsize=9, labelfontsize=9, size=(800, 640))","category":"page"},{"location":"#Example-of-controller-reduction:","page":"Home","title":"Example of controller reduction:","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The order of the controller designed above can be reduced maintaining at least 2/3 of the robustness margin like this","category":"page"},{"location":"","page":"Home","title":"Home","text":"e,_ = ncfmargin(info.Gs, info.Ks)\nKr, hs, infor = baltrunc_coprime(info.Ks, n=info.Ks.nx)\nn = findlast(RobustAndOptimalControl.error_bound(hs) .> 2e/3) # 2/3 e sets the robustness margin\nKsr, hs, infor = baltrunc_coprime(info.Ks; n)\n@test ncfmargin(info.Gs, Ksr)[1] >= 2/3 * e\nKr = W1*Ksr\nbodeplot([G*K, G*Kr], lab=[\"L original\" \"\" \"L Reduced\" \"\"])","category":"page"},{"location":"","page":"Home","title":"Home","text":"This gives a final controller Kr of order 2 instead of order 5, but a very similar robustness margin. You may also call","category":"page"},{"location":"","page":"Home","title":"Home","text":"controller_reduction_plot(info.Gs, info.Ks)","category":"page"},{"location":"","page":"Home","title":"Home","text":"to help you select the controller order.","category":"page"},{"location":"#Example:-Glover-McFarlane-2-dof-design","page":"Home","title":"Example: Glover McFarlane 2-dof design","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In this example, we design a 2 degree-of-freedom controller using the Glover McFarlane method. This design method requires you to specify both a loop-shaping controller as well as a reference model. It's usually a good idea to let the reference model have the same number of poles as the system that is being controlled in order not not differentiate the references and introduce non-robustness.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using RobustAndOptimalControl, ControlSystemsBase, Plots\nP = tf([1, 5], [1, 2, 10]) # Plant\nW1 = tf(1,[1, 0]) |> ss    # Loop shaping controller\n\nTref = tf(1, [1, 1])^2 |> ss # Reference model of same order as P\n\nK1dof, γ1, info1 = glover_mcfarlane(ss(P), 1.1; W1)\nK2dof, γ2, info2 = glover_mcfarlane_2dof(ss(P), Tref, 1.1, 1.1; W1)\n\nG1 = feedback(P*K1dof)\nG2 = info2.Gcl\n\nw = exp10.(LinRange(-2, 2, 200))\nfig1 = bodeplot(info2.K1, w, lab=\"Feedforward filter\")\nfig2 = plot([step(G1, 15), step(G2, 15), step(Tref, 15)], lab=[\"1-DOF\" \"2-DOF\" \"Tref\"])\nplot(fig1, fig2)","category":"page"},{"location":"#LQG-design","page":"Home","title":"LQG design","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The main functionality for LQG design is exposed through LQGProblem. See the docstring for an example.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A video tutorial on how to use the LQG interface is available here:","category":"page"},{"location":"","page":"Home","title":"Home","text":"<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/NuAxN1mGCPs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"#System-analysis","page":"Home","title":"System analysis","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"hinfnorm2\nlinfnorm2\nhankelnorm\nh2norm\nnugap\nncfmargin\nrobstab\nispassive\npassivity_index\npassivityplot","category":"page"},{"location":"","page":"Home","title":"Home","text":"See also Structured singular value and diskmargin below","category":"page"},{"location":"#Structured-singular-value-and-diskmargin","page":"Home","title":"Structured singular value and diskmargin","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"structured_singular_value. Note, this only handles diagonal complex perturbations at the moment.\nmuplot\ndiskmargin\nloop_diskmargin\nsim_diskmargin\nloop_scale\nloop_scaling","category":"page"},{"location":"","page":"Home","title":"Home","text":"A video tutorial on how to perform robustness analysis using the diskmargin is available here.","category":"page"},{"location":"#Diskmargin-example","page":"Home","title":"Diskmargin example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The diskmargin can be visualized in several ways, as a region of allowed simultaneous gain and phase variations:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using RobustAndOptimalControl, ControlSystemsBase, Plots\nL = tf(25, [1,10,10,10])\ndm = diskmargin(L, 0)\nplot(dm) # Plot the disk margin to illustrate maximum allowed simultaneous gain and phase variations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"As a Nyquist exclusion disk:","category":"page"},{"location":"","page":"Home","title":"Home","text":"nyquistplot(L)\nplot!(dm, nyquist=true) # plot a nyquist exclusion disk. The Nyquist curve will be tangent to this disk at `dm.ω0`\nnyquistplot!(dm.f0*L, lab=\"perturbed\") # If we perturb the system with the worst-case perturbation `f0`, the curve will pass through the critical point -1.","category":"page"},{"location":"","page":"Home","title":"Home","text":"And as a frequency-dependent margin","category":"page"},{"location":"","page":"Home","title":"Home","text":"w = exp10.(LinRange(-2, 2, 500))\ndms = diskmargin(L, 0, w)\nplot(dms)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can also visualize the plane of complex perturbations that are allowed to be simultaneously applied to the system:","category":"page"},{"location":"","page":"Home","title":"Home","text":"gainphaseplot(L)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The green regions are stable perturbations while red regions are unstable. The diskmargin is the largest disk that can be placed entirely inside the green area. The center of the disk is determined by the skew of the diskmargin. The classical gain margin is the length of the green area along the x-axis starting at the point 1, while the classical phase margin is the length of the green area along the unit circle starting a the point 1.","category":"page"},{"location":"#Closed-loop-analysis","page":"Home","title":"Closed-loop analysis","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ncfmargin\nSensitivity analysis","category":"page"},{"location":"","page":"Home","title":"Home","text":"A video tutorial on how to perform closed-loop analysis is available here.","category":"page"},{"location":"#Model-reduction","page":"Home","title":"Model reduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"baltrunc2\nfrequency_weighted_reduction\nstab_unstab\nbaltrunc_unstab\nbaltrunc_coprime\ncontroller_reduction\nRobustAndOptimalControl.error_bound\ncontroller_reduction_plot","category":"page"},{"location":"#Model-transformations","page":"Home","title":"Model transformations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"modal_form\nschur_form\nhess_form\nfrequency_separation\nRobustAndOptimalControl.blockdiagonalize","category":"page"},{"location":"lqg_disturbance/#Disturbance-modeling-and-rejection-with-LQG-controllers","page":"LQG control with integral action","title":"Disturbance modeling and rejection with LQG controllers","text":"","category":"section"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"This example will demonstrate how you can add disturbance models to ta plant model and achieve effective disturbance rejection using an LQG controller. For simplicity, we will consider a simple first-order system G","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"beginaligned\ndotx = -ax + b(u + d) \ny = cx\nendaligned","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"where a load disturbance d is acting on the input of the system. This is a simple and very common model for load disturbances. In this example, we will let d be a unit step at time t=10, this will effectively create a LQG controller with integral action.","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"We will begin by setting up the LQG problem and solve it without andy disturbance model. For details regarding the setup of an LQG problem, see, the LQGProblem documentation.","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"We start by defining the process model and discretize it using zero-order hold.","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"using RobustAndOptimalControl, ControlSystemsBase, Plots, LinearAlgebra\nTs = 1 # Sample time\nG = c2d(ss(tf(1, [10, 1])), Ts) # Process model","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"We then choose the parameters of the LQG controller, i.e., the cost matrices Q_1 Q_2 as well as the covariance matrices R_1 R_2","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"nx  = G.nx\nnu  = G.nu\nny  = G.ny\nx0  = zeros(G.nx) # Initial condition\n\nQ1 = 100diagm(ones(G.nx)) # state cost matrix\nQ2 = 0.01diagm(ones(nu))  # control cost matrix\n\nR1 = 0.001I(nx) # State noise covariance\nR2 = I(ny)      # measurement noise covariance\nprob = LQGProblem(G, Q1, Q2, R1, R2)\n\ndisturbance = (x, t) -> t * Ts ≥ 10 # This is our load disturbance, a step at ``t = 10``\nGcl = G_PS(prob)  # This forms the transfer function from load disturbance to output\nres = lsim(Gcl, disturbance, 100)\nplot(res)","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"As we can see, the controller appears to do next to nothing to suppress the disturbance. The problem is that the Kalman filter does not have a model for such a disturbance, and its estimate of the state will thus be severely biased.","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"The next step is to add a disturbance model to the plant model. Since the disturbance if of low-frequency character (indeed, its transfer function is 1s), we make use of the function add_low_frequency_disturbance","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"Gd = add_low_frequency_disturbance(G, ϵ = 1e-6) # The ϵ moves the integrator pole slightly into the stable region\nnx = Gd.nx","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"There is no point trying to penalize the disturbance state in the LQR problem, it's not controllable, we thus penalize the output only, which we can write as","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"y^T Q_1 y = (Cx)^T Q_1 Cx = x^T (C^T Q_1C) x","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"C  = Gd.C\nQ1 = 100C'diagm(ones(G.nx)) * C # state cost matrix\nx0 = zeros(nx)\nnothing # hide","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"We also provide new covariance matrices for the Kalman filter where the entry of the state-covariance matrix that corresponds to the disturbance state (the second and last state) determines how fast the Kalman filter integrates the disturbance. We choose a large value (1), implying fast integration","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"R1 = diagm([0.001, 1])\nR2 = I(ny)\nSQ = [zeros(nx-nu, nu); Q2] # Adding Q2 to the x-u cross term achieves perfect integral action without manually modifying the computed feedback gain, if not all inputs are augmented with integral action, we should add Q2[augmented_inds, :] instead\nprob = LQGProblem(Gd, Q1, Q2, R1, R2; SQ=SQ)\nGcl  = [G_PS(prob); -comp_sensitivity(prob)] # -comp_sensitivity(prob) is the same as the transfer function from load disturbance to control signal\nres  = lsim(Gcl, disturbance, 100)\nplot(res, ylabel=[\"y\" \"u\"]); ylims!((-0.05, 0.3), sp = 1)","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"This time, we see that the controller indeed rejects the disturbance and the control signal settles on -1 which is exactly what's required to counteract the load disturbance of +1.","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"using Test\n@test lqr(prob)[end] ≈ 1.0 # The gain from estimated disturbance state to control signal should be 1.0, indicating perfect integral action","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"Before we feel confident about deploying the LQG controller, we investigate its closed-loop properties.","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"w = exp10.(LinRange(-3, log10(pi / Ts), 200))\ngangoffourplot(prob, w, lab = \"\", legend = :bottomright)","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"We see that our design led to a system with a rather high peak in sensitivity. This is an indication that we perhaps added too much \"integral action\" by a too fast observer pole related to the disturbance state. Let's see how a slightly more conservative design fares:","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"R1 = diagm([0.001, 0.2]) # Reduce the noise on the integrator state from 1 to 0.2\nR2 = I(ny)\nprob = LQGProblem(Gd, Q1, Q2, R1, R2)\n\nGcl = [G_PS(prob); -comp_sensitivity(prob)]\nres = lsim(Gcl, disturbance, 100)\nf1 = plot(res, ylabel=[\"y\" \"u\"]); ylims!((-0.05, 0.3), sp = 1)\nf2 = gangoffourplot(prob, w, lab = \"\", legend = :bottomright)\n\nplot(f1, f2, titlefontsize=10)","category":"page"},{"location":"lqg_disturbance/","page":"LQG control with integral action","title":"LQG control with integral action","text":"We see that we now have a slightly larger disturbance response than before, but in exchange, we lowered the peak sensitivity and complimentary sensitivity from (1.51, 1.25) to (1.31, 1.11), a more robust design. We also reduced the amplification of measurement noise (CS = C(1+PC)). To be really happy with the design, we should probably add high-frequency roll-off as well.","category":"page"}]
}
